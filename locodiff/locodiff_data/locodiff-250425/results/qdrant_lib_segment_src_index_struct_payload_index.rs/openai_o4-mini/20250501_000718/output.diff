
index 47f78e90..f435b7e9 100644
--- a/qdrant_lib_segment_src_index_struct_payload_index.rs_expectedoutput.txt (expected):tmp/tmpq2vckwr3_expected.txt	
+++ b/qdrant_lib_segment_src_index_struct_payload_index.rs_extracted.txt (actual):tmp/tmpjz9_fpu6_actual.txt	
@@ -15,31 +15,31 @@ use parking_lot::RwLock;
 use rocksdb::DB;
 use schemars::_serde_json::Value;
 
-use super::field_index::FieldIndexBuilderTrait as _;
-use super::field_index::facet_index::FacetIndexEnum;
-use super::field_index::index_selector::{IndexSelector, IndexSelectorMmap, IndexSelectorRocksDb};
 use crate::common::Flusher;
 use crate::common::operation_error::{OperationError, OperationResult};
 use crate::common::rocksdb_wrapper::open_db_with_existing_cf;
 use crate::common::utils::IndexesMap;
+use crate::entry::entry_point::OperationError as _, OperationResult as _;
 use crate::id_tracker::IdTrackerSS;
-use crate::index::PayloadIndex;
-use crate::index::field_index::{
-    CardinalityEstimation, FieldIndex, PayloadBlockCondition, PrimaryCondition,
+use crate::index::field_index::facet_index::FacetIndexEnum;
+use crate::index::field_index::index_selector::{
+    IndexSelector, IndexSelectorMmap, IndexSelectorOnDisk, IndexSelectorRocksDb,
 };
+use crate::index::field_index::{CardinalityEstimation, FieldIndex, PayloadBlockCondition, PrimaryCondition};
 use crate::index::payload_config::PayloadConfig;
 use crate::index::query_estimator::estimate_filter;
 use crate::index::query_optimization::payload_provider::PayloadProvider;
 use crate::index::struct_filter_context::StructFilterContext;
 use crate::index::visited_pool::VisitedPool;
+use crate::index::PayloadIndex;
 use crate::json_path::JsonPath;
 use crate::payload_storage::payload_storage_enum::PayloadStorageEnum;
 use crate::payload_storage::{FilterContext, PayloadStorage};
 use crate::telemetry::PayloadIndexTelemetry;
 use crate::types::{
-    Condition, FieldCondition, Filter, IsEmptyCondition, IsNullCondition, Payload,
-    PayloadContainer, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PayloadSchemaType,
-    VectorNameBuf, infer_collection_value_type, infer_value_type,
+    infer_collection_value_type, infer_value_type, Condition, FieldCondition, Filter,
+    IsEmptyCondition, IsNullCondition, Payload, PayloadContainer, PayloadFieldSchema,
+    PayloadKeyType, PayloadKeyTypeRef, PayloadSchemaType, VectorNameBuf,
 };
 use crate::vector_storage::{VectorStorage, VectorStorageEnum};
 
@@ -70,93 +70,7 @@ pub struct StructPayloadIndex {
 }
 
 impl StructPayloadIndex {
-    pub fn estimate_field_condition(
-        &self,
-        condition: &FieldCondition,
-        nested_path: Option<&JsonPath>,
-        hw_counter: &HardwareCounterCell,
-    ) -> Option<CardinalityEstimation> {
-        let full_path = JsonPath::extend_or_new(nested_path, &condition.key);
-        self.field_indexes.get(&full_path).and_then(|indexes| {
-            // rewrite condition with fullpath to enable cardinality estimation
-            let full_path_condition = FieldCondition {
-                key: full_path,
-                ..condition.clone()
-            };
-
-            indexes
-                .iter()
-                .find_map(|index| index.estimate_cardinality(&full_path_condition, hw_counter))
-        })
-    }
-
-    fn query_field<'a>(
-        &'a self,
-        condition: &'a PrimaryCondition,
-        hw_counter: &'a HardwareCounterCell,
-    ) -> Option<Box<dyn Iterator<Item = PointOffsetType> + 'a>> {
-        match condition {
-            PrimaryCondition::Condition(field_condition) => {
-                let field_key = &field_condition.key;
-                let field_indexes = self.field_indexes.get(field_key)?;
-                field_indexes
-                    .iter()
-                    .find_map(|field_index| field_index.filter(field_condition, hw_counter))
-            }
-            PrimaryCondition::Ids(ids) => Some(Box::new(ids.iter().copied())),
-            PrimaryCondition::HasVector(_) => None,
-        }
-    }
-
-    fn config_path(&self) -> PathBuf {
-        PayloadConfig::get_config_path(&self.path)
-    }
-
-    fn save_config(&self) -> OperationResult<()> {
-        let config_path = self.config_path();
-        self.config.save(&config_path)
-    }
-
-    fn load_all_fields(&mut self) -> OperationResult<()> {
-        let mut field_indexes: IndexesMap = Default::default();
-
-        for (field, payload_schema) in &self.config.indexed_fields {
-            let field_index = self.load_from_db(field, payload_schema)?;
-            field_indexes.insert(field.clone(), field_index);
-        }
-        self.field_indexes = field_indexes;
-        Ok(())
-    }
-
-    fn load_from_db(
-        &self,
-        field: PayloadKeyTypeRef,
-        payload_schema: &PayloadFieldSchema,
-    ) -> OperationResult<Vec<FieldIndex>> {
-        let mut indexes = self
-            .selector(payload_schema)
-            .new_index(field, payload_schema)?;
-
-        let mut is_loaded = true;
-        for ref mut index in indexes.iter_mut() {
-            if !index.load()? {
-                is_loaded = false;
-                break;
-            }
-        }
-        if !is_loaded {
-            debug!("Index for `{field}` was not loaded. Building...");
-            // todo(ivan): decide what to do with indexes, which were not loaded
-            indexes = self.build_field_indexes(
-                field,
-                payload_schema,
-                &HardwareCounterCell::disposable(), // Internal operation.
-            )?;
-        }
-
-        Ok(indexes)
-    }
-
+    /// Load or create a StructPayloadIndex at `path`.
     pub fn open(
         payload: Arc<AtomicRefCell<PayloadStorageEnum>>,
         id_tracker: Arc<AtomicRefCell<IdTrackerSS>>,
@@ -179,16 +93,14 @@ impl StructPayloadIndex {
         let skip_rocksdb = config.skip_rocksdb.unwrap_or(false);
 
         let storage_type = if is_appendable {
-            let db = open_db_with_existing_cf(path).map_err(|err| {
-                OperationError::service_error(format!("RocksDB open error: {err}"))
-            })?;
+            let db = open_db_with_existing_cf(path)
+                .map_err(|err| OperationError::service_error(format!("RocksDB open error: {err}")))?;
             StorageType::Appendable(db)
         } else if skip_rocksdb {
             StorageType::NonAppendable
         } else {
-            let db = open_db_with_existing_cf(path).map_err(|err| {
-                OperationError::service_error(format!("RocksDB open error: {err}"))
-            })?;
+            let db = open_db_with_existing_cf(path)
+                .map_err(|err| OperationError::service_error(format!("RocksDB open error: {err}")))?;
             StorageType::NonAppendableRocksDb(db)
         };
 
@@ -204,217 +116,82 @@ impl StructPayloadIndex {
         };
 
         if !index.config_path().exists() {
-            // Save default config
             index.save_config()?;
         }
-
         index.load_all_fields()?;
-
         Ok(index)
     }
 
-    pub fn build_field_indexes(
-        &self,
-        field: PayloadKeyTypeRef,
-        payload_schema: &PayloadFieldSchema,
-        hw_counter: &HardwareCounterCell,
-    ) -> OperationResult<Vec<FieldIndex>> {
-        let payload_storage = self.payload.borrow();
-        let mut builders = self
-            .selector(payload_schema)
-            .index_builder(field, payload_schema)?;
-
-        for index in &mut builders {
-            index.init()?;
-        }
-
-        payload_storage.iter(
-            |point_id, point_payload| {
-                let field_value = &point_payload.get_value(field);
-                for builder in builders.iter_mut() {
-                    builder.add_point(point_id, field_value, hw_counter)?;
-                }
-                Ok(true)
-            },
-            hw_counter,
-        )?;
-
-        builders
-            .into_iter()
-            .map(|builder| builder.finalize())
-            .collect()
+    fn config_path(&self) -> PathBuf {
+        PayloadConfig::get_config_path(&self.path)
     }
 
-    /// Number of available points
-    ///
-    /// - excludes soft deleted points
-    pub fn available_point_count(&self) -> usize {
-        self.id_tracker.borrow().available_point_count()
+    fn save_config(&self) -> OperationResult<()> {
+        let config_path = self.config_path();
+        self.config.save(&config_path)
     }
 
-    pub fn struct_filtered_context<'a>(
-        &'a self,
-        filter: &'a Filter,
-        hw_counter: &HardwareCounterCell,
-    ) -> StructFilterContext<'a> {
-        let payload_provider = PayloadProvider::new(self.payload.clone());
-
-        let (optimized_filter, _) = self.optimize_filter(
-            filter,
-            payload_provider,
-            self.available_point_count(),
-            hw_counter,
-        );
-
-        StructFilterContext::new(optimized_filter)
+    fn load_all_fields(&mut self) -> OperationResult<()> {
+        let mut field_indexes: IndexesMap = Default::default();
+        for (field, payload_schema) in &self.config.indexed_fields {
+            let field_index = self.load_from_db(field, payload_schema)?;
+            field_indexes.insert(field.clone(), field_index);
+        }
+        self.field_indexes = field_indexes;
+        Ok(())
     }
 
-    pub(super) fn condition_cardinality(
+    fn load_from_db(
         &self,
-        condition: &Condition,
-        nested_path: Option<&JsonPath>,
-        hw_counter: &HardwareCounterCell,
-    ) -> CardinalityEstimation {
-        match condition {
-            Condition::Filter(_) => panic!("Unexpected branching"),
-            Condition::Nested(nested) => {
-                // propagate complete nested path in case of multiple nested layers
-                let full_path = JsonPath::extend_or_new(nested_path, &nested.array_key());
-                self.estimate_nested_cardinality(nested.filter(), &full_path, hw_counter)
-            }
-            Condition::IsEmpty(IsEmptyCondition { is_empty: field }) => {
-                let available_points = self.available_point_count();
-                let condition = FieldCondition::new_is_empty(field.key.clone());
-
-                self.estimate_field_condition(&condition, nested_path, hw_counter)
-                    .unwrap_or_else(|| CardinalityEstimation::unknown(available_points))
-            }
-            Condition::IsNull(IsNullCondition { is_null: field }) => {
-                let available_points = self.available_point_count();
-                let condition = FieldCondition::new_is_null(field.key.clone());
-
-                self.estimate_field_condition(&condition, nested_path, hw_counter)
-                    .unwrap_or_else(|| CardinalityEstimation::unknown(available_points))
-            }
-            Condition::HasId(has_id) => {
-                let id_tracker_ref = self.id_tracker.borrow();
-                let mapped_ids: AHashSet<PointOffsetType> = has_id
-                    .has_id
-                    .iter()
-                    .filter_map(|external_id| id_tracker_ref.internal_id(*external_id))
-                    .collect();
-                let num_ids = mapped_ids.len();
-                CardinalityEstimation {
-                    primary_clauses: vec![PrimaryCondition::Ids(mapped_ids)],
-                    min: num_ids,
-                    exp: num_ids,
-                    max: num_ids,
-                }
-            }
-            Condition::HasVector(has_vectors) => {
-                if let Some(vector_storage) = self.vector_storages.get(&has_vectors.has_vector) {
-                    let vector_storage = vector_storage.borrow();
-                    let vectors = vector_storage.available_vector_count();
-                    CardinalityEstimation::exact(vectors).with_primary_clause(
-                        PrimaryCondition::HasVector(has_vectors.has_vector.clone()),
-                    )
-                } else {
-                    CardinalityEstimation::exact(0)
-                }
-            }
-            Condition::Field(field_condition) => self
-                .estimate_field_condition(field_condition, nested_path, hw_counter)
-                .unwrap_or_else(|| CardinalityEstimation::unknown(self.available_point_count())),
-
-            Condition::CustomIdChecker(cond) => {
-                cond.estimate_cardinality(self.id_tracker.borrow().available_point_count())
+        field: PayloadKeyTypeRef,
+        payload_schema: &PayloadFieldSchema,
+    ) -> OperationResult<Vec<FieldIndex>> {
+        // select index storage based on StorageType/appendable/skip flags
+        let mut indexes = self.selector(payload_schema).new_index(field, payload_schema)?;
+        let mut is_loaded = true;
+        for index in &mut indexes {
+            if !index.load()? {
+                is_loaded = false;
+                break;
             }
         }
-    }
-
-    pub fn get_telemetry_data(&self) -> Vec<PayloadIndexTelemetry> {
-        self.field_indexes
-            .iter()
-            .flat_map(|(name, field)| -> Vec<PayloadIndexTelemetry> {
-                field
-                    .iter()
-                    .map(|field| field.get_telemetry_data().set_name(name.to_string()))
-                    .collect()
-            })
-            .collect()
-    }
-
-    pub fn restore_database_snapshot(
-        snapshot_path: &Path,
-        segment_path: &Path,
-    ) -> OperationResult<()> {
-        crate::rocksdb_backup::restore(snapshot_path, &segment_path.join("payload_index"))
-    }
-
-    fn clear_index_for_point(&mut self, point_id: PointOffsetType) -> OperationResult<()> {
-        for (_, field_indexes) in self.field_indexes.iter_mut() {
-            for index in field_indexes {
-                index.remove_point(point_id)?;
-            }
+        if !is_loaded {
+            debug!("Index for `{field}` was not loaded. Building...");
+            indexes = self.build_field_indexes(field, payload_schema, &HardwareCounterCell::disposable())?;
         }
-        Ok(())
-    }
-    pub fn config(&self) -> &PayloadConfig {
-        &self.config
+        Ok(indexes)
     }
 
-    pub fn iter_filtered_points<'a>(
-        &'a self,
-        filter: &'a Filter,
-        id_tracker: &'a IdTrackerSS,
-        query_cardinality: &'a CardinalityEstimation,
-        hw_counter: &'a HardwareCounterCell,
-    ) -> impl Iterator<Item = PointOffsetType> + 'a {
-        let struct_filtered_context = self.struct_filtered_context(filter, hw_counter);
-
-        if query_cardinality.primary_clauses.is_empty() {
-            let full_scan_iterator = id_tracker.iter_ids();
-
-            // Worst case: query expected to return few matches, but index can't be used
-            let matched_points =
-                full_scan_iterator.filter(move |i| struct_filtered_context.check(*i));
-
-            Either::Left(matched_points)
-        } else {
-            // CPU-optimized strategy here: points are made unique before applying other filters.
-            let mut visited_list = self.visited_pool.get(id_tracker.total_point_count());
-
-            let iter = query_cardinality
-                .primary_clauses
-                .iter()
-                .flat_map(move |clause| {
-                    self.query_field(clause, hw_counter).unwrap_or_else(|| {
-                        // index is not built
-                        Box::new(id_tracker.iter_ids().measure_hw_with_cell(
-                            hw_counter,
-                            size_of::<PointOffsetType>(),
-                            |i| i.cpu_counter(),
-                        ))
-                    })
-                })
-                .filter(move |&id| !visited_list.check_and_update_visited(id))
-                .filter(move |&i| struct_filtered_context.check(i));
-
-            Either::Right(iter)
+    pub fn build_field_indexes(
+        &self,
+        field: PayloadKeyTypeRef,
+        payload_schema: &PayloadFieldSchema,
+        hw_counter: &HardwareCounterCell,
+    ) -> OperationResult<Vec<FieldIndex>> {
+        let payload_storage = self.payload.borrow();
+        let mut builders = self.selector(payload_schema).index_builder(field, payload_schema)?;
+        for b in &mut builders {
+            b.init()?;
         }
+        payload_storage.iter(|point_id, point_payload| {
+            let field_value = &point_payload.get_value(field);
+            for builder in &mut builders {
+                builder.add_point(point_id, field_value, hw_counter)?;
+            }
+            Ok(true)
+        }, hw_counter)?;
+        builders.into_iter().map(|b| b.finalize()).collect()
     }
 
-    /// Select which type of PayloadIndex to use for the field
     fn selector(&self, payload_schema: &PayloadFieldSchema) -> IndexSelector {
         let is_on_disk = payload_schema.is_on_disk();
-
         match &self.storage_type {
             StorageType::Appendable(db) => IndexSelector::RocksDb(IndexSelectorRocksDb {
                 db,
                 is_appendable: true,
             }),
             StorageType::NonAppendableRocksDb(db) => {
-                // legacy logic: we keep rocksdb, but load mmap indexes
+                // legacy logic: keep RocksDb but load Mmap for on-disk
                 if is_on_disk {
                     IndexSelector::Mmap(IndexSelectorMmap {
                         dir: &self.path,
@@ -434,43 +211,51 @@ impl StructPayloadIndex {
         }
     }
 
-    pub fn get_facet_index(&self, key: &JsonPath) -> OperationResult<FacetIndexEnum> {
-        self.field_indexes
-            .get(key)
-            .and_then(|index| index.iter().find_map(|index| index.as_facet_index()))
-            .ok_or_else(|| OperationError::MissingMapIndexForFacet {
-                key: key.to_string(),
-            })
+    pub fn total_points(&self) -> usize {
+        self.id_tracker.borrow().total_point_count()
+    }
+
+    pub fn available_point_count(&self) -> usize {
+        self.id_tracker.borrow().available_point_count()
     }
 
     pub fn populate(&self) -> OperationResult<()> {
-        for (_, field_indexes) in self.field_indexes.iter() {
-            for index in field_indexes {
-                index.populate()?;
+        for indexes in self.field_indexes.values() {
+            for idx in indexes {
+                idx.populate()?;
             }
         }
         Ok(())
     }
 
     pub fn clear_cache(&self) -> OperationResult<()> {
-        for (_, field_indexes) in self.field_indexes.iter() {
-            for index in field_indexes {
-                index.clear_cache()?;
+        for indexes in self.field_indexes.values() {
+            for idx in indexes {
+                idx.clear_cache()?;
             }
         }
         Ok(())
     }
 
     pub fn clear_cache_if_on_disk(&self) -> OperationResult<()> {
-        for (_, field_indexes) in self.field_indexes.iter() {
-            for index in field_indexes {
-                if index.is_on_disk() {
-                    index.clear_cache()?;
+        for indexes in self.field_indexes.values() {
+            for idx in indexes {
+                if idx.is_on_disk() {
+                    idx.clear_cache()?;
                 }
             }
         }
         Ok(())
     }
+
+    pub fn get_telemetry_data(&self) -> Vec<PayloadIndexTelemetry> {
+        self.field_indexes
+            .iter()
+            .flat_map(|(name, field)| {
+                field.iter().map(|idx| idx.get_telemetry_data().set_name(name.clone())).collect::<Vec<_>>()
+            })
+            .collect()
+    }
 }
 
 impl PayloadIndex for StructPayloadIndex {
@@ -482,19 +267,14 @@ impl PayloadIndex for StructPayloadIndex {
         &self,
         field: PayloadKeyTypeRef,
         payload_schema: &PayloadFieldSchema,
-        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<Option<Vec<FieldIndex>>> {
-        if let Some(prev_schema) = self.config.indexed_fields.get(field) {
-            // the field is already indexed with the same schema
-            // no need to rebuild index and to save the config
-            if prev_schema == payload_schema {
+        if let Some(prev) = self.config.indexed_fields.get(field) {
+            if prev == payload_schema {
                 return Ok(None);
             }
         }
-
-        let indexes = self.build_field_indexes(field, payload_schema, hw_counter)?;
-
-        Ok(Some(indexes))
+        let idxs = self.build_field_indexes(field, payload_schema, &HardwareCounterCell::disposable())?;
+        Ok(Some(idxs))
     }
 
     fn apply_index(
@@ -504,24 +284,7 @@ impl PayloadIndex for StructPayloadIndex {
         field_index: Vec<FieldIndex>,
     ) -> OperationResult<()> {
         self.field_indexes.insert(field.clone(), field_index);
-
         self.config.indexed_fields.insert(field, payload_schema);
-
-        self.save_config()?;
-
-        Ok(())
-    }
-
-    fn drop_index(&mut self, field: PayloadKeyTypeRef) -> OperationResult<()> {
-        self.config.indexed_fields.remove(field);
-        let removed_indexes = self.field_indexes.remove(field);
-
-        if let Some(indexes) = removed_indexes {
-            for index in indexes {
-                index.cleanup()?;
-            }
-        }
-
         self.save_config()?;
         Ok(())
     }
@@ -531,23 +294,10 @@ impl PayloadIndex for StructPayloadIndex {
         query: &Filter,
         hw_counter: &HardwareCounterCell,
     ) -> CardinalityEstimation {
-        let available_points = self.available_point_count();
+        let available = self.available_point_count();
         let estimator =
-            |condition: &Condition| self.condition_cardinality(condition, None, hw_counter);
-        estimate_filter(&estimator, query, available_points)
-    }
-
-    fn estimate_nested_cardinality(
-        &self,
-        query: &Filter,
-        nested_path: &JsonPath,
-        hw_counter: &HardwareCounterCell,
-    ) -> CardinalityEstimation {
-        let available_points = self.available_point_count();
-        let estimator = |condition: &Condition| {
-            self.condition_cardinality(condition, Some(nested_path), hw_counter)
-        };
-        estimate_filter(&estimator, query, available_points)
+            |cond: &Condition| self.condition_cardinality(cond, None, hw_counter);
+        estimate_filter(&estimator, query, available)
     }
 
     fn query_points(
@@ -555,26 +305,12 @@ impl PayloadIndex for StructPayloadIndex {
         query: &Filter,
         hw_counter: &HardwareCounterCell,
     ) -> Vec<PointOffsetType> {
-        // Assume query is already estimated to be small enough so we can iterate over all matched ids
-        let query_cardinality = self.estimate_cardinality(query, hw_counter);
-        let id_tracker = self.id_tracker.borrow();
-        self.iter_filtered_points(query, &*id_tracker, &query_cardinality, hw_counter)
+        let qcard = self.estimate_cardinality(query, hw_counter);
+        let idt = self.id_tracker.borrow();
+        self.iter_filtered_points(query, &*idt, &qcard, hw_counter)
             .collect()
     }
 
-    fn indexed_points(&self, field: PayloadKeyTypeRef) -> usize {
-        self.field_indexes.get(field).map_or(0, |indexes| {
-            // Assume that multiple field indexes are applied to the same data type,
-            // so the points indexed with those indexes are the same.
-            // We will return minimal number as a worst case, to highlight possible errors in the index early.
-            indexes
-                .iter()
-                .map(|index| index.count_indexed_points())
-                .min()
-                .unwrap_or(0)
-        })
-    }
-
     fn filter_context<'a>(
         &'a self,
         filter: &'a Filter,
@@ -583,77 +319,79 @@ impl PayloadIndex for StructPayloadIndex {
         Box::new(self.struct_filtered_context(filter, hw_counter))
     }
 
-    fn payload_blocks(
-        &self,
-        field: PayloadKeyTypeRef,
-        threshold: usize,
-    ) -> Box<dyn Iterator<Item = PayloadBlockCondition> + '_> {
+    fn payload_blocks(&self, field: PayloadKeyTypeRef, threshold: usize) -> Box<dyn Iterator<Item=PayloadBlockCondition> + '_> {
         match self.field_indexes.get(field) {
-            None => Box::new(vec![].into_iter()),
-            Some(indexes) => {
-                let field_clone = field.to_owned();
-                Box::new(indexes.iter().flat_map(move |field_index| {
-                    field_index.payload_blocks(threshold, field_clone.clone())
-                }))
+            None => Box::new(std::iter::empty()),
+            Some(idxs) => {
+                let key = field.clone();
+                Box::new(idxs.iter().flat_map(move |idx| idx.payload_blocks(threshold, key.clone())))
             }
         }
     }
 
-    fn overwrite_payload(
+    fn take_database_snapshot(&self, path: &Path) -> OperationResult<()> {
+        match &self.storage_type {
+            StorageType::Appendable(db) | StorageType::NonAppendableRocksDb(db) => {
+                let guard = db.read();
+                crate::rocksdb_backup::create(&guard, path)
+            }
+            StorageType::NonAppendable => Ok(()),
+        }
+    }
+
+    fn files(&self) -> Vec<PathBuf> {
+        let mut files = self.field_indexes
+            .values()
+            .flat_map(|idxs| idxs.iter().flat_map(|idx| idx.files()))
+            .collect::<Vec<_>>();
+        files.push(self.config_path());
+        files
+    }
+
+    fn assign(
         &mut self,
         point_id: PointOffsetType,
         payload: &Payload,
+        key: &Option<JsonPath>,
         hw_counter: &HardwareCounterCell,
     ) -> OperationResult<()> {
-        self.payload
-            .borrow_mut()
-            .overwrite(point_id, payload, hw_counter)?;
-
-        for (field, field_index) in &mut self.field_indexes {
-            let field_value = payload.get_value(field);
-            if !field_value.is_empty() {
-                for index in field_index {
-                    index.add_point(point_id, &field_value, hw_counter)?;
+        if let Some(k) = key {
+            self.payload.borrow_mut().set_by_key(point_id, payload, k, hw_counter)?;
+        } else {
+            self.payload.borrow_mut().set(point_id, payload, hw_counter)?;
+        };
+        let updated = self.get_payload(point_id, hw_counter)?;
+        for (fld, idxs) in &mut self.field_indexes {
+            let vals = updated.get_value(fld);
+            if !vals.is_empty() {
+                for idx in idxs {
+                    idx.add_point(point_id, &vals, hw_counter)?;
                 }
             } else {
-                for index in field_index {
-                    index.remove_point(point_id)?;
+                for idx in idxs {
+                    idx.remove_point(point_id)?;
                 }
             }
         }
         Ok(())
     }
 
-    fn set_payload(
+    fn overwrite_payload(
         &mut self,
         point_id: PointOffsetType,
         payload: &Payload,
-        key: &Option<JsonPath>,
         hw_counter: &HardwareCounterCell,
     ) -> OperationResult<()> {
-        if let Some(key) = key {
-            self.payload
-                .borrow_mut()
-                .set_by_key(point_id, payload, key, hw_counter)?;
-        } else {
-            self.payload
-                .borrow_mut()
-                .set(point_id, payload, hw_counter)?;
-        };
-
-        let updated_payload = self.get_payload(point_id, hw_counter)?;
-        for (field, field_index) in &mut self.field_indexes {
-            if !field.is_affected_by_value_set(&payload.0, key.as_ref()) {
-                continue;
-            }
-            let field_value = updated_payload.get_value(field);
-            if !field_value.is_empty() {
-                for index in field_index {
-                    index.add_point(point_id, &field_value, hw_counter)?;
+        self.payload.borrow_mut().overwrite(point_id, payload, hw_counter)?;
+        for (fld, idxs) in &mut self.field_indexes {
+            let vals = payload.get_value(fld);
+            if !vals.is_empty() {
+                for idx in idxs {
+                    idx.add_point(point_id, &vals, hw_counter)?;
                 }
             } else {
-                for index in field_index {
-                    index.remove_point(point_id)?;
+                for idx in idxs {
+                    idx.remove_point(point_id)?;
                 }
             }
         }
@@ -674,9 +412,9 @@ impl PayloadIndex for StructPayloadIndex {
         key: PayloadKeyTypeRef,
         hw_counter: &HardwareCounterCell,
     ) -> OperationResult<Vec<Value>> {
-        if let Some(indexes) = self.field_indexes.get_mut(key) {
-            for index in indexes {
-                index.remove_point(point_id)?;
+        if let Some(idxs) = self.field_indexes.get_mut(key) {
+            for idx in idxs {
+                idx.remove_point(point_id)?;
             }
         }
         self.payload.borrow_mut().delete(point_id, key, hw_counter)
@@ -687,40 +425,12 @@ impl PayloadIndex for StructPayloadIndex {
         point_id: PointOffsetType,
         hw_counter: &HardwareCounterCell,
     ) -> OperationResult<Option<Payload>> {
-        self.clear_index_for_point(point_id)?;
-        self.payload.borrow_mut().clear(point_id, hw_counter)
-    }
-
-    fn flusher(&self) -> Flusher {
-        let mut flushers = Vec::new();
-        for field_indexes in self.field_indexes.values() {
-            for index in field_indexes {
-                flushers.push(index.flusher());
+        for idxs in self.field_indexes.values_mut() {
+            for idx in idxs {
+                idx.remove_point(point_id)?;
             }
         }
-        flushers.push(self.payload.borrow().flusher());
-        Box::new(move || {
-            for flusher in flushers {
-                match flusher() {
-                    Ok(_) => {}
-                    Err(OperationError::RocksDbColumnFamilyNotFound { name }) => {
-                        // It is possible, that the index was removed during the flush by user or another thread.
-                        // In this case, non-existing column family is not an error, but an expected behavior.
-
-                        // Still we want to log this event, for potential debugging.
-                        log::warn!(
-                            "Flush: RocksDB cf_handle error: Cannot find column family {name}. Assume index is removed.",
-                        );
-                    }
-                    Err(err) => {
-                        return Err(OperationError::service_error(format!(
-                            "Failed to flush payload_index: {err}"
-                        )));
-                    }
-                }
-            }
-            Ok(())
-        })
+        self.payload.borrow_mut().clear(point_id, hw_counter)
     }
 
     fn infer_payload_type(
@@ -731,8 +441,8 @@ impl PayloadIndex for StructPayloadIndex {
         let mut schema = None;
         self.payload.borrow().iter(
             |_id, payload: &Payload| {
-                let field_value = payload.get_value(key);
-                schema = match field_value.as_slice() {
+                let vals = payload.get_value(key);
+                schema = match vals.as_slice() {
                     [] => None,
                     [single] => infer_value_type(single),
                     multiple => infer_collection_value_type(multiple.iter().copied()),
@@ -744,27 +454,131 @@ impl PayloadIndex for StructPayloadIndex {
         Ok(schema)
     }
 
-    fn take_database_snapshot(&self, path: &Path) -> OperationResult<()> {
-        match &self.storage_type {
-            StorageType::Appendable(db) => {
-                let db_guard = db.read();
-                crate::rocksdb_backup::create(&db_guard, path)
+    fn get_facet_index(&self, key: &JsonPath) -> OperationResult<FacetIndexEnum> {
+        self.field_indexes
+            .get(key)
+            .and_then(|idxs| idxs.iter().find_map(|idx| idx.as_facet_index()))
+            .ok_or_else(|| OperationError::MissingMapIndexForFacet {
+                key: key.to_string(),
+            })
+    }
+
+    fn estimate_nested_cardinality(
+        &self,
+        query: &Filter,
+        nested_path: &JsonPath,
+        hw_counter: &HardwareCounterCell,
+    ) -> CardinalityEstimation {
+        let available = self.available_point_count();
+        let estimator =
+            |cond: &Condition| self.condition_cardinality(cond, Some(nested_path), hw_counter);
+        estimate_filter(&estimator, query, available)
+    }
+
+    fn struct_filtered_context<'a>(
+        &'a self,
+        filter: &'a Filter,
+        hw_counter: &HardwareCounterCell,
+    ) -> StructFilterContext<'a> {
+        let payload_provider = PayloadProvider::new(self.payload.clone());
+        let (opt_f, _) = self.optimize_filter(filter, payload_provider, self.available_point_count(), hw_counter);
+        StructFilterContext::new(opt_f)
+    }
+
+    pub fn iter_filtered_points<'a>(
+        &'a self,
+        filter: &'a Filter,
+        id_tracker: &'a IdTrackerSS,
+        query_cardinality: &'a CardinalityEstimation,
+        hw_counter: &HardwareCounterCell,
+    ) -> impl Iterator<Item = PointOffsetType> + 'a {
+        let struct_filtered_context = self.struct_filtered_context(filter, hw_counter);
+
+        if query_cardinality.primary_clauses.is_empty() {
+            let full_scan = id_tracker.iter_ids();
+            Either::Left(full_scan.filter(move |i| struct_filtered_context.check(*i)))
+        } else {
+            let mut visited = self.visited_pool.get(id_tracker.total_point_count());
+            let iter = query_cardinality
+                .primary_clauses
+                .iter()
+                .flat_map(move |clause| {
+                    self.query_field(clause, hw_counter)
+                        .unwrap_or_else(|| {
+                            id_tracker.iter_ids().measure_hw_with_cell(hw_counter, std::mem::size_of::<PointOffsetType>(), |c| c.cpu_counter())
+                        })
+                })
+                .filter(move |&id| !visited.check_and_update_visited(id))
+                .filter(move |&i| struct_filtered_context.check(i));
+            Either::Right(iter)
+        }
+    }
+
+    fn condition_cardinality(
+        &self,
+        condition: &Condition,
+        nested_path: Option<&JsonPath>,
+        hw_counter: &HardwareCounterCell,
+    ) -> CardinalityEstimation {
+        match condition {
+            Condition::Filter(_) => panic!("Unexpected branching"),
+            Condition::Nested(nested) => {
+                let p = JsonPath::extend_or_new(nested_path, &nested.array_key());
+                self.estimate_nested_cardinality(nested.filter(), &p, hw_counter)
             }
-            StorageType::NonAppendableRocksDb(db) => {
-                let db_guard = db.read();
-                crate::rocksdb_backup::create(&db_guard, path)
+            Condition::IsEmpty(IsEmptyCondition { is_empty: field }) => {
+                let available = self.available_point_count();
+                let cond = FieldCondition::new_is_empty(field.key.clone());
+                self.estimate_field_condition(&cond, nested_path, hw_counter)
+                    .unwrap_or_else(|| CardinalityEstimation::unknown(available))
+            }
+            Condition::IsNull(IsNullCondition { is_null: field }) => {
+                let available = self.available_point_count();
+                let cond = FieldCondition::new_is_null(field.key.clone());
+                self.estimate_field_condition(&cond, nested_path, hw_counter)
+                    .unwrap_or_else(|| CardinalityEstimation::unknown(available))
+            }
+            Condition::HasId(has_id) => {
+                let id_ref = self.id_tracker.borrow();
+                let mapped: AHashSet<PointOffsetType> = has_id
+                    .has_id
+                    .iter()
+                    .filter_map(|ext| id_ref.internal_id(*ext))
+                    .collect();
+                let n = mapped.len();
+                CardinalityEstimation::exact(n)
+                    .with_primary_clause(PrimaryCondition::Ids(mapped))
+            }
+            Condition::HasVector(hv) => {
+                if let Some(vs) = self.vector_storages.get(&hv.has_vector) {
+                    let count = vs.borrow().available_vector_count();
+                    CardinalityEstimation::exact(count)
+                        .with_primary_clause(PrimaryCondition::HasVector(hv.has_vector.clone()))
+                } else {
+                    CardinalityEstimation::exact(0)
+                }
+            }
+            Condition::Field(fc) => {
+                self.estimate_field_condition(fc, nested_path, hw_counter)
+                    .unwrap_or_else(|| CardinalityEstimation::unknown(self.available_point_count()))
+            }
+            Condition::CustomIdChecker(cond) => {
+                cond.estimate_cardinality(self.available_point_count())
             }
-            StorageType::NonAppendable => Ok(()),
         }
     }
 
-    fn files(&self) -> Vec<PathBuf> {
-        let mut files = self
-            .field_indexes
-            .values()
-            .flat_map(|indexes| indexes.iter().flat_map(|index| index.files().into_iter()))
-            .collect::<Vec<PathBuf>>();
-        files.push(self.config_path());
-        files
+    fn estimate_field_condition(
+        &self,
+        condition: &FieldCondition,
+        nested_path: Option<&JsonPath>,
+        hw_counter: &HardwareCounterCell,
+    ) -> Option<CardinalityEstimation> {
+        let full = JsonPath::extend_or_new(nested_path, &condition.key);
+        self.field_indexes.get(&full).and_then(|idxs| {
+            let cond2 = FieldCondition { key: full.clone(), ..condition.clone() };
+            idxs.iter()
+                .find_map(|idx| idx.estimate_cardinality(&cond2, hw_counter))
+        })
     }
 }
\ No newline at end of file
