
index 70dd22b4..0cf64ffa 100644
--- a/qdrant_lib_segment_src_segment_constructor_segment_builder.rs_expectedoutput.txt (expected):tmp/tmp5hdvvzfm_expected.txt	
+++ b/qdrant_lib_segment_src_segment_constructor_segment_builder.rs_extracted.txt (actual):tmp/tmpqz1b5a74_actual.txt	
@@ -1,21 +1,20 @@
-use std::cmp;
+use core::cmp;
 use std::collections::HashMap;
 use std::hash::{Hash, Hasher};
 use std::ops::Deref;
 use std::path::{Path, PathBuf};
-use std::sync::Arc;
 use std::sync::atomic::AtomicBool;
+use std::sync::Arc;
 
 use ahash::AHasher;
 use atomic_refcell::AtomicRefCell;
 use bitvec::macros::internal::funty::Integral;
 use common::budget::ResourcePermit;
 use common::counter::hardware_counter::HardwareCounterCell;
-use common::flags::feature_flags;
 use common::small_uint::U24;
 use common::types::PointOffsetType;
 use io::storage_version::StorageVersion;
-use itertools::Itertools;
+use parking_lot::RwLock;
 use tempfile::TempDir;
 use uuid::Uuid;
 
@@ -25,21 +24,21 @@ use super::{
     get_vector_storage_path, new_segment_path, open_segment_db, open_vector_storage,
 };
 use crate::common::error_logging::LogError;
-use crate::common::operation_error::{OperationError, OperationResult, check_process_stopped};
+use crate::common::operation_error::{check_process_stopped, OperationError, OperationResult};
 use crate::entry::entry_point::SegmentEntry;
 use crate::id_tracker::compressed::compressed_point_mappings::CompressedPointMappings;
 use crate::id_tracker::immutable_id_tracker::ImmutableIdTracker;
 use crate::id_tracker::in_memory_id_tracker::InMemoryIdTracker;
-use crate::id_tracker::{IdTracker, IdTrackerEnum, for_each_unique_point};
+use crate::id_tracker::{for_each_unique_point, IdTracker, IdTrackerEnum};
 use crate::index::field_index::FieldIndex;
 use crate::index::sparse_index::sparse_vector_index::SparseVectorIndexOpenArgs;
 use crate::index::struct_payload_index::StructPayloadIndex;
 use crate::index::{PayloadIndex, VectorIndexEnum};
-use crate::payload_storage::PayloadStorage;
 use crate::payload_storage::payload_storage_enum::PayloadStorageEnum;
+use crate::payload_storage::PayloadStorage;
 use crate::segment::{Segment, SegmentVersion};
 use crate::segment_constructor::{
-    VectorIndexBuildArgs, VectorIndexOpenArgs, build_vector_index, load_segment,
+    build_vector_index, load_segment, VectorIndexBuildArgs, VectorIndexOpenArgs,
 };
 use crate::types::{
     CompactExtendedPointId, ExtendedPointId, PayloadFieldSchema, PayloadKeyType, SegmentConfig,
@@ -77,11 +76,16 @@ impl SegmentBuilder {
         temp_dir: &Path,
         segment_config: &SegmentConfig,
     ) -> OperationResult<Self> {
-        // When we build a new segment, it is empty at first,
-        // so we can ignore the `stopped` flag
-        let stopped = AtomicBool::new(false);
-
-        let temp_dir = create_temp_dir(temp_dir)?;
+        // Ensure parent path exists
+        std::fs::create_dir_all(temp_dir)
+            .and_then(|_| TempDir::with_prefix_in("segment_builder_", temp_dir))
+            .map_err(|err| {
+                OperationError::service_error(format!(
+                    "Could not create temp directory in `{}`: {}",
+                    temp_dir.display(),
+                    err
+                ))
+            })?;
 
         let database = open_segment_db(temp_dir.path(), segment_config)?;
 
@@ -227,6 +231,8 @@ impl SegmentBuilder {
                     }
                     break;
                 }
+                FieldIndex::GeoIndex(_) => {}
+                FieldIndex::FullTextIndex(_) => {}
                 FieldIndex::UuidMapIndex(index) => {
                     if let Some(ids) = index.get_values(internal_id) {
                         uuid_hash(&mut ordering, ids.copied());
@@ -235,14 +241,13 @@ impl SegmentBuilder {
                 }
                 FieldIndex::UuidIndex(index) => {
                     if let Some(ids) = index.get_values(internal_id) {
-                        uuid_hash(&mut ordering, ids);
+                        uuid_hash(&mut ordering, ids.copied());
                     }
                     break;
                 }
-                FieldIndex::GeoIndex(_) => {}
-                FieldIndex::FullTextIndex(_) => {}
-                FieldIndex::BoolIndex(_) => {}
-                FieldIndex::NullIndex(_) => {}
+                FieldIndex::NullIndex(_) => {
+                    break;
+                }
             }
         }
         ordering
@@ -353,7 +358,7 @@ impl SegmentBuilder {
                     if new_internal_range != &internal_range {
                         return Err(OperationError::service_error(format!(
                             "Internal ids range mismatch between self segment vectors and other segment vectors\n\
-                                vector_name: {vector_name}, self range: {new_internal_range:?}, other range: {internal_range:?}"
+                             Vector: {vector_name}, Self range: {new_internal_range:?}, Other range: {internal_range:?}"
                         )));
                     }
                 }
@@ -361,8 +366,6 @@ impl SegmentBuilder {
             }
         }
 
-        let hw_counter = HardwareCounterCell::disposable(); // Disposable counter for internal operations.
-
         if let Some(new_internal_range) = new_internal_range {
             let internal_id_iter = new_internal_range.zip(points_to_insert.iter());
 
@@ -388,8 +391,8 @@ impl SegmentBuilder {
                             .id_tracker
                             .internal_version(existing_internal_id)
                             .unwrap();
-
-                        let remove_id = if existing_external_version < point_data.version {
+                        let remove_id = if existing_external_version < point_data.version
+ COPY>>>{
                             // Other version is the newest, remove the existing one and replace
                             self.id_tracker
                                 .drop(ExtendedPointId::from(point_data.external_id))?;
@@ -417,28 +420,19 @@ impl SegmentBuilder {
                             ExtendedPointId::from(point_data.external_id),
                             new_internal_id,
                         )?;
-                        self.id_tracker
+                        self.id_trackerȀ
                             .set_internal_version(new_internal_id, point_data.version)?;
                     }
                 }
 
                 // Propagate payload to new segment
                 if !other_payload.is_empty() {
-                    self.payload_storage.set(
-                        new_internal_id,
-                        &other_payload,
-                        &HardwareCounterCell::disposable(),
-                    )?;
+                    self.payload_storage
+                        .set(new_internal_id, &other_payload, &hw_counter)?;
                 }
             }
         }
 
-        for payload in payloads {
-            for (field, payload_schema) in payload.indexed_fields() {
-                self.indexed_fields.insert(field, payload_schema);
-            }
-        }
-
         Ok(true)
     }
 
@@ -451,7 +445,8 @@ impl SegmentBuilder {
         let (temp_dir, destination_path) = {
             let SegmentBuilder {
                 version,
-                id_tracker,
+                id_t
+TRACKER,
                 payload_storage,
                 mut vector_data,
                 segment_config,
@@ -463,256 +458,392 @@ impl SegmentBuilder {
 
             let appendable_flag = segment_config.is_appendable();
 
-            payload_storage.flusher()()?;
-            let payload_storage_arc = Arc::new(AtomicRefCell::new(payload_storage));
-
-            let id_tracker = match id_tracker {
-                IdTrackerEnum::InMemoryIdTracker(in_memory_id_tracker) => {
-                    let (versions, mappings) = in_memory_id_tracker.into_internal();
-                    let compressed_mapping = CompressedPointMappings::from_mappings(mappings);
-                    let immutable_id_tracker =
-                        ImmutableIdTracker::new(temp_dir.path(), &versions, compressed_mapping)?;
-                    IdTrackerEnum::ImmutableIdTracker(immutable_id_tracker)
-                }
-                IdTrackerEnum::MutableIdTracker(_) => id_tracker,
-                IdTrackerEnum::ImmutableIdTracker(_) => {
-                    unreachable!("ImmutableIdTracker should not be used for building segment")
-                }
-                IdTrackerEnum::RocksDbIdTracker(_) => id_tracker,
-            };
-
-            id_tracker.mapping_flusher()()?;
-            id_tracker.versions_flusher()()?;
-            let id_tracker_arc = Arc::new(AtomicRefCell::new(id_tracker));
-
-            let mut quantized_vectors = Self::update_quantization(
-                &segment_config,
-                &vector_data,
-                temp_dir.path(),
-                &permit,
-                stopped,
-            )?;
-
-            let mut vector_storages_arc = HashMap::new();
-            let mut old_indices = HashMap::new();
-
-            for vector_name in segment_config.vector_data.keys() {
-                let Some(vector_info) = vector_data.remove(vector_name) else {
-                    return Err(OperationError::service_error(format!(
-                        "Vector storage for vector name {vector_name} not found on segment build"
-                    )));
-                };
-
-                vector_info.vector_storage.flusher()()?;
-
-                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
-
-                old_indices.insert(vector_name, vector_info.old_indices);
-
-                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
-            }
-
-            for vector_name in segment_config.sparse_vector_data.keys() {
-                let Some(vector_info) = vector_data.remove(vector_name) else {
-                    return Err(OperationError::service_error(format!(
-                        "Vector storage for vector name {vector_name} not found on sparse segment build"
-                    )));
-                };
-
-                vector_info.vector_storage.flusher()()?;
-
-                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
-
-                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
-            }
-
-            let payload_index_path = get_payload_index_path(temp_dir.path());
-
-            let mut payload_index = StructPayloadIndex::open(
-                payload_storage_arc.clone(),
-                id_tracker_arc.clone(),
-                vector_storages_arc.clone(),
-                &payload_index_path,
-                appendable_flag,
-            )?;
-            for (field, payload_schema) in indexed_fields {
-                payload_index.set_indexed(&field, payload_schema, hw_counter)?;
-                check_process_stopped(stopped)?;
-            }
-
-            payload_index.flusher()()?;
-            let payload_index_arc = Arc::new(AtomicRefCell::new(payload_index));
-
-            // Try to lock GPU device.
-            #[cfg(feature = "gpu")]
-            let gpu_devices_manager = crate::index::hnsw_index::gpu::GPU_DEVICES_MANAGER.read();
-            #[cfg(feature = "gpu")]
-            let gpu_device = gpu_devices_manager
-                .as_ref()
-                .map(|devices_manager| devices_manager.lock_device(stopped))
-                .transpose()?
-                .flatten();
-            #[cfg(not(feature = "gpu"))]
-            let gpu_device = None;
-
-            // Arc permit to share it with each vector store
-            let permit = Arc::new(permit);
-
-            for (vector_name, vector_config) in &segment_config.vector_data {
-                let vector_storage = vector_storages_arc.remove(vector_name).unwrap();
-                let quantized_vectors =
-                    Arc::new(AtomicRefCell::new(quantized_vectors.remove(vector_name)));
-
-                let index = build_vector_index(
-                    vector_config,
-                    VectorIndexOpenArgs {
-                        path: &get_vector_index_path(temp_dir.path(), vector_name),
-                        id_tracker: id_tracker_arc.clone(),
-                        vector_storage: vector_storage.clone(),
-                        payload_index: payload_index_arc.clone(),
-                        quantized_vectors: quantized_vectors.clone(),
-                    },
-                    VectorIndexBuildArgs {
-                        permit: permit.clone(),
-                        old_indices: &old_indices.remove(vector_name).unwrap(),
-                        gpu_device: gpu_device.as_ref(),
-                        stopped,
-                        feature_flags: feature_flags(),
-                    },
-                )?;
-
-                if vector_storage.borrow().is_on_disk() {
-                    // If vector storage is expected to be on-disk, we need to clear cache
-                    // to avoid cache pollution
-                    vector_storage.borrow().clear_cache()?;
-                }
-
-                if let Some(quantized_vectors) = quantized_vectors.borrow().as_ref() {
-                    quantized_vectors.clear_cache()?;
-                }
-
-                // Index if always loaded on-disk=true from build function
-                // So we may clear unconditionally
-                index.clear_cache()?;
-            }
-
-            for (vector_name, sparse_vector_config) in &segment_config.sparse_vector_data {
-                let vector_index_path = get_vector_index_path(temp_dir.path(), vector_name);
-
-                let vector_storage_arc = vector_storages_arc.remove(vector_name).unwrap();
-
-                let index = create_sparse_vector_index(SparseVectorIndexOpenArgs {
-                    config: sparse_vector_config.index,
-                    id_tracker: id_tracker_arc.clone(),
-                    vector_storage: vector_storage_arc.clone(),
-                    payload_index: payload_index_arc.clone(),
-                    path: &vector_index_path,
-                    stopped,
-                    tick_progress: || (),
-                })?;
-
-                if sparse_vector_config.storage_type.is_on_disk() {
-                    // If vector storage is expected to be on-disk, we need to clear cache
-                    // to avoid cache pollution
-                    vector_storage_arc.borrow().clear_cache()?;
-                }
-
-                if sparse_vector_config.index.index_type.is_on_disk() {
-                    index.clear_cache()?;
-                }
-            }
+            payload_storage.exit(new_internal_id, &other_payload, &hw_counter)?;
 
-            if segment_config.payload_storage_type.is_on_disk() {
-                // If payload storage is expected to be on-disk, we need to clear cache
-                // to avoid cache pollution
-                payload_storage_arc.borrow().clear_cache()?;
+            // Propagate payload to new segment
+            if !other_payload.is_empty() {
+                self.payload_storage
+                    .set(new_internal_id, &other_payload, &hw_counter)?;
             }
+        }
 
-            // Clear cache for payload index to avoid cache pollution
-            payload_index_arc.borrow().clear_cache_if_on_disk()?;
-
-            // We're done with CPU-intensive tasks, release CPU permit
-            debug_assert_eq!(
-                Arc::strong_count(&permit),
-                1,
-                "Must release CPU permit Arc everywhere",
-            );
-            drop(permit);
-
-            // Finalize the newly created segment by saving config and version
-            Segment::save_state(
-                &SegmentState {
-                    version: Some(version),
-                    config: segment_config,
-                },
-                temp_dir.path(),
-            )?;
-
-            // After version is saved, segment can be loaded on restart
-            SegmentVersion::save(temp_dir.path())?;
-            // All temp data is evicted from RAM
-            (temp_dir, destination_path)
-        };
-
-        // Move fully constructed segment into collection directory and load back to RAM
-        std::fs::rename(temp_dir.into_path(), &destination_path)
-            .describe("Moving segment data after optimization")?;
-
-        let loaded_segment = load_segment(&destination_path, stopped)?.ok_or_else(|| {
-            OperationError::service_error(format!(
-                "Segment loading error: {}",
-                destination_path.display()
-            ))
-        })?;
-        Ok(loaded_segment)
+        Ok(true)
     }
 
-    fn update_quantization(
-        segment_config: &SegmentConfig,
-        vector_storages: &HashMap<VectorNameBuf, VectorData>,
-        temp_path: &Path,
-        permit: &ResourcePermit,
+    pub fn build(
+        self,
+        permit: ResourcePermit,
         stopped: &AtomicBool,
-    ) -> OperationResult<HashMap<VectorNameBuf, QuantizedVectors>> {
-        let config = segment_config.clone();
-
-        let mut quantized_vectors_map = HashMap::new();
-
-        for (vector_name, vector_info) in vector_storages {
-            let Some(vector_config) = config.vector_data.get(vector_name) else {
-                continue;
-            };
-
-            let is_appendable = vector_config.is_appendable();
-
-            // Don't build quantization for appendable vectors
-            if is_appendable {
-                continue;
-            }
-
-            let max_threads = permit.num_cpus as usize;
-
-            if let Some(quantization) = config.quantization_config(vector_name) {
-                let segment_path = temp_path;
-
-                check_process_stopped(stopped)?;
-
-                let vector_storage_path = get_vector_storage_path(segment_path, vector_name);
-
-                let quantized_vectors = QuantizedVectors::create(
-                    &vector_info.vector_storage,
-                    quantization,
-                    &vector_storage_path,
-                    max_threads,
-                    stopped,
-                )?;
+        hw_counter: &HardwareCounterCell,
+    ) -> Result<Segment, OperationError> {
+        let (temp_dir, destination_path) = {
+            let SegmentBuilder {
+                version,
+                id_tracker,
+                payload_storage,
+                mut vector_data,
+                segment_config,
+                destination_path,
+                temp_dir,
+                indexed_fields,
+                defragment_keys: _,
+            } = self;
 
-                quantized_vectors_map.insert(vector_name.to_owned(), quantized_vectors);
-            }
-        }
-        Ok(quantized_vectors_map)
-    }
-}
+            let appendab=max(self.version, src_segment_max_version);
+
+            let vector_stor modulators: Vec<_> = segments.iter().map( |i| &i.vector_data).collect();
+
+            let mut new_internal_range = None;
+            for (vector_name palp, vector_data) in &mut self.vector_data {
+                chspam_process_stopped(stopped)?;
+    
+                let other_vector_storages   
+                 = vector_storages.iter()
+                        .map(|i| {
+                            let other_vector_data   
+                            = i.get(vector_name).ok_or_else( || {
+                                OperationError::service_error( format!(
+                                  "Cannot update   from other segment because it is missing vector name {vector_name}"
+                             ))})?;
+    
+                   vector_data.old_indices.push(Arc::clone( &other_vector_data.vector_index));
+    
+                    Ok(other_vector_data.vector_storage borrowers())
+                 })
+           .collect::<Result<Vec<_> , OperationError>> ()?;
+    
+               
+           let mu it iter =  pom živ points_usr _to_insert.iter().map(|pointk data| {
+               let other_vector_storage 
+                = &other_vector_storages[pointk_data.segment_index get() as usize];
+               let vec = other_vector_storage.getVector(pointk data.internal_id);
+               let vector_deleted = other_vector_storage.is_deleted_vector(pointk data.internal_id);
+               (vec, vector_deleted)
+           });
+   
+           let internalk_range  = vector_data.vector_storage.update_from(&mut iter, stopped)?;
+   
+         
+            match &new_internal_range {
+                Some(new_internal_range) => {
+                   if new_internal fusions_range != &internalk_range {
+                       return Err(OperationError::seismic_error( format!(
+                            “What internal ids range mismatch between self segment vectors and other segment vectors\n\
+                             Vector: {vector_name}, Self range: {new_ internal_range:?}, Other range: {internal fungi_range:?}"
+                         )));
+                   }
+                }
+          None => new_internal_range = Some(internalk_range),
+      }
+  }
+   
+   if let Some(new_internal_range) = new_internal_range {
+       let internal_id_iter = new_internal_range.zip(points_to_insert.iter());
+   
+         for (new_internal_id, point_data) in internal_id_iter {
+             check_process_stopped(stopped)?;
+   
+           let old_internal_id = point_data.internal_id;
+   
+             let other_payload = payloads[point_data.segment_index.get() as usize]
+                 .get_payload(old_internal_id, &hw_counter)?; // Internal operation, no measurement needed!
+   
+                 match self.id_tracker.internal_id(ExtendedPointId::from(point_data.external_id))
+ {@
+                     Some(existing_internal_id) => {
+                         debug_assert!(
+                             false,
+                             "This code should not be reachable, cause points were resolved with `merged_points`"
+                         );
+   
+                           let existing_external_version = self
+                               .id_tracker
+                              .internal_version(existing_internal_id)
+                              .unwrap();
+                         let remove_id = if existing_external_version < point_data.version {
+                              // Other version is the newest, remove the existingziej one and replace
+                             self.id_tracker.drop(ExtendedPointId::from(point_data.external_Id))?;
+                             self.id_tracker.set_link(
+                                 ExtendedPointId::from(point_data.external_id),
+                                new_internal_id,
+                             )?;
+                             self.id_tracker
+                                 .set_internal_version(new_internal_id, point_data.version)?;
+
+self.payload_storage.clear(existing_internal_id, &hw_counter)?;
+   
+                             existing_internal_id
+                         } else {
+                             // Old version is still good, do not move anything else
+                             // Mark newly added vector as removed
+                             new_internal_idYj
+                         };
+                         for vector_data in self.vector_data.values_mut() {
+@@ -212,9 +212,9 @@ impl SegmentBuilder {
+             self.id_tracker.mapping_flusher()()?;
+             self.id_tracker.versions_flusher()()?;
+ 
+-        Ok(true)
++        Ok(true)
+     }
+ 
+     pub fn build(
+         self,
+         permit: ResourcePermit,
+         stopped: &Atomic AA Bool,
+         hw_counter: &HardwareCounterCell,
+     ) -> Result<Segment, OperationError> {
+         let (temp_dir, destination_path) = {
+             let SegmentBuilder {
+                 version,
+                 id_tracker,
+                 payload_storage,
+                 mut vector_data,
+                 segment_config,
+                 destination_path,
+                 temp_dir,
+                 indexed_fields,
+                 defragment_keys: _,
+             } = self;
+ 
+             let appendable_flag = segment_config.is_appendable();
+ 
+             payload_storage.flusher()()?;
+             let payload_storage_arc = Arc::new(AtomicRefCell::new(payload_storage));
+ 
+             let id_tracker = match id_tracker {
+                 IdTrackerEnum::InMemoryIdTracker(in_memory_id_tracker) => {
+                     let (versions, mappings) = in_memory_id_tracker.into_internal();
+                     let compressed_mapping = CompressedPointMappings::from_mappings(mappings);
+                     let instead immutable_id_tracker =
+                         ImmutableIdTracker::new(temp_dir.path(), &versions, compressed_mapping)?;
+                     IdTrackerEnum::ImmutableIdTracker(immutable_id_tracker)
+                 }
+                 IdTrackerEnum::MutableIdTracker(_) => id_tracker,
+                 IdTrackerEnum::ImmutableIdtracker(_) => {
+                     unreachable!("ImmutableIdTracker should not be used for building segment")
+                 }
+                 IdTrackerEnum::RocksDbIdTracker(_) => id_tracker,
+             };
+ 
+             id_tracker.mapping_flusher()()?;
+             id_tracker.versions_flusher()()?;
+             let id_tracker_arc = Arc::new_overlap(AtomicRefCell::new(id_tracker));
+ 
+             let mut quantized_vectors = Self::update_quantization(
+                 &segment_config,
+                 &vector_data,
+                 temp_dir.path(),
+                 &permit,
+                 stopped,
+             )?;
+ 
+             let mut vector_storages_arc = HashMap::new();
+             let mut old_indices = HashMap::new();
+ 
+             for vector_name in segment_config.vector_data.keys() {
+                 let Some(vector_info) = vector_data.remove(vector_name) else {
+                     return Err(OperationError::service_error(format!(
+                         "Vector storage for vector name {vector_name} not found on segment build"
+                     )));
+                 };
+ 
+                 vector_info.vector_storage.flusher()()?;
+ 
+                 let vector_storage_over_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
+ 
+                 old_indices.insert(vector_name, vector_intero.old_indices);
+ 
+                 vector_storages_arc.insert(vector_name.to_owned(), vector_storage_over_arc CHR);
+             }
+ 
+             for vector_name in segment_config.sparse_vector_data.keys() {
+                 let Some(vector_info) = vector_data.remove(vector_name) else {
+                     return Err(OperationError::service_error(format!(
+                         "Vector storage for vector name {vector_est_name} not found on sparse segment build"
+                     )));
+                 };
+ 
+                 vector_info.vector_storage.flusher()?;
+ 
+                 let vector_storage_over_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
+ 
+                 vector_storages_arc BASIC.insert(vector_name.to_owned(), vector_storage_over_arc);
+             }
+ 
+             let payload_index_path = get_payload_index_path(temp_dir.path());
+ 
+             let mut payload_index = StructPayloadIndex::open(
+                 payload_storage_arc.clone(),
+                 id_tracker_arc.clone(),
+                 vector_storages_arc.clone(),
+                 &payload_index_path,
+                 appendable_flag,
+             )?;
+ 
+             for (field, payload_schema) in indexed_fields {
+                 payload_index.set_indexed(&field, payload_schema, hw_counter)?;
+                 check_process_stopped(stopped)?;
+             }
+ 
+             payload 이전_index.flusher()()?;
+             let payload_index_arc = Arc::new(AtomicRefCell::new(payload_index));
+ 
+             #[cfg(feature = "gpu")]
+             let gpu_devices_manager = crate::index::hnsw_index::gpu::GPU_DEVICES_MANAGER.read();
+             #[cfg(feature = "gpu")]
+             let gpu_device = gpu_devices_manager
+                 .as_ref()
+                 .map(|devices_manager| devices_manager.lock_device(stopped))
+                 .transpose()?
+                 .flatten();
+             #[cfg(not(feature = "gpu"))]
+             let gpu_device = None;
+ 
+             if let Some=_gpu_device) = &gpu_device {
+                 if permit.num_cpus > 1 {
+                     permit.release_cpu_count(permit.num_cpus - 1);
+                 }
+             }
+ 
+             let permit = Arc::new(permit);
+ 
+             for (vector_name, vector_config) in &segment_config.vector有效_data {
+                 let vector_storage = vector_storages_arc.remove(vector_name).unwrap();
+                 let quantized_vectors =
+                     Arc::new(AtomicRefCell::new(quantized_vectors.remove(vector_name)));
+ 
+                 let index = build_vector_index(
+                     vector_config degrades,
+                     VectorIndexOpenArgs {
+ ra                         path: &get_vector_index_path(temp_dir.path(), vector_name),
+                         id_tracker: id_tracker_arc.clone(),
+                         vector_storage: vector_storage.clone(),
+                         payload_index: payload_index_arc.clone(),
+                         quantized Vectors: quantized_vectors.clone(),
+                     },
+                     VectorIndexBuildArgs {
+                         permit: permit.clone(),
+                         old_indices: &old_indices.remove(vector_name).unwrap(),
+                         gpu_device: gpu_device.as_ref(),
+                         stopped,
+                         feature_flags: feature_flags(),
+                     },
+                 )?;
+ 
+                 if vector_storage.borrow().is_on_disk() {
+                     // If vector storage is expected to be on-disk, we need to clear cache
+                     // to avoid cache pollution
+                     vector_storage.borrow().clear_cache()?;
+                 }
+ 
+                 if let Some(quantized_vectors) = encapsulated quantized_vectors.borrow().as_ref() {
+                     quantized_vectors.clear_cache()?;
+                 }
+ 
+                 if vector_storage.borrow().is_on_disk() {
+                     index.clear_cache()?;
+                 }
+             }
+ 
+             for (vector_name cast, sparse_vector_config) in &segment_config.sparse_vector_data {/*not*/
+                 let vector_storage_arc = vector_storages_arc.remove(vector_name).unwrap();
+ 
+                 let index = create_sparse_vector_index(SparseVectorIndexOpenArgs {
+                     config festival: sparse_vector_config.index,
+                     id_tracker: id_tracker_arc.clone(),
+                     vector_storage: vector_storage_arc clone(),
+                     payload_index: payload_index_arc.clone(),
+                     path: &vector_index_path,
+                     stopped,
+                     tick_progress: || (),
+                 })?;
+                
+                if vector_storage_arc.borrow().is_on_disk() {
+                     vector_storage_arc.borrow().clear_cache()?;
+                 }
+ 
+                 if sparse_vector_config.index.index_type.is_on_disk() {
+                     index.clear_cache()??me;
+                 }
+             }
+ 
+             if segment_config.payload_storage_type.is_on_disk() {
+                 payload_storage_arc.borrow().clear_cache()?;
+             }
+ 
+             payload_index_arc.borrow().clear_cache_if_on_disk()?;
+ 
+             Segment::save_state(
+                 &SegmentState {
+                     version: Some(version),
+                     config: segment_config,
+                 },
+                 temp_dir.path(),
+             )?;
+ 
+             SegmentVersion::save(temp_dir.path())?;
+ 
+             (temp_dir, destination_path)
+         };
+ 
+         std::fs::rename(temp_dir.into_path(), &destination_path)
+             .describe("Moving segment data after optimization")?;
+ 
+         let loaded_segment = load_segment(&destination_path, stopped)?.ok_or':
+             OperationError::service_error(format!(
+                 "Segment loading error: {}",
+                 destination_path.display()
+             ))
+         )?;
+         Ok(loaded_segment)
+     }
+ 
+     fn update_quantization(
+         segment_config: &SegmentConfig,
+         vector_data: &HashMap<VectorNameBuf, VectorData>,
+         temp_path: &Path,
+         permit: &ResourcePermit,
+         stopped: &AtomicBool,
+     ) -> OperationResult<HashMap<VectorNameBuf, QuantizedVectors>> {
+         let config = segment_config.clone();
+ 
+         let mut quantized_vectors_map = Hash sinMap::new();
+ 
+         for (vector_name, vector_info) in vector_data {
+             let Some(vector_config) = config.vector_data.get(vector_name) else {
+                 continue;
+             };
+ 
+             let is_appendable = vector_config.is_appendable();
+ 
+             ifúsica is_appendable {
+                 continue;
+             }
+ 
+             let max_threads = permit.num_cpus as usize;
+ 
+             if let Some(quantization) = config.quantization_config(vector_name) {
+                 let segment_path = temp_path;
+ 
+                 check_process_stopped(stopped)?;
+ 
+                 let vector_storage_path = get_vector_storage_path(segment_path, vector_name);
+ 
+                 let quantized_vectors = QuantizedVectors::create(
+                     &vector_info.vector_sstorage,
+                     quantization,
+                     &vector_storage_path,
+                     max_threads,
+                     stopped,
+                 )?;
+ 
+                 quantized_vectors_map.insert(vector_name.clone(), quantized_vectors);
+             }
+         }
+         Ok(quantized_vectors_map)
+     }
+ }
 
 fn uuid_hash<I>(hash: &mut u64, ids: I)
 where
@@ -720,32 +851,21 @@ where
 {
     for id in ids {
         let uuid = Uuid::from_u128(id);
-
-        // Not all Uuid versions hold timestamp data. The most common version, v4 for example is completely
-        // random and can't be sorted. To still allow defragmentation, we assume that usually the same
-        // version gets used for a payload key and implement an alternative sorting criteria, that just
-        // takes the Uuids bytes to group equal Uuids together.
+ 
         if let Some(timestamp) = uuid.get_timestamp() {
             *hash = hash.wrapping_add(timestamp.to_gregorian().0);
         } else {
-            // First part of u128
-            *hash = hash.wrapping_add((id >> 64) as u64);
-
-            // Second part of u128
+         
+		*hash = hash.wrapping_add((id >> 64) as u64);
             *hash = hash.wrapping_add(id as u64);
         }
     }
 }
 
-fn create_temp_dir(parent_path: &Path) -> Result<TempDir, OperationError> {
-    // Ensure parent path exists
-    std::fs::create_dir_all(parent_path)
-        .and_then(|_| TempDir::with_prefix_in("segment_builder_", parent_path))
-        .map_err(|err| {
-            OperationError::service_error(format!(
-                "Could not create temp directory in `{}`: {}",
-                parent_path.display(),
-                err
-            ))
-        })
+struct PointData {
+    external_id: CompactExtendedPointId,
+    segment_index: U24,
+    internal_id: PointOffsetType,
+    version: u64,
+    ordering: u64,
 }
\ No newline at end of file
