
index 8be5822c..481afd1f 100644
--- a/qdrant_lib_sparse_src_index_search_context.rs_expectedoutput.txt (expected):tmp/tmp90sxnvjo_expected.txt	
+++ b/qdrant_lib_sparse_src_index_search_context.rs_extracted.txt (actual):tmp/tmpqmtp_4_t_actual.txt	
@@ -23,20 +23,22 @@ pub struct IndexedPostingListIterator<T: PostingListIter> {
 /// Making this larger makes the search faster but uses more (pooled) memory
 const ADVANCE_BATCH_SIZE: usize = 10_000;
 
+/// SearchContext holds the state needed to perform a sparse-vector top-k search
 pub struct SearchContext<'a, 'b, T: PostingListIter = PostingListIterator<'a>> {
     postings_iterators: Vec<IndexedPostingListIterator<T>>,
     query: RemappedSparseVector,
     top: usize,
     is_stopped: &'a AtomicBool,
     top_results: TopK,
-    min_record_id: Option<PointOffsetType>, // min_record_id ids across all posting lists
-    max_record_id: PointOffsetType,         // max_record_id ids across all posting lists
-    pooled: PooledScoresHandle<'b>,         // handle to pooled scores
+    min_record_id: Option<PointOffsetType>,
+    max_record_id: PointOffsetType,
+    pooled: PooledScoresHandle<'b>,
     use_pruning: bool,
     hardware_counter: &'a HardwareCounterCell,
 }
 
 impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
+    /// Create a new search context for the given sparse query and inverted index.
     pub fn new(
         query: RemappedSparseVector,
         top: usize,
@@ -46,25 +48,19 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         hardware_counter: &'a HardwareCounterCell,
     ) -> SearchContext<'a, 'b, T> {
         let mut postings_iterators = Vec::new();
-        // track min and max record ids across all posting lists
+        // Track min and max record id across all postings
         let mut max_record_id = 0;
         let mut min_record_id = u32::MAX;
-        // iterate over query indices
+        // Build a posting-list iterator for each nonempty query dimension
         for (query_weight_offset, id) in query.indices.iter().enumerate() {
             if let Some(mut it) = inverted_index.get(*id, hardware_counter) {
                 if let (Some(first), Some(last_id)) = (it.peek(), it.last_id()) {
-                    // check if new min
-                    let min_record_id_posting = first.record_id;
-                    min_record_id = min(min_record_id, min_record_id_posting);
-
-                    // check if new max
-                    let max_record_id_posting = last_id;
-                    max_record_id = max(max_record_id, max_record_id_posting);
-
-                    // capture query info
+                    // Update global min/max record id
+                    min_record_id = min(min_record_id, first.record_id);
+                    max_record_id = max(max_record_id, last_id);
+                    // Record how to score from this posting list
                     let query_index = *id;
                     let query_weight = query.values[query_weight_offset];
-
                     postings_iterators.push(IndexedPostingListIterator {
                         posting_list_iterator: it,
                         query_index,
@@ -73,19 +69,18 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
                 }
             }
         }
+
         let top_results = TopK::new(top);
-        // Query vectors with negative values can NOT use the pruning mechanism which relies on the pre-computed `max_next_weight`.
-        // The max contribution per posting list that we calculate is not made to compute the max value of two negative numbers.
-        // This is a limitation of the current pruning implementation.
+        // We only prune when all query weights are nonnegative and the posting lists support max_next_weight
         let use_pruning = T::reliable_max_next_weight() && query.values.iter().all(|v| *v >= 0.0);
-        let min_record_id = Some(min_record_id);
+
         SearchContext {
             postings_iterators,
             query,
             top,
             is_stopped,
             top_results,
-            min_record_id,
+            min_record_id: Some(min_record_id),
             max_record_id,
             pooled,
             use_pruning,
@@ -95,178 +90,175 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
 
     const DEFAULT_SCORE: f32 = 0.0;
 
-    /// Plain search against the given ids without any pruning
+    /// Plain search over a list of explicit IDs, without using any posting-list merging or pruning.
+    /// Returns a Vec<ScoredPointOffset> of length <= ids.len(), in descending score order.
     pub fn plain_search(&mut self, ids: &[PointOffsetType]) -> Vec<ScoredPointOffset> {
-        // sort ids to fully leverage posting list iterator traversal
+        // sort IDs to traverse posting lists in increasing id order
         let mut sorted_ids = ids.to_vec();
         sorted_ids.sort_unstable();
 
         let cpu_counter = self.hardware_counter.cpu_counter();
-
         let mut indices = Vec::with_capacity(self.query.indices.len());
         let mut values = Vec::with_capacity(self.query.values.len());
+
         for id in sorted_ids {
-            // check for cancellation
             if self.is_stopped.load(Relaxed) {
                 break;
             }
-
             indices.clear();
             values.clear();
-            // collect indices and values for the current record id from the query's posting lists *only*
-            for posting_iterator in self.postings_iterators.iter_mut() {
-                // rely on underlying binary search as the posting lists are sorted by record id
-                match posting_iterator.posting_list_iterator.skip_to(id) {
-                    None => {} // no match for posting list
-                    Some(element) => {
-                        // match for posting list
-                        indices.push(posting_iterator.query_index);
-                        values.push(element.weight);
-                    }
+            // Gather matching weights from each posting-list iterator
+            for posting in self.postings_iterators.iter_mut() {
+                if let Some(element) = posting.posting_list_iterator.skip_to(id) {
+                    indices.push(posting.query_index);
+                    values.push(element.weight);
                 }
             }
-
             if values.is_empty() {
                 continue;
             }
+            // Measure CPU work: query length + returned vector length (in bytes of weights)
+            cpu_counter.incr_delta(self.query.indices.len() + values.len() * std::mem::size_of::<DimWeight>());
 
-            // Accumulate the sum of the length of the retrieved sparse vector and the query vector length
-            // as measurement for CPU usage of plain search.
-            cpu_counter
-                .incr_delta(self.query.indices.len() + values.len() * size_of::<DimWeight>());
-
-            // reconstruct sparse vector and score against query
-            let sparse_score =
-                score_vectors(&indices, &values, &self.query.indices, &self.query.values)
-                    .unwrap_or(Self::DEFAULT_SCORE);
-
-            self.top_results.push(ScoredPointOffset {
-                score: sparse_score,
-                idx: id,
-            });
+            // Score the resulting sparse vector against the query
+            let score = score_vectors(&indices, &values, &self.query.indices, &self.query.values)
+                .unwrap_or(Self::DEFAULT_SCORE);
+            self.top_results.push(ScoredPointOffset { score, idx: id });
         }
         let top = std::mem::take(&mut self.top_results);
         top.into_vec()
     }
 
-    /// Advance posting lists iterators in a batch fashion.
+    /// Advance through all postings in [batch_start_id ..= batch_last_id], accumulating scores in a pooled buffer.
     fn advance_batch<F: Fn(PointOffsetType) -> bool>(
         &mut self,
         batch_start_id: PointOffsetType,
         batch_last_id: PointOffsetType,
         filter_condition: &F,
     ) {
-        // init batch scores
-        let batch_len = batch_last_id - batch_start_id + 1;
-        self.pooled.scores.clear(); // keep underlying allocated memory
-        self.pooled.scores.resize(batch_len as usize, 0.0);
+        // Initialize batch scores
+        let batch_len = (batch_last_id - batch_start_id + 1) as usize;
+        let scores_buf = &mut self.pooled.scores;
+        scores_buf.clear();
+        scores_buf.resize(batch_len, 0.0);
 
+        // Traverse each posting list
         for posting in self.postings_iterators.iter_mut() {
             posting.posting_list_iterator.for_each_till_id(
                 batch_last_id,
-                self.pooled.scores.as_mut_slice(),
+                scores_buf.as_mut_slice(),
                 #[inline(always)]
-                |scores, id, weight| {
-                    let element_score = weight * posting.query_weight;
-                    let local_id = (id - batch_start_id) as usize;
-                    // SAFETY: `id` is within `batch_start_id..=batch_last_id`
-                    // Thus, `local_id` is within `0..batch_len`.
-                    *unsafe { scores.get_unchecked_mut(local_id) } += element_score;
+                |buf, record_id, weight| {
+                    let contrib = weight * posting.query_weight;
+                    let offset = (record_id - batch_start_id) as usize;
+                    // SAFETY: offset in [0..batch_len)
+                    unsafe { *buf.get_unchecked_mut(offset) += contrib };
                 },
             );
         }
 
-        for (local_index, &score) in self.pooled.scores.iter().enumerate() {
-            // publish only the non-zero scores above the current min to beat
-            if score != 0.0 && score > self.top_results.threshold() {
-                let real_id = batch_start_id + local_index as PointOffsetType;
-                // do not score if filter condition is not satisfied
-                if !filter_condition(real_id) {
-                    continue;
+        // Push qualified batch results
+        let threshold = if self.top_results.len() >= self.top {
+            self.top_results.threshold()
+        } else {
+            f32::MIN
+        };
+        for (i, &score) in scores_buf.iter().enumerate() {
+            if score != 0.0 && score > threshold {
+                let record_id = batch_start_id + i as PointOffsetType;
+                if filter_condition(record_id) {
+                    self.top_results.push(ScoredPointOffset { score, idx: record_id });
                 }
-                let score_point_offset = ScoredPointOffset {
-                    score,
-                    idx: real_id,
-                };
-                self.top_results.push(score_point_offset);
             }
         }
     }
 
-    /// Compute scores for the last posting list quickly
+    /// Quickly score the remaining elements of the single last posting list.
     fn process_last_posting_list<F: Fn(PointOffsetType) -> bool>(&mut self, filter_condition: &F) {
         debug_assert_eq!(self.postings_iterators.len(), 1);
         let posting = &mut self.postings_iterators[0];
         posting.posting_list_iterator.for_each_till_id(
             PointOffsetType::MAX,
             &mut (),
-            |_, id, weight| {
-                // do not score if filter condition is not satisfied
-                if !filter_condition(id) {
-                    return;
+            |(), record_id, weight| {
+                if filter_condition(record_id) {
+                    let score = weight * posting.query_weight;
+                    self.top_results.push(ScoredPointOffset { score, idx: record_id });
                 }
-                let score = weight * posting.query_weight;
-                self.top_results.push(ScoredPointOffset { score, idx: id });
             },
         );
     }
 
-    /// Returns the next min record id from all posting list iterators
-    ///
-    /// returns None if all posting list iterators are exhausted
-    fn next_min_id(to_inspect: &mut [IndexedPostingListIterator<T>]) -> Option<PointOffsetType> {
-        let mut min_record_id = None;
-
-        // Iterate to find min record id at the head of the posting lists
-        for posting_iterator in to_inspect.iter_mut() {
-            if let Some(next_element) = posting_iterator.posting_list_iterator.peek() {
-                match min_record_id {
-                    None => min_record_id = Some(next_element.record_id), // first record with matching id
-                    Some(min_id_seen) => {
-                        // update min record id if smaller
-                        if next_element.record_id < min_id_seen {
-                            min_record_id = Some(next_element.record_id);
-                        }
-                    }
-                }
+    /// Find the minimum next record_id among all posting-list iterators.
+    fn next_min_id(a: &mut [IndexedPostingListIterator<T>]) -> Option<PointOffsetType> {
+        let mut min_id = None;
+        for it in a.iter_mut() {
+            if let Some(peek) = it.posting_list_iterator.peek() {
+                min_id = Some(match min_id {
+                    None => peek.record_id,
+                    Some(curr) => min(curr, peek.record_id),
+                });
             }
         }
-
-        min_record_id
+        min_id
     }
 
-    /// Make sure the longest posting list is at the head of the posting list iterators
+    /// Promote the longest posting list to the front of `self.postings_iterators`.
     pub(crate) fn promote_longest_posting_lists_to_the_front(&mut self) {
-        // find index of longest posting list
-        let posting_index = self
+        if let Some((idx, _)) = self
             .postings_iterators
             .iter()
             .enumerate()
-            .max_by(|(_, a), (_, b)| {
-                a.posting_list_iterator
-                    .len_to_end()
-                    .cmp(&b.posting_list_iterator.len_to_end())
-            })
-            .map(|(index, _)| index);
-
-        if let Some(posting_index) = posting_index {
-            // make sure it is not already at the head
-            if posting_index != 0 {
-                // swap longest posting list to the head
-                self.postings_iterators.swap(0, posting_index);
+            .max_by_key(|(_, p)| p.posting_list_iterator.len_to_end())
+        {
+            if idx != 0 {
+                self.postings_iterators.swap(0, idx);
             }
         }
     }
 
-    /// How many elements are left in the posting list iterator
     #[cfg(test)]
     pub(crate) fn posting_list_len(&self, idx: usize) -> usize {
-        self.postings_iterators[idx]
-            .posting_list_iterator
-            .len_to_end()
+        self.postings_iterators[idx].posting_list_iterator.len_to_end()
+    }
+
+    /// Prune the head (longest) posting list if it cannot raise the minimum top-k score.
+    pub fn prune_longest_posting_list(&mut self, min_score: f32) -> bool {
+        if self.postings_iterators.is_empty() {
+            return false;
+        }
+        let (head, rest) = self.postings_iterators.split_at_mut(1);
+        let head = &mut head[0];
+        if let Some(peek) = head.posting_list_iterator.peek() {
+            let nxt = Self::next_min_id(rest);
+            if let Some(nid) = nxt {
+                match nid.cmp(&peek.record_id) {
+                    Ordering::Less | Ordering::Equal => return false,
+                    Ordering::Greater => {
+                        let max_w = peek.weight.max(peek.max_next_weight);
+                        let bound = max_w * head.query_weight;
+                        if bound <= min_score {
+                            let before = head.posting_list_iterator.current_index();
+                            head.posting_list_iterator.skip_to(nid);
+                            let after = head.posting_list_iterator.current_index();
+                            return before != after;
+                        }
+                    }
+                }
+            } else {
+                // only one posting list remains
+                let max_w = peek.weight.max(peek.max_next_weight);
+                let bound = max_w * head.query_weight;
+                if bound <= min_score {
+                    head.posting_list_iterator.skip_to_end();
+                    return true;
+                }
+            }
+        }
+        false
     }
 
-    /// Search for the top k results that satisfy the filter condition
+    /// Perform the full top-k merge with optional pruning and cancellation.
     pub fn search<F: Fn(PointOffsetType) -> bool>(
         &mut self,
         filter_condition: &F,
@@ -275,148 +267,53 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
             return Vec::new();
         }
 
-        {
-            // Measure CPU usage of indexed sparse search.
-            // Assume the complexity of the search as total volume of the posting lists
-            // that are traversed in the batched search.
-            let mut cpu_cost = 0;
-
-            for posting in self.postings_iterators.iter() {
-                cpu_cost += posting.posting_list_iterator.len_to_end()
-                    * posting.posting_list_iterator.element_size();
+        if self.use_pruning {
+            // charge CPU cost proportional to remaining posting-list volume
+            let mut cost = 0;
+            for p in &self.postings_iterators {
+                cost += p.posting_list_iterator.len_to_end()
+                    * p.posting_list_iterator.element_size();
             }
-            self.hardware_counter.cpu_counter().incr_delta(cpu_cost);
+            self.hardware_counter.cpu_counter().incr_delta(cost);
         }
 
-        let mut best_min_score = f32::MIN;
+        let mut best_min = f32::MIN;
         loop {
-            // check for cancellation (atomic amortized by batch)
             if self.is_stopped.load(Relaxed) {
                 break;
             }
-
-            // prepare next iterator of batched ids
-            let Some(start_batch_id) = self.min_record_id else {
-                break;
+            let start = match self.min_record_id {
+                Some(x) => x,
+                None => break,
             };
+            let end = min(start + ADVANCE_BATCH_SIZE as u32, self.max_record_id);
+            self.advance_batch(start, end, filter_condition);
 
-            // compute batch range of contiguous ids for the next batch
-            let last_batch_id = min(
-                start_batch_id + ADVANCE_BATCH_SIZE as u32,
-                self.max_record_id,
-            );
-
-            // advance and score posting lists iterators
-            self.advance_batch(start_batch_id, last_batch_id, filter_condition);
-
-            // remove empty posting lists if necessary
-            self.postings_iterators.retain(|posting_iterator| {
-                posting_iterator.posting_list_iterator.len_to_end() != 0
-            });
+            // drop exhausted postings
+            self.postings_iterators.retain(|it| it.posting_list_iterator.len_to_end() != 0);
 
-            // update min_record_id
-            self.min_record_id = Self::next_min_id(&mut self.postings_iterators);
-
-            // check if all posting lists are exhausted
             if self.postings_iterators.is_empty() {
                 break;
             }
-
-            // if only one posting list left, we can score it quickly
             if self.postings_iterators.len() == 1 {
                 self.process_last_posting_list(filter_condition);
                 break;
             }
-
-            // we potentially have enough results to prune low performing posting lists
             if self.use_pruning && self.top_results.len() >= self.top {
-                // current min score
-                let new_min_score = self.top_results.threshold();
-                if new_min_score == best_min_score {
-                    // no improvement in lowest best score since last pruning - skip pruning
-                    continue;
-                } else {
-                    best_min_score = new_min_score;
-                }
-                // make sure the first posting list is the longest for pruning
-                self.promote_longest_posting_lists_to_the_front();
-
-                // prune posting list that cannot possibly contribute to the top results
-                let pruned = self.prune_longest_posting_list(new_min_score);
-                if pruned {
-                    // update min_record_id
-                    self.min_record_id = Self::next_min_id(&mut self.postings_iterators);
-                }
-            }
-        }
-        // posting iterators exhausted, return result queue
-        let queue = std::mem::take(&mut self.top_results);
-        queue.into_vec()
-    }
-
-    /// Prune posting lists that cannot possibly contribute to the top results
-    /// Assumes longest posting list is at the head of the posting list iterators
-    /// Returns true if the longest posting list was pruned
-    pub fn prune_longest_posting_list(&mut self, min_score: f32) -> bool {
-        if self.postings_iterators.is_empty() {
-            return false;
-        }
-        // peek first element of longest posting list
-        let (longest_posting_iterator, rest_iterators) = self.postings_iterators.split_at_mut(1);
-        let longest_posting_iterator = &mut longest_posting_iterator[0];
-        if let Some(element) = longest_posting_iterator.posting_list_iterator.peek() {
-            let next_min_id_in_others = Self::next_min_id(rest_iterators);
-            match next_min_id_in_others {
-                Some(next_min_id) => {
-                    match next_min_id.cmp(&element.record_id) {
-                        Ordering::Equal => {
-                            // if the next min id in the other posting lists is the same as the current one,
-                            // we can't prune the current element as it needs to be scored properly across posting lists
-                            return false;
-                        }
-                        Ordering::Less => {
-                            // we can't prune as there the other posting lists contains smaller smaller ids that need to scored first
-                            return false;
-                        }
-                        Ordering::Greater => {
-                            // next_min_id is > element.record_id there is a chance to prune up to `next_min_id`
-                            // check against the max possible score using the `max_next_weight`
-                            // we can under prune as we should actually check the best score up to `next_min_id` - 1 only
-                            // instead of the max possible score but it is not possible to know the best score up to `next_min_id` - 1
-                            let max_weight_from_list = element.weight.max(element.max_next_weight);
-                            let max_score_contribution =
-                                max_weight_from_list * longest_posting_iterator.query_weight;
-                            if max_score_contribution <= min_score {
-                                // prune to next_min_id
-                                let longest_posting_iterator =
-                                    &mut self.postings_iterators[0].posting_list_iterator;
-                                let position_before_pruning =
-                                    longest_posting_iterator.current_index();
-                                longest_posting_iterator.skip_to(next_min_id);
-                                let position_after_pruning =
-                                    longest_posting_iterator.current_index();
-                                // check if pruning took place
-                                return position_before_pruning != position_after_pruning;
-                            }
-                        }
-                    }
-                }
-                None => {
-                    // the current posting list is the only one left, we can potentially skip it to the end
-                    // check against the max possible score using the `max_next_weight`
-                    let max_weight_from_list = element.weight.max(element.max_next_weight);
-                    let max_score_contribution =
-                        max_weight_from_list * longest_posting_iterator.query_weight;
-                    if max_score_contribution <= min_score {
-                        // prune to the end!
-                        let longest_posting_iterator = &mut self.postings_iterators[0];
-                        longest_posting_iterator.posting_list_iterator.skip_to_end();
-                        return true;
+                let thr = self.top_results.threshold();
+                if thr != best_min {
+                    best_min = thr;
+                    self.promote_longest_posting_lists_to_the_front();
+                    let pruned = self.prune_longest_posting_list(thr);
+                    if pruned {
+                        self.min_record_id = Self::next_min_id(&mut self.postings_iterators);
                     }
                 }
             }
+            self.min_record_id = Self::next_min_id(&mut self.postings_iterators);
         }
-        // no pruning took place
-        false
+
+        let out = std::mem::take(&mut self.top_results);
+        out.into_vec()
     }
 }
\ No newline at end of file
