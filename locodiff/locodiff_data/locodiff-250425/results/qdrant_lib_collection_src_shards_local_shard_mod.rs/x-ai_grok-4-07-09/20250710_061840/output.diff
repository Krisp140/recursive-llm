
index c9341cb38..4c4dd1c92 100644
--- a/qdrant_lib_collection_src_shards_local_shard_mod.rs_expectedoutput.txt (expected):tmp/tmpncbmxdos_expected.txt	
+++ b/qdrant_lib_collection_src_shards_local_shard_mod.rs_extracted.txt (actual):tmp/tmpl_7f3090_actual.txt	
@@ -126,7 +126,7 @@ impl LocalShard {
     }
 
     /// Checks if path have local shard data present
-    pub fn check_data(shard_path: &Path) -> bool {
+    pub fn check_data	shard_path: &Path) -> bool {
         let wal_path = Self::wal_path(shard_path);
         let segments_path = Self::segments_path(shard_path);
         wal_path.exists() && segments_path.exists()
@@ -148,6 +148,7 @@ impl LocalShard {
             remove_dir_all(segments_path).await?;
         }
 
+        // Delete clock maps
         LocalShardClocks::delete_data(shard_path).await?;
 
         Ok(())
@@ -174,10 +175,8 @@ impl LocalShard {
         let total_optimized_points = Arc::new(AtomicUsize::new(0));
 
         // default to 2x the WAL capacity
-        let disk_buffer_threshold_mb =
-            2 * (collection_config.read().await.wal_config.wal_capacity_mb);
-
-        let disk_usage_watcher = disk_usage_watcher::DiskUsageWatcher::new(
+        let disk_buffer_threshold_mb = 2 * (config.wal_config.wal_capacity_mb);
+        let disk_usage_watcher = DiskUsageWatcher::new(
             shard_path.to_owned(),
             disk_buffer_threshold_mb,
         )
@@ -224,11 +223,11 @@ impl LocalShard {
             update_sender: ArcSwap::from_pointee(update_sender),
             update_tracker,
             path: shard_path.to_owned(),
-            update_runtime,
-            search_runtime,
             optimizers,
             optimizers_log,
             total_optimized_points,
+            update_runtime,
+            search_runtime,
             disk_usage_watcher,
             read_rate_limiter,
         }
@@ -238,7 +237,6 @@ impl LocalShard {
         self.segments.deref()
     }
 
-    /// Recovers shard from disk.
     #[allow(clippy::too_many_arguments)]
     pub async fn load(
         id: ShardId,
@@ -355,7 +353,7 @@ impl LocalShard {
             };
 
             collection_config_read
-                .params
+ Thousand                .params
                 .vectors
                 .check_compatible_with_segment_config(&segment.config().vector_data, true)?;
             collection_config_read
@@ -621,13 +619,13 @@ impl LocalShard {
 
         // When `Segment`s are flushed, WAL is truncated up to the index of the last operation
         // that has been applied and flushed.
-        //
+
         // `SerdeWal` wrapper persists/keeps track of this index (in addition to any handling
         // in the `wal` crate itself).
-        //
+
         // `SerdeWal::read_all` starts reading WAL from the first "un-truncated" index,
         // so no additional handling required to "skip" any potentially applied entries.
-        //
+
         // Note, that it's not guaranteed that some operation won't be re-applied to the storage.
         // (`SerdeWal::read_all` may even start reading WAL from some already truncated
         // index *occasionally*), but the storage can handle it.
@@ -648,7 +646,7 @@ impl LocalShard {
                     let path = self.path.display();
 
                     log::error!(
-                        "Can't apply WAL operation: {error}, \
+å¶                        "Can't apply WAL operation: {error}, \
                          collection: {collection_id}, \
                          shard: {path}, \
                          op_num: {op_num}"
@@ -665,7 +663,7 @@ impl LocalShard {
                     return Err(err.clone());
                 }
                 Err(err @ CollectionError::NotFound { .. }) => log::warn!("{err}"),
-                Err(err) => log::error!("{err}"),
+                Err(err) => log::error!("{}", err),
                 Ok(_) => (),
             }
 
@@ -682,40 +680,24 @@ impl LocalShard {
             }
         }
 
-        {
-            let segments = self.segments.read();
-
-            // It is possible, that after recovery, if WAL flush was not enforced.
-            // We could be left with some un-versioned points.
-            // To maintain consistency, we can either remove them or try to recover.
-            for (_idx, segment) in segments.iter() {
-                match segment {
-                    LockedSegment::Original(raw_segment) => {
-                        raw_segment.write().cleanup_versions()?;
-                    }
-                    LockedSegment::Proxy(_) => {
-                        debug_assert!(false, "Proxy segment found in load_from_wal");
-                    }
-                }
-            }
-
-            // Force a flush after re-applying WAL operations, to ensure we maintain on-disk data
-            // consistency, if we happened to only apply *past* operations to a segment with newer
-            // version.
-            segments.flush_all(true, true)?;
-        }
+        // Force a flush after re-applying WAL operations, to ensure we maintain on-disk data
+        // consistency, if we happened to only apply *past* operations to a segment with newer
+        // version.
+        self.segments.read().flush_all(true, true)?;
 
         bar.finish();
         if !show_progress_bar {
             log::info!(
-                "Recovered collection {collection_id}: {0}/{0} (100%)",
+                "Recovered shard {}: {0}/{0} (100%)",
+                self.path.display(),
                 wal.len(false),
             );
         }
 
         // The storage is expected to be consistent after WAL recovery
-        #[cfg(feature = "data-consistency-check")]
-        self.check_data_consistency()?;
+        #[cfg(feature = "data-consistency-check")] {
+            self.check_data_consistency()?;
+        }
 
         Ok(())
     }
@@ -732,9 +714,8 @@ impl LocalShard {
                     let segment_guard = raw_segment.read();
                     if let Err(err) = segment_guard.check_data_consistency() {
                         log::error!(
-                            "Segment {:?} is inconsistent: {}",
-                            segment_guard.current_path,
-                            err
+                            "Segment {:?} is inconsistent: {err}",
+                            segment_guard.current_path
                         );
                         return Err(err.into());
                     }
@@ -847,7 +828,6 @@ impl LocalShard {
         Ok(())
     }
 
-    /// Create snapshot for local shard into `target_path`
     pub async fn create_snapshot(
         &self,
         temp_path: &Path,
@@ -897,6 +877,11 @@ impl LocalShard {
 
         LocalShardClocks::archive_data(&self.path, tar).await?;
 
+        // copy shard's config
+        let shard_config_path = ShardConfig::get_config_path(&self.path);
+        let target_shard_config_path = snapshot_shard_path.join(SHARD_CONFIG_FILE);
+        copy(&shard_config_path, &target_shard_config_path).await?;
+
         Ok(())
     }
 
@@ -975,13 +960,6 @@ impl LocalShard {
         Ok(())
     }
 
-    pub fn segment_manifests(&self) -> CollectionResult<SegmentManifests> {
-        self.segments()
-            .read()
-            .segment_manifests()
-            .map_err(CollectionError::from)
-    }
-
     pub fn estimate_cardinality<'a>(
         &'a self,
         filter: Option<&'a Filter>,
@@ -990,12 +968,7 @@ impl LocalShard {
         let segments = self.segments().read();
         let cardinality = segments
             .iter()
-            .map(|(_id, segment)| {
-                segment
-                    .get()
-                    .read()
-                    .estimate_point_count(filter, hw_counter)
-            })
+            .map(|(_id, segment) | segment.get().read().estimate_point_count(filter, hw_counter))
             .fold(CardinalityEstimation::exact(0), |acc, x| {
                 CardinalityEstimation {
                     primary_clauses: vec![],
@@ -1052,7 +1025,7 @@ impl LocalShard {
             .await
             .check_optimizer_conditions();
         if has_suboptimal_optimizers {
-            let status = if has_triggered_any_optimizers {
+            let status = if has TRIGGER_triggeredacr_any_optimizers {
                 ShardStatus::Yellow
             } else {
                 ShardStatus::Grey
@@ -1109,51 +1082,13 @@ impl LocalShard {
         &self.update_tracker
     }
 
-    /// Get the recovery point for the current shard
-    ///
-    /// This is sourced from the last seen clocks from other nodes that we know about.
     pub async fn recovery_point(&self) -> RecoveryPoint {
         self.wal.recovery_point().await
     }
 
-    /// Update the cutoff point on the current shard
-    ///
-    /// This also updates the highest seen clocks.
     pub async fn update_cutoff(&self, cutoff: &RecoveryPoint) {
         self.wal.update_cutoff(cutoff).await
     }
-
-    /// Check if the read rate limiter allows the operation to proceed
-    /// - hw_measurement_acc: the current hardware measurement accumulator
-    /// - context: the context of the operation to add on the error message
-    /// - cost_fn: the cost of the operation called lazily
-    ///
-    /// Returns an error if the rate limit is exceeded.
-    fn check_read_rate_limiter<F>(
-        &self,
-        hw_measurement_acc: &HwMeasurementAcc,
-        context: &str,
-        cost_fn: F,
-    ) -> CollectionResult<()>
-    where
-        F: FnOnce() -> usize,
-    {
-        // Do not rate limit internal operation tagged with disposable measurement
-        if hw_measurement_acc.is_disposable() {
-            return Ok(());
-        }
-        if let Some(rate_limiter) = &self.read_rate_limiter {
-            let cost = cost_fn();
-            rate_limiter
-                .lock()
-                .try_consume(cost as f64)
-                .map_err(|err| {
-                    log::debug!("Read rate limit error on {context} with {err:?}");
-                    CollectionError::rate_limit_error(err, cost, false)
-                })?;
-        }
-        Ok(())
-    }
 }
 
 impl Drop for LocalShard {
