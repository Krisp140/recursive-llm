use std::collections::{BTreeSet, HashMap};

#[allow(unused_imports)] // This import is used in tests and trait methods
use common::counter::hardware_counter::HardwareCounterCell;

use common::types::PointOffsetType;
use serde::{Deserialize, Serialize};

use crate::common::operation_error::OperationResult;
use crate::index::field_index::{CardinalityEstimation, PayloadBlockCondition, PrimaryCondition};
use crate::types::{FieldCondition, Match, PayloadKeyType};

use crate::index::field_index::full_text_index::immutable_inverted_index::ImmutableInvertedIndex;
use crate::index::field_index::full_text_index::mutable_inverted_index::MutableInvertedIndex;


pub type TokenId = u32;

#[derive(Default, Serialize, Deserialize, Debug, Clone)]
pub struct Document {
    tokens: Vec<TokenId>,
}

impl Document {
    pub fn new(mut tokens: Vec<TokenId>) -> Self {
        tokens.sort_unstable();
        Self { tokens }
    }

    pub fn len(&self) -> usize {
        self.tokens.len()
    }

    pub fn is_empty(&self) -> bool {
        self.tokens.is_empty()
    }

    pub fn tokens(&self) -> &[TokenId] {
        &self.tokens
    }

    pub fn check(&self, token: TokenId) -> bool {
        self.tokens.binary_search(&token).is_ok()
    }
}

#[derive(Debug, Clone)]
pub struct ParsedQuery {
    pub tokens: Vec<Option<TokenId>>,
}

impl ParsedQuery {
    pub fn check_match(&self, document: &Document) -> bool {
        if self.tokens.contains(&None) {
            return false;
        }

        // Check that all tokens are in document
        self.tokens
            .iter()
            // unwrap crash safety: all tokens exist in the vocabulary if it passes the above check
            .all(|query_token| document.check(query_token.unwrap()))
    }
}

// This helper function is used by the default trait method `document_from_tokens`
pub fn document_from_tokens_impl(
    vocab: &mut HashMap<String, TokenId>,
    tokens: &BTreeSet<String>,
) -> Document {
    let mut document_tokens = vec![];
    for token in tokens {
        // check if in vocab
        let vocab_idx = match vocab.get(token) {
            Some(&idx) => idx,
            None => {
                let next_token_id = vocab.len() as TokenId;
                 vocab.insert(token.to_string(), next_token_id);
                next_token_id
            }
        };
        document_tokens.push(vocab_idx);
    }

    Document::new(document_tokens)
}


pub trait InvertedIndex {
    fn get_vocab_mut(&mut self) -> &mut HashMap<String, TokenId>;

    fn document_from_tokens(&mut self, tokens: &BTreeSet<String>) -> Document {
        let vocab = self.get_vocab_mut();
        document_from_tokens_impl(vocab, tokens)
    }

    fn index_document(
        &mut self,
        idx: PointOffsetType,
        document: Document,
        hw_counter: &HardwareCounterCell,
    ) -> OperationResult<()>;

    fn remove_document(&mut self, idx: PointOffsetType) -> bool;

    fn filter<'a>(
        &'a self,
        query: ParsedQuery,
        hw_counter: &'a HardwareCounterCell,
    ) -> Box<dyn Iterator<Item = PointOffsetType> + 'a>;

    fn get_posting_len(
        &self,
        token_id: TokenId,
        hw_counter: &HardwareCounterCell,
    ) -> Option<usize>;

    fn estimate_cardinality(
        &self,
        query: &ParsedQuery,
        condition: &FieldCondition,
        hw_counter: &HardwareCounterCell,
    ) -> CardinalityEstimation {
        let points_count = self.points_count();

        let posting_lengths: Option<Vec<usize>> = query
            .tokens
            .iter()
            .map(|&vocab_idx| match vocab_idx {
                None => None,
                Some(idx) => self.get_posting_len(idx, hw_counter),
            })
            .collect();
        if posting_lengths.is_none() || points_count == 0 {
            // There are unseen tokens -> no matches
            return CardinalityEstimation {
                primary_clauses: vec![PrimaryCondition::Condition(Box::new(condition.clone()))],
                min: 0,
                exp: 0,
                max: 0,
            };
        }
        let postings = posting_lengths.unwrap();
        if postings.is_empty() {
            // Empty request -> no matches
            return CardinalityEstimation {
                primary_clauses: vec![PrimaryCondition::Condition(Box::new(condition.clone()))],
                min: 0,
                exp: 0,
                max: 0,
            };
        }
        // Smallest posting is the largest possible cardinality
        let smallest_posting = postings.iter().min().copied().unwrap();

        if postings.len() == 1 {
            CardinalityEstimation {
                primary_clauses: vec![PrimaryCondition::Condition(Box::new(condition.clone()))],
                min: smallest_posting,
                exp: smallest_posting,
                max: smallest_posting,
            }
        } else {
            let expected_frac: f64 = postings
                .iter()
                .map(|posting| *posting as f64 / points_count as f64)
                .product();
            let exp = (expected_frac * points_count as f64) as usize;
            CardinalityEstimation {
                primary_clauses: vec![PrimaryCondition::Condition(Box::new(condition.clone()))],
                min: 0, // ToDo: make better estimation
                exp,
                max: smallest_posting,
            }
        }
    }

    fn vocab_with_postings_len_iter(&self) -> impl Iterator<Item = (&str, usize)> + '_;

    fn payload_blocks(
        &self,
        threshold: usize,
        key: PayloadKeyType,
    ) -> impl Iterator<Item = PayloadBlockCondition> + '_ {
        let map_filter_condition = move |(token, postings_len): (&str, usize)| {
            if postings_len >= threshold {
                Some(PayloadBlockCondition {
                    condition: FieldCondition::new_match(key.clone(), Match::new_text(token)),
                    cardinality: postings_len,
                })
            } else {
                None
            }
        };

        // It might be very hard to predict possible combinations of conditions,
        // so we only build it for individual tokens
        self.vocab_with_postings_len_iter()
            .filter_map(map_filter_condition)
    }

    fn check_match(
        &self,
        parsed_query: &ParsedQuery,
        point_id: PointOffsetType,
    ) -> bool;

    fn values_is_empty(&self, point_id: PointOffsetType) -> bool;

    fn values_count(&self, point_id: PointOffsetType) -> usize;

    fn points_count(&self) -> usize;

    fn get_token_id(&self, token: &str, hw_counter: &HardwareCounterCell) -> Option<TokenId>;
}


// The enum itself is defined in this file and implements the trait. The impl block is not here.
pub enum InvertedIndex {
    Mutable(MutableInvertedIndex),
    Immutable(ImmutableInvertedIndex),
}

impl InvertedIndex {
    pub fn new(is_appendable: bool) -> InvertedIndex {
        if is_appendable {
            InvertedIndex::Mutable(MutableInvertedIndex::default())
        } else {
            InvertedIndex::Immutable(ImmutableInvertedIndex::default())
        }
    }
}


#[cfg(test)]
mod tests {
    use std::collections::BTreeSet;
    use std::path::Path;

    use common::counter::hardware_counter::HardwareCounterCell;
    use rand::Rng;
    use rand::seq::SliceRandom;
    use rstest::rstest;

    use crate::index::field_index::full_text_index::immutable_inverted_index::ImmutableInvertedIndex;
    use crate::index::field_index::full_text_index::mmap_inverted_index::MmapInvertedIndex;
    use crate::index::field_index::full_text_index::mutable_inverted_index::MutableInvertedIndex;

    // Import types from the parent module explicitly
    use super::{Document, ParsedQuery, TokenId, document_from_tokens_impl};

    fn generate_word() -> String {
        let mut rng = rand::rng();

        // Each word is 1 to 3 characters long
        let len = rng.random_range(1..=3);
        rng.sample_iter(rand::distr::Alphanumeric)
            .take(len)
            .map(char::from)
            .collect()
    }

    fn generate_query() -> Vec<String> {
        let mut rng = rand::rng();
        let len = rng.random_range(1..=2);
        (0..len).map(|_| generate_word()).collect()
    }

    fn to_parsed_query(
        query: Vec<String>,
        token_to_id: impl Fn(String) -> Option<TokenId>,
    ) -> ParsedQuery {
        let tokens: Vec<_> = query.into_iter().map(token_to_id).collect();
        ParsedQuery { tokens }
    }

    // mutable_inverted_index is a helper to generate a MutableInvertedIndex
    fn mutable_inverted_index(indexed_count: u32, deleted_count: u32) -> MutableInvertedIndex {
        let mut index = MutableInvertedIndex::default();

        let hw_counter = HardwareCounterCell::new(); // Needed for index_document

        for idx in 0..indexed_count {
            // Generate 10 tot 30-word documents
            let doc_len = rand::rng().random_range(10..=30);
            let tokens: BTreeSet<String> = (0..doc_len).map(|_| generate_word()).collect();
            let document = document_from_tokens_impl(&mut index.vocab, &tokens); // Use the helper function
            index.index_document(idx, document, &hw_counter).unwrap(); // Pass hw_counter
        }

        // Remove some points
        let mut points_to_delete = (0..indexed_count).collect::<Vec<_>>();
        points_to_delete.shuffle(&mut rand::rng());
        for idx in &points_to_delete[..deleted_count as usize] {
            index.remove_document(*idx);
        }

        index
    }

    #[test]
    fn test_mutable_to_immutable() {
        let mutable = mutable_inverted_index(2000, 400);

        let immutable = ImmutableInvertedIndex::from(mutable.clone()); // Immutable passed by cloned value

        assert!(immutable.vocab.len() < mutable.vocab.len());
        assert!(immutable.postings.len() < mutable.postings.len());
        assert!(!immutable.vocab.is_empty());

        let hw_counter = HardwareCounterCell::new(); // Needed for posting iter/reader

        // Check that new vocabulary token ids leads to the same posting lists
        assert!({
            immutable.vocab.iter().all(|(key, new_token)| {
                let new_posting = immutable
                    .postings
                    .get(*new_token as usize)
                    .cloned()
                    .unwrap();

                let orig_token = mutable.vocab.get(key).unwrap();

                let orig_posting = mutable
                    .postings
                    .get(*orig_token as usize)
                    .cloned()
                    .unwrap()
                    .unwrap();

                let new_contains_orig = orig_posting
                    .iter()
                    .all(|point_id| new_posting.reader().contains(point_id)); // Use reader().contains() implies CompressedPostingList has a reader() method

                let orig_contains_new = new_posting
                    .iter() // hw_counter removed from iter in 56a7cfdb205f90df28d2816d9e8ef6251fc517a2
                    .all(|point_id| orig_posting.contains(point_id));

                new_contains_orig && orig_contains_new
            })
        });
    }

    #[rstest]
    #[case(2000, 400)]
    #[case(2000, 2000)]
    #[case(1111, 1110)]
    #[case(1111, 0)]
    #[case(10, 2)]
    #[case(0, 0)]
    fn test_immutable_to_mmap(#[case] indexed_count: u32, #[case] deleted_count: u32) {
        let mutable = mutable_inverted_index(indexed_count, deleted_count);
        let immutable = ImmutableInvertedIndex::from(mutable);

        let path = tempfile::tempdir().unwrap().into_path();

        // Ensure the directory exists for Mmap creation
        std::fs::create_dir_all(&path).unwrap();

        MmapInvertedIndex::create(&path, immutable.clone()).unwrap(); // Immutable passed by cloned value

        let hw_counter = HardwareCounterCell::new(); // Needed for mmap interaction

        let mmap = MmapInvertedIndex::open(&path, false).unwrap(); // Takes path and populate bool

        // Check same vocabulary
        for (token, token_id) in immutable.vocab.iter() {
            assert_eq!(mmap.get_token_id(token, &hw_counter), Some(*token_id)); // Pass hw_counter
        }

        // Check same postings
        for (token_id, posting) in immutable.postings.iter().enumerate() {
            let chunk_reader = mmap.postings.get(token_id as u32, &hw_counter).unwrap(); // Pass hw_counter

            for point_id in posting.iter() { // hw_counter removed from iter in 56a7cfdb205f90df28d2816d9e8ef6251fc517a2
                assert!(chunk_reader.contains(point_id));
            }
        }

        for (point_id, count) in immutable.point_to_tokens_count.iter().enumerate() {
            // Check same deleted points
            // Check size_of PointOffsetType vs u32 logic here. MmapBitSlice uses u32 index.
            assert_eq!(
                mmap.deleted_points.get(point_id as u32),
                count.is_none(),
                "point_id: {point_id}"
            );

            // Check same count
            // MmapVector takes u32 index
            assert_eq!(
                *mmap.point_to_tokens_count.get(point_id as u32),
                count.unwrap_or(0)
            );
        }

        // Check same points count
        assert_eq!(mmap.active_points_count, immutable.points_count);
    }

    #[test]
    fn test_mmap_index_congruence() {
        let indexed_count = 10000;
        let deleted_count = 500;

        let mut mutable = mutable_inverted_index(indexed_count, deleted_count);
        let immutable = ImmutableInvertedIndex::from(mutable.clone()); // Immutable passed by cloned value

        let path = tempfile::tempdir().unwrap().into_path();

        // Ensure the directory exists for Mmap creation
        std::fs::create_dir_all(&path).unwrap();

        MmapInvertedIndex::create(&path, immutable).unwrap(); // Immutable passed by value

        let hw_counter = HardwareCounterCell::new(); // Needed for mmap interaction

        let mut mmap_index = MmapInvertedIndex::open(&path, false).unwrap(); // Takes path and populate bool

        let queries: Vec<_> = (0..100).map(|_| generate_query()).collect();

        let mut_parsed_queries: Vec<_> = queries
            .clone()
            .into_iter()
            .map(|query| to_parsed_query(query, |token| mutable.vocab.get(&token).copied()))
            .collect();

        let imm_parsed_queries: Vec<_> = queries
            .into_iter()
            .map(|query| {
                to_parsed_query(query, |token| mmap_index.get_token_id(&token, &hw_counter)) // Pass hw_counter
            })
            .collect();

        for (mut_query, imm_query) in mut_parsed_queries
            .iter()
            .cloned()
            .zip(imm_parsed_queries.iter().cloned())
        {
            let mut_filtered = mutable.filter(mut_query, &hw_counter).collect::<Vec<_>>(); // Pass hw_counter, query by value
            let imm_filtered = mmap_index
                .filter(imm_query, &hw_counter) // Pass hw_counter, query by value
                .collect::<Vec<_>>();

            assert_eq!(mut_filtered, imm_filtered);
        }

        // Delete random documents from both indexes

        let points_to_delete: Vec<_> = (0..deleted_count)
            .map(|_| rand::rng().random_range(0..indexed_count))
            .collect();

        for point_id in &points_to_delete {
            mutable.remove_document(*point_id);
            mmap_index.remove_document(*point_id); // mmap_index removes document
        }

        // Check congruence after deletion

        for (mut_query, imm_query) in mut_parsed_queries
            .iter()
            .cloned()
            .zip(imm_parsed_queries.iter().cloned())
        {
            let mut_filtered = mutable.filter(mut_query, &hw_counter).collect::<Vec<_>>(); // Pass hw_counter, query by value
            let imm_filtered = mmap_index
                .filter(imm_query, &hw_counter) // Pass hw_counter, query by value
                .collect::<Vec<_>>();

            assert_eq!(mut_filtered, imm_filtered);
        }
    }
}