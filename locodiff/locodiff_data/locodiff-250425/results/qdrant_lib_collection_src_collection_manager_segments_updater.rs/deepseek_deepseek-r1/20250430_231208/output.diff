
index 3c0816e9..f44968bb 100644
--- a/qdrant_lib_collection_src_collection_manager_segments_updater.rs_expectedoutput.txt (expected):tmp/tmpb0809hte_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_segments_updater.rs_extracted.txt (actual):tmp/tmpp0xn__3f_actual.txt	
@@ -1,5 +1,3 @@
-//! A collection of functions for updating points and payloads stored in segments
-
 use std::sync::atomic::AtomicBool;
 
 use ahash::{AHashMap, AHashSet};
@@ -17,13 +15,13 @@ use segment::types::{
 };
 
 use crate::collection_manager::holders::segment_holder::SegmentHolder;
-use crate::operations::FieldIndexOperations;
 use crate::operations::payload_ops::PayloadOps;
 use crate::operations::point_ops::{
     PointInsertOperationsInternal, PointOperations, PointStructPersisted,
 };
 use crate::operations::types::{CollectionError, CollectionResult};
 use crate::operations::vector_ops::{PointVectorsPersisted, VectorOperations};
+use crate::operations::FieldIndexOperations;
 
 pub(crate) fn check_unprocessed_points(
     points: &[PointIdType],
@@ -37,7 +35,6 @@ pub(crate) fn check_unprocessed_points(
     }
 }
 
-/// Tries to delete points from all segments, returns number of actually deleted points
 pub(crate) fn delete_points(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
@@ -46,7 +43,7 @@ pub(crate) fn delete_points(
 ) -> CollectionResult<usize> {
     let mut total_deleted_points = 0;
 
-    for batch in ids.chunks(VECTOR_OP_BATCH_SIZE) {
+    for batch in ids.chunks(512) {
         let deleted_points = segments.apply_points(
             batch,
             |_| (),
@@ -59,14 +56,12 @@ pub(crate) fn delete_points(
     Ok(total_deleted_points)
 }
 
-/// Update the specified named vectors of a point, keeping unspecified vectors intact.
 pub(crate) fn update_vectors(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
     points: Vec<PointVectorsPersisted>,
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<usize> {
-    // Build a map of vectors to update per point, merge updates on same point ID
     let mut points_map: AHashMap<PointIdType, NamedVectors> = AHashMap::new();
     for point in points {
         let PointVectorsPersisted { id, vector } = point;
@@ -79,7 +74,7 @@ pub(crate) fn update_vectors(
     let ids: Vec<PointIdType> = points_map.keys().copied().collect();
 
     let mut total_updated_points = 0;
-    for batch in ids.chunks(VECTOR_OP_BATCH_SIZE) {
+    for batch in ids.chunks(512) {
         let updated_points = segments.apply_points_with_conditional_move(
             op_num,
             batch,
@@ -102,9 +97,6 @@ pub(crate) fn update_vectors(
     Ok(total_updated_points)
 }
 
-const VECTOR_OP_BATCH_SIZE: usize = 512;
-
-/// Delete the given named vectors for the given points, keeping other vectors intact.
 pub(crate) fn delete_vectors(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
@@ -113,7 +105,7 @@ pub(crate) fn delete_vectors(
 ) -> CollectionResult<usize> {
     let mut total_deleted_points = 0;
 
-    for batch in points.chunks(VECTOR_OP_BATCH_SIZE) {
+    for batch in points.chunks(512) {
         let deleted_points = segments.apply_points(
             batch,
             |_| (),
@@ -132,7 +124,6 @@ pub(crate) fn delete_vectors(
     Ok(total_deleted_points)
 }
 
-/// Delete the given named vectors for points matching the given filter, keeping other vectors intact.
 pub(crate) fn delete_vectors_by_filter(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
@@ -144,7 +135,6 @@ pub(crate) fn delete_vectors_by_filter(
     delete_vectors(segments, op_num, &affected_points, vector_names)
 }
 
-/// Batch size when modifying payload.
 const PAYLOAD_OP_BATCH_SIZE: usize = 512;
 
 pub(crate) fn overwrite_payload(
@@ -226,7 +216,6 @@ fn points_by_filter(
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<Vec<PointIdType>> {
     let mut affected_points: Vec<PointIdType> = Vec::new();
-    // we don’t want to cancel this filtered read
     let is_stopped = AtomicBool::new(false);
     segments.for_each_segment(|s| {
         let points = s.read_filtered(None, None, Some(filter), &is_stopped, hw_counter);
@@ -325,7 +314,6 @@ pub(crate) fn clear_payload(
     Ok(total_updated_points)
 }
 
-/// Clear Payloads from all segments matching the given filter
 pub(crate) fn clear_payload_by_filter(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
@@ -370,12 +358,6 @@ pub(crate) fn delete_field_index(
         .map_err(Into::into)
 }
 
-/// Upsert to a point ID with the specified vectors and payload in the given segment.
-///
-/// Returns
-/// - Ok(true) if the operation was successful and point replaced existing value
-/// - Ok(false) if the operation was successful and point was inserted
-/// - Err if the operation failed
 fn upsert_with_payload(
     segment: &mut RwLockWriteGuard<dyn SegmentEntry>,
     op_num: SeqNumberType,
@@ -391,16 +373,6 @@ fn upsert_with_payload(
     Ok(res)
 }
 
-/// Sync points within a given [from_id; to_id) range.
-///
-/// 1. Retrieve existing points for a range
-/// 2. Remove points, which are not present in the sync operation
-/// 3. Retrieve overlapping points, detect which one of them are changed
-/// 4. Select new points
-/// 5. Upsert points which differ from the stored ones
-///
-/// Returns:
-///     (number of deleted points, number of new points, number of updated points)
 pub(crate) fn sync_points(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
@@ -411,22 +383,18 @@ pub(crate) fn sync_points(
 ) -> CollectionResult<(usize, usize, usize)> {
     let id_to_point: AHashMap<PointIdType, _> = points.iter().map(|p| (p.id, p)).collect();
     let sync_points: AHashSet<_> = points.iter().map(|p| p.id).collect();
-    // 1. Retrieve existing points for a range
     let stored_point_ids: AHashSet<_> = segments
         .iter()
         .flat_map(|(_, segment)| segment.get().read().read_range(from_id, to_id))
         .collect();
-    // 2. Remove points, which are not present in the sync operation
     let points_to_remove: Vec<_> = stored_point_ids.difference(&sync_points).copied().collect();
     let deleted = delete_points(segments, op_num, points_to_remove.as_slice(), hw_counter)?;
-    // 3. Retrieve overlapping points, detect which one of them are changed
     let existing_point_ids: Vec<_> = stored_point_ids
         .intersection(&sync_points)
         .copied()
         .collect();
 
     let mut points_to_update: Vec<_> = Vec::new();
-    // we don’t want to cancel this filtered read
     let is_stopped = AtomicBool::new(false);
     let _num_updated =
         segments.read_points(existing_point_ids.as_slice(), &is_stopped, |id, segment| {
@@ -454,27 +422,19 @@ pub(crate) fn sync_points(
             }
         })?;
 
-    // 4. Select new points
-    let num_updated = points_to_update.len();
     let mut num_new = 0;
-    sync_points.difference(&stored_point_ids).for_each(|id| {
-        num_new += 1;
-        points_to_update.push(*id_to_point.get(id).unwrap());
-    });
+    sync_points
+        .difference(&stored_point_ids)
+        .copied()
+        .for_each(|id| {
+            num_new += 1;
+            points_to_update.push(*id_to_point.get(&id).unwrap());
+        });
 
-    // 5. Upsert points which differ from the stored ones
     let num_replaced = upsert_points(segments, op_num, points_to_update, hw_counter)?;
-    debug_assert!(
-        num_replaced <= num_updated,
-        "number of replaced points cannot be greater than points to update ({num_replaced} <= {num_updated})",
-    );
-
-    Ok((deleted, num_new, num_updated))
+    Ok((deleted, num_new, num_replaced))
 }
 
-/// Checks point id in each segment, update point if found.
-/// All not found points are inserted into random segment.
-/// Returns: number of updated points.
 pub(crate) fn upsert_points<'a, T>(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
@@ -487,18 +447,16 @@ where
     let points_map: AHashMap<PointIdType, _> = points.into_iter().map(|p| (p.id, p)).collect();
     let ids: Vec<PointIdType> = points_map.keys().copied().collect();
 
-    // Update points in writable segments
     let updated_points = segments.apply_points_with_conditional_move(
         op_num,
         &ids,
         |id, write_segment| {
-            let point = points_map[&id];
             upsert_with_payload(
                 write_segment,
                 op_num,
                 id,
-                point.get_vectors(),
-                point.payload.as_ref(),
+                points_map[&id].get_vectors(),
+                points_map[&id].payload.as_ref(),
                 hw_counter,
             )
         },
@@ -516,7 +474,6 @@ where
     )?;
 
     let mut res = updated_points.len();
-    // Insert new points, which was not updated or existed
     let new_point_ids = ids.iter().copied().filter(|x| !updated_points.contains(x));
 
     {
@@ -703,10 +660,8 @@ pub(crate) fn process_field_index_operation(
     }
 }
 
-/// Max amount of points to delete in a batched deletion iteration.
 const DELETION_BATCH_SIZE: usize = 512;
 
-/// Deletes points from all segments matching the given filter
 pub(crate) fn delete_points_by_filter(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
@@ -714,7 +669,6 @@ pub(crate) fn delete_points_by_filter(
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<usize> {
     let mut total_deleted = 0;
-    // we don’t want to cancel this filtered read
     let is_stopped = AtomicBool::new(false);
     let mut points_to_delete: AHashMap<_, _> = segments
         .iter()
