
index 8096e53f..7b95f7ff 100644
--- a/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_expectedoutput.txt (expected):tmp/tmppebtyqvi_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_extracted.txt (actual):tmp/tmpcjsfbky0_actual.txt	
@@ -1,10 +1,5 @@
-use std::collections::BTreeSet;
-use std::collections::hash_map::Entry;
-use std::sync::Arc;
-use std::sync::atomic::AtomicBool;
-
-use ahash::AHashMap;
 use common::counter::hardware_accumulator::HwMeasurementAcc;
+use common::counter::hardware_counter::HardwareCounterCell;
 use common::types::ScoreType;
 use futures::stream::FuturesUnordered;
 use futures::{FutureExt, TryStreamExt};
@@ -22,6 +17,11 @@ use tinyvec::TinyVec;
 use tokio::runtime::Handle;
 use tokio::task::JoinHandle;
 
+use std::collections::hash_map::Entry;
+use std::collections::{BTreeSet, HashMap};
+use std::sync::Arc;
+use std::sync::atomic::AtomicBool;
+
 use super::holders::segment_holder::LockedSegmentHolder;
 use crate::collection_manager::holders::segment_holder::LockedSegment;
 use crate::collection_manager::probabilistic_search_sampling::find_search_sampling_over_point_distribution;
@@ -29,10 +29,9 @@ use crate::collection_manager::search_result_aggregator::BatchResultAggregator;
 use crate::common::stopping_guard::StoppingGuard;
 use crate::config::CollectionConfigInternal;
 use crate::operations::query_enum::QueryEnum;
-use crate::operations::types::{
-    CollectionResult, CoreSearchRequestBatch, Modifier, RecordInternal,
-};
+use crate::operations::types::{CollectionResult, CoreSearchRequestBatch, Modifier, RecordInternal};
 use crate::optimizers_builder::DEFAULT_INDEXING_THRESHOLD_KB;
+use ahash::AHashMap;
 
 type BatchOffset = usize;
 type SegmentOffset = usize;
@@ -219,6 +218,7 @@ impl SegmentsSearcher {
         // Do blocking calls in a blocking task: `segment.get().read()` calls might block async runtime
         let task = {
             let segments = segments.clone();
+            let mut query_context = query_context;
 
             tokio::task::spawn_blocking(move || {
                 let segments = segments.read();
@@ -246,6 +246,7 @@ impl SegmentsSearcher {
         runtime_handle: &Handle,
         sampling_enabled: bool,
         query_context: QueryContext,
+        hw_measurement_acc: &HwMeasurementAcc,
     ) -> CollectionResult<Vec<Vec<ScoredPoint>>> {
         let query_context_arc = Arc::new(query_context);
 
@@ -270,19 +271,25 @@ impl SegmentsSearcher {
             segments
                 .map(|segment| {
                     let query_context_arc_segment = query_context_arc.clone();
+                    let hw_collector = hw_measurement_acc.new_collector();
 
                     let search = runtime_handle.spawn_blocking({
-                        let (segment, batch_request) = (segment.clone(), batch_request.clone());
+                        let (segment, batch_request) = (segment, batch_request.clone());
                         move || {
                             let segment_query_context =
                                 query_context_arc_segment.get_segment_query_context();
 
-                            search_in_segment(
+                            let res = search_in_segment(
                                 segment,
                                 batch_request,
                                 use_sampling,
                                 &segment_query_context,
-                            )
+                            );
+
+                            hw_collector
+                                .merge_from_cell(segment_query_context.take_hardware_counter());
+
+                            res
                         }
                     });
                     (segment, search)
@@ -301,7 +308,7 @@ impl SegmentsSearcher {
             batch_request
                 .searches
                 .iter()
-                .map(|request| request.limit + request.offset)
+                .map(|request| request.limit.unwrap_or(0) + request.offset.unwrap_or(0))
                 .collect(),
             &further_results,
         );
@@ -314,7 +321,7 @@ impl SegmentsSearcher {
                 searches_to_rerun.into_iter().collect();
 
             let secondary_searches: Vec<_> = {
-                let mut res = vec![];
+                let mut res = Vec::with_capacity(searches_to_rerun.len());
                 for (segment_id, batch_ids) in searches_to_rerun.iter() {
                     let query_context_arc_segment = query_context_arc.clone();
                     let segment = locked_segments[*segment_id].clone();
@@ -324,17 +331,22 @@ impl SegmentsSearcher {
                             .map(|batch_id| batch_request.searches[*batch_id].clone())
                             .collect(),
                     });
+                    let hw_collector = hw_measurement_acc.new_collector();
 
                     res.push(runtime_handle.spawn_blocking(move || {
                         let segment_query_context =
                             query_context_arc_segment.get_segment_query_context();
 
-                        search_in_segment(
+                        let result = search_in_segment(
                             segment,
                             partial_batch_request,
                             false,
                             &segment_query_context,
-                        )
+                        );
+
+                        hw_collector.merge_from_cell(segment_query_context.take_hardware_counter());
+
+                        result
                     }))
                 }
                 res
@@ -352,13 +364,12 @@ impl SegmentsSearcher {
 
             for ((_segment_id, batch_ids), segments_result) in searches_to_rerun
                 .into_iter()
-                .zip(secondary_search_results_per_segment.into_iter())
+                .zip(secondary_search_results_per_segment)
             {
                 for (batch_id, secondary_batch_result) in
-                    batch_ids.into_iter().zip(segments_result.into_iter())
+                    batch_ids.into_iter().zip(segments_result)
                 {
-                    result_aggregator
-                        .update_batch_results(batch_id, secondary_batch_result.into_iter());
+                    result_aggregator.update_batch_results(batch_id, secondary_batch_result);
                 }
             }
         }
@@ -385,12 +396,12 @@ impl SegmentsSearcher {
         let stopping_guard = StoppingGuard::new();
         runtime_handle
             .spawn_blocking({
-                let segments = segments.clone();
+                let segments = segments;
                 let points = points.to_vec();
                 let with_payload = with_payload.clone();
                 let with_vector = with_vector.clone();
                 let is_stopped = stopping_guard.get_is_stopped();
-                // TODO create one Task per segment level retrieve
+                // TODO create one Task per segment level retrieve - needs to re-check
                 move || {
                     Self::retrieve_blocking(
                         segments,
@@ -480,36 +491,6 @@ impl SegmentsSearcher {
         Ok(point_records)
     }
 
-    pub async fn read_filtered(
-        segments: LockedSegmentHolder,
-        filter: Option<&Filter>,
-        runtime_handle: &Handle,
-        hw_measurement_acc: HwMeasurementAcc,
-    ) -> CollectionResult<BTreeSet<PointIdType>> {
-        let stopping_guard = StoppingGuard::new();
-        let filter = filter.cloned();
-        runtime_handle
-            .spawn_blocking(move || {
-                let is_stopped = stopping_guard.get_is_stopped();
-                let segments = segments.read();
-                let hw_counter = hw_measurement_acc.get_counter_cell();
-                let all_points: BTreeSet<_> = segments
-                    .non_appendable_then_appendable_segments()
-                    .flat_map(|segment| {
-                        segment.get().read().read_filtered(
-                            None,
-                            None,
-                            filter.as_ref(),
-                            &is_stopped,
-                            &hw_counter,
-                        )
-                    })
-                    .collect();
-                Ok(all_points)
-            })
-            .await?
-    }
-
     /// Rescore results with a formula that can reference payload values.
     ///
     /// Aggregates rescores from the segments.
@@ -543,7 +524,7 @@ impl SegmentsSearcher {
 
         let mut segments_results = Vec::with_capacity(futures.len());
         while let Some(result) = futures.try_next().await? {
-            segments_results.push(result?)
+            segments_results.push(result?);
         }
 
         // use aggregator with only one "batch"
@@ -557,6 +538,36 @@ impl SegmentsSearcher {
 
         Ok(top)
     }
+
+    pub async fn read_filtered(
+        segments: LockedSegmentHolder,
+        filter: Option<&Filter>,
+        runtime_handle: &Handle,
+        hw_measurement_acc: HwMeasurementAcc,
+    ) -> CollectionResult<BTreeSet<PointIdType>> {
+        let stopping_guard = StoppingGuard::new();
+        let filter = filter.cloned();
+        runtime_handle
+            .spawn_blocking(move || {
+                let is_stopped = stopping_guard.get_is_stopped();
+                let segments = segments.read();
+                let hw_counter = hw_measurement_acc.get_counter_cell();
+                let all_points: BTreeSet<_> = segments
+                    .non_appendable_then_appendable_segments()
+                    .flat_map(|segment| {
+                        segment.get().read().read_filtered(
+                            None,
+                            None,
+                            filter.as_ref(),
+                            &is_stopped,
+                            &hw_counter,
+                        )
+                    })
+                    .collect();
+                Ok(all_points)
+            })
+            .await?
+    }
 }
 
 #[derive(PartialEq, Default, Debug)]
@@ -630,7 +641,7 @@ fn effective_limit(limit: usize, ef_limit: usize, poisson_sampling: usize) -> us
 /// * `segment` - Locked segment to search in
 /// * `request` - Batch of search requests
 /// * `use_sampling` - If true, try to use probabilistic sampling
-/// * `query_context` - Additional context for the search
+/// * `segment_query_context` - Additional context for the search
 ///
 /// # Returns
 ///
@@ -647,7 +658,7 @@ fn search_in_segment(
 
     let mut result: Vec<Vec<ScoredPoint>> = Vec::with_capacity(batch_size);
     let mut further_results: Vec<bool> = Vec::with_capacity(batch_size); // if segment have more points to return
-    let mut vectors_batch: Vec<QueryVector> = vec![];
+    let mut vectors_batch: Vec<QueryVector> = Vec::with_capacity(batch_size);
     let mut prev_params = BatchSearchParams::default();
 
     for search_query in &request.searches {
@@ -662,7 +673,7 @@ fn search_in_segment(
             filter: search_query.filter.as_ref(),
             with_payload: WithPayload::from(with_payload_interface),
             with_vector: search_query.with_vector.clone().unwrap_or_default(),
-            top: search_query.limit + search_query.offset,
+            top: search_query.limit.unwrap_or(0) + search_query.offset.unwrap_or(0),
             params: search_query.params.as_ref(),
         };
 
@@ -717,10 +728,10 @@ fn execute_batch_search(
 ) -> CollectionResult<(Vec<Vec<ScoredPoint>>, Vec<bool>)> {
     let locked_segment = segment.get();
     let read_segment = locked_segment.read();
-
-    let segment_points = read_segment.available_point_count();
     let segment_config = read_segment.config();
 
+    let segment_points = segment_query_context.available_point_count();
+    let total_points = segment_query_context.available_point_count();
     let top = if use_sampling {
         let ef_limit = search_params
             .params
@@ -730,12 +741,28 @@ fn execute_batch_search(
             search_params.top,
             ef_limit,
             segment_points,
-            segment_query_context.available_point_count(),
+            total_points,
         )
     } else {
         search_params.top
     };
 
+    let ignore_plain_index = search_params
+        .params
+        .map(|p| p.indexed_only)
+        .unwrap_or(false);
+    if ignore_plain_index
+        && !read_segment.is_search_optimized(
+            segment_query_context.search_optimized_threshold_kb(),
+            search_params.vector_name,
+            search_params.filter,
+            segment_query_context.get_hardware_counter_cell(),
+        )?
+    {
+        let batch_len = vectors_batch.len();
+        return Ok((vec![vec![]; batch_len], vec![false; batch_len]));
+    }
+
     let vectors_batch = &vectors_batch.iter().collect_vec();
     let res = read_segment.search_batch(
         search_params.vector_name,
@@ -772,10 +799,13 @@ fn get_hnsw_ef_construct(config: &SegmentConfig, vector_name: &VectorName) -> Op
 
 #[cfg(test)]
 mod tests {
+    use ahash::AHashMap;
     use ahash::AHashSet;
     use api::rest::SearchRequestInternal;
+    use common::counter::hardware_accumulator::HwMeasurementAcc;
     use common::counter::hardware_counter::HardwareCounterCell;
     use parking_lot::RwLock;
+    use rand::rngs::ThreadRng;
     use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
     use segment::fixtures::index_fixtures::random_vector;
     use segment::index::VectorIndexEnum;
@@ -843,9 +873,9 @@ mod tests {
             with_vector: None,
             filter: None,
             params: None,
-            limit: 5,
+            limit: Some(5),
             score_threshold: None,
-            offset: 0,
+            offset: None,
         };
 
         let batch_request = CoreSearchRequestBatch {
@@ -853,12 +883,14 @@ mod tests {
         };
 
         let hw_acc = HwMeasurementAcc::new();
+        let query_context = QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_acc);
         let result = SegmentsSearcher::search(
             Arc::new(segment_holder),
             Arc::new(batch_request),
             &Handle::current(),
             true,
-            QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_acc),
+            query_context,
+            &hw_acc,
         )
         .await
         .unwrap()
@@ -888,12 +920,12 @@ mod tests {
 
         let segment_holder = Arc::new(RwLock::new(holder));
 
-        let mut rnd = rand::rng();
+        let mut rnd: ThreadRng = rand::rng();
 
         for _ in 0..100 {
             let req1 = SearchRequestInternal {
                 vector: random_vector(&mut rnd, 4).into(),
-                limit: 150, // more than LOWER_SEARCH_LIMIT_SAMPLING
+                limit: Some(150), // more than LOWER_SEARCH_LIMIT_SAMPLING
                 offset: None,
                 with_payload: None,
                 with_vector: None,
@@ -903,7 +935,7 @@ mod tests {
             };
             let req2 = SearchRequestInternal {
                 vector: random_vector(&mut rnd, 4).into(),
-                limit: 50, // less than LOWER_SEARCH_LIMIT_SAMPLING
+                limit: Some(50), // less than LOWER_SEARCH_LIMIT_SAMPLING
                 offset: None,
                 filter: None,
                 params: None,
@@ -916,18 +948,17 @@ mod tests {
                 searches: vec![req1.into(), req2.into()],
             };
 
-            let batch_request = Arc::new(batch_request);
-
             let hw_measurement_acc = HwMeasurementAcc::new();
             let query_context =
                 QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_measurement_acc.clone());
 
             let result_no_sampling = SegmentsSearcher::search(
                 segment_holder.clone(),
-                batch_request.clone(),
+                Arc::new(batch_request.clone()),
                 &Handle::current(),
                 false,
                 query_context,
+                &hw_measurement_acc,
             )
             .await
             .unwrap();
@@ -942,10 +973,11 @@ mod tests {
 
             let result_sampling = SegmentsSearcher::search(
                 segment_holder.clone(),
-                batch_request,
+                Arc::new(batch_request),
                 &Handle::current(),
                 true,
                 query_context,
+                &hw_measurement_acc,
             )
             .await
             .unwrap();
@@ -957,6 +989,7 @@ mod tests {
             assert_eq!(result_no_sampling[0].len(), result_sampling[0].len());
             assert_eq!(result_no_sampling[1].len(), result_sampling[1].len());
 
+            #[allow(clippy::float_cmp)]
             for (no_sampling, sampling) in
                 result_no_sampling[0].iter().zip(result_sampling[0].iter())
             {
@@ -965,8 +998,8 @@ mod tests {
         }
     }
 
-    #[test]
-    fn test_retrieve() {
+    #[tokio::test]
+    async fn test_retrieve() {
         let dir = Builder::new().prefix("segment_dir").tempdir().unwrap();
         let segment_holder = build_test_holder(dir.path());
         let records = SegmentsSearcher::retrieve_blocking(
@@ -1017,10 +1050,11 @@ mod tests {
             (1000, 0, 150, 150),
             (1000, 0, 110, 110),
         ];
-        tests.into_iter().for_each(|(limit, ef_limit, poisson_sampling, effective)| assert_eq!(
-            effective_limit(limit, ef_limit, poisson_sampling),
-            effective,
-            "effective limit for [limit: {limit}, ef_limit: {ef_limit}, poisson_sampling: {poisson_sampling}] must be {effective}",
-        ));
-    }
-}
\ No newline at end of file
+        tests.into_iter().for_each(
+            |(limit, ef_limit, poisson_sampling, effective)| {
+                assert_eq!(
+                    effective_limit(limit, ef_limit, poisson_sampling),
+                    effective,
+                    "effective limit for [limit: {limit}, ef_limit: {ef_limit}, poisson_sampling: {poisson_sampling}] must be {effective}",
+                )
+            },
\ No newline at end of file
