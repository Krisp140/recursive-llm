# Instructions

You are being benchmarked. You will see the output of a git log command, and from that must infer the current state of a file. Think carefully, as you must output the exact state of the file to earn full marks.

**Important:** Your goal is to reproduce the file's content *exactly* as it exists at the final commit, even if the code appears broken, buggy, or contains obvious errors. Do **not** try to "fix" the code. Attempting to correct issues will result in a poor score, as this benchmark evaluates your ability to reproduce the precise state of the file based on its history.

# Required Response Format

Wrap the content of the file in triple backticks (```). Any text outside the final closing backticks will be ignored. End your response after outputting the closing backticks.

# Example Response

```python
#!/usr/bin/env python
print('Hello, world!')
```

# File History

> git log -p --cc --topo-order --reverse -- lib/sparse/src/index/search_context.rs

commit 4601ed3d89ad39967ad374c6e5e97ffbaf1857c1
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Fri Sep 15 16:30:11 2023 +0200

    Sparse vector index (#2318)
    
    * Sparse vector index
    
    * better name
    
    * fill properly postings
    
    * conflict
    
    * easy reviews
    
    * use unstable sort
    
    * use optional instead of bool flag
    
    * clearer score type and future direction
    
    * NonZeroUsize length for FixedLengthPriorityQueue
    
    * rename id to record_id
    
    * cleanup dimension inverted index
    
    * standard Iterator
    
    * code review
    
    * Shift comment
    
    * early return if no matching posting lists
    
    * sprinkle iterators
    
    * privatize the means of production
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
new file mode 100644
index 000000000..6c73ac74d
--- /dev/null
+++ b/lib/sparse/src/index/search_context.rs
@@ -0,0 +1,450 @@
+use common::fixed_length_priority_queue::FixedLengthPriorityQueue;
+
+use crate::common::scored_candidate::ScoredCandidate;
+use crate::common::sparse_vector::SparseVector;
+use crate::index::inverted_index::InvertedIndex;
+use crate::index::posting_list::PostingListIterator;
+
+pub struct IndexedPostingListIterator<'a> {
+    posting_list_iterator: PostingListIterator<'a>,
+    query_weight_offset: usize,
+}
+
+pub struct SearchContext<'a> {
+    postings_iterators: Vec<IndexedPostingListIterator<'a>>,
+    query: SparseVector,
+    top: usize,
+    result_queue: FixedLengthPriorityQueue<ScoredCandidate>, // keep the largest elements and peek smallest
+}
+
+impl<'a> SearchContext<'a> {
+    pub fn new(
+        query: SparseVector,
+        top: usize,
+        inverted_index: &'a InvertedIndex,
+    ) -> SearchContext<'a> {
+        let mut postings_iterators = Vec::new();
+
+        for (query_weight_offset, id) in query.indices.iter().enumerate() {
+            if let Some(posting) = inverted_index.get(id) {
+                postings_iterators.push(IndexedPostingListIterator {
+                    posting_list_iterator: PostingListIterator::new(posting),
+                    query_weight_offset,
+                });
+            }
+        }
+        let result_queue = FixedLengthPriorityQueue::new(top);
+
+        SearchContext {
+            postings_iterators,
+            query,
+            top,
+            result_queue,
+        }
+    }
+
+    /// Example
+    ///
+    /// postings_iterators:
+    ///
+    /// 1,  30, 34, 60, 230
+    /// 10, 30, 35, 51, 230
+    /// 2,  21, 34, 60, 200
+    /// 2,  30, 34, 60, 230
+    ///
+    /// Next:
+    ///
+    /// a,  30, 34, 60, 230
+    /// 10, 30, 35, 51, 230
+    /// 2,  21, 34, 60, 200
+    /// 2,  30, 34, 60, 230
+    ///
+    /// Next:
+    ///
+    /// a,  30, 34, 60, 230
+    /// 10, 30, 35, 51, 230
+    /// b,  21, 34, 60, 200
+    /// b,  30, 34, 60, 230
+    ///
+    /// Next:
+    ///
+    /// a,  30, 34, 60, 230
+    /// c,  30, 35, 51, 230
+    /// b,  21, 34, 60, 200
+    /// b,  30, 34, 60, 230
+    fn advance(&mut self) -> Option<ScoredCandidate> {
+        let min_record_id = Self::next_min(&self.postings_iterators)?;
+        let mut score = 0.0;
+
+        // Iterate second time to advance posting iterators
+        for posting_iterator in self.postings_iterators.iter_mut() {
+            if let Some(record_id) = posting_iterator
+                .posting_list_iterator
+                .peek()
+                .map(|element| element.record_id)
+            {
+                // accumulate score for the current record id
+                if record_id == min_record_id {
+                    let element = posting_iterator.posting_list_iterator.next().unwrap();
+                    score +=
+                        element.weight * self.query.weights[posting_iterator.query_weight_offset];
+                }
+            }
+        }
+
+        Some(ScoredCandidate {
+            score,
+            vector_id: min_record_id,
+        })
+    }
+
+    fn next_min(to_inspect: &[IndexedPostingListIterator<'_>]) -> Option<u32> {
+        let mut min_record_id = None;
+
+        // Iterate first time to find min record id at the head of the posting lists
+        for posting_iterator in to_inspect.iter() {
+            if let Some(next_element) = posting_iterator.posting_list_iterator.peek() {
+                if Some(next_element.record_id) < min_record_id || min_record_id.is_none() {
+                    min_record_id = Some(next_element.record_id);
+                }
+            }
+        }
+
+        min_record_id
+    }
+
+    /// Make sure the longest posting list is at the head of the posting list iterators
+    fn sort_posting_lists_by_len(&mut self) {
+        // decreasing order
+        self.postings_iterators.sort_by(|a, b| {
+            b.posting_list_iterator
+                .len_to_end()
+                .cmp(&a.posting_list_iterator.len_to_end())
+        });
+    }
+
+    pub fn search(&mut self) -> Vec<ScoredCandidate> {
+        if self.postings_iterators.is_empty() {
+            return Vec::new();
+        }
+        while let Some(candidate) = self.advance() {
+            // push candidate to result queue
+            self.result_queue.push(candidate);
+
+            // we potentially have enough results to prune low performing posting lists
+            if self.result_queue.len() == self.top {
+                // current min score
+                let min_score = self.result_queue.top().unwrap().score;
+
+                // sort posting lists by length to try to prune the longest one
+                self.sort_posting_lists_by_len();
+
+                self.prune_longest_posting_list(min_score);
+            }
+        }
+        // posting iterators exhausted, return result queue
+        let queue = std::mem::take(&mut self.result_queue);
+        queue.into_vec()
+    }
+
+    /// Prune posting lists that cannot possibly contribute to the top results
+    /// Assumes longest posting list is at the head of the posting list iterators
+    /// Returns true if the longest posting list was pruned
+    pub fn prune_longest_posting_list(&mut self, min_score: f32) -> bool {
+        // compute skip target before acquiring mutable reference to posting list iterator
+        let skip_to = if self.postings_iterators.len() == 1 {
+            // if there is only one posting list iterator, we can skip to the end
+            None
+        } else {
+            // otherwise, we skip to the next min elements in the remaining posting list
+            Self::next_min(&self.postings_iterators[1..])
+        };
+
+        let posting_iterator = &mut self.postings_iterators[0];
+        let posting_query_offset = posting_iterator.query_weight_offset;
+        if let Some(element) = posting_iterator.posting_list_iterator.peek() {
+            let max_weight_from_list = element.weight.max(element.max_next_weight);
+            let max_score_contribution =
+                max_weight_from_list * self.query.weights[posting_query_offset];
+            if max_score_contribution < min_score {
+                return match skip_to {
+                    None => {
+                        posting_iterator.posting_list_iterator.skip_to_end();
+                        true
+                    }
+                    Some(skip_to) => {
+                        let moved = posting_iterator.posting_list_iterator.skip_to(skip_to);
+                        moved.is_some()
+                    }
+                };
+            }
+        }
+        // no pruning occurred
+        false
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use crate::index::inverted_index::InvertedIndexBuilder;
+    use crate::index::posting_list::PostingList;
+
+    #[test]
+    fn advance_basic_test() {
+        let inverted_index = InvertedIndexBuilder::new()
+            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                weights: vec![1.0, 1.0, 1.0],
+            },
+            10,
+            &inverted_index,
+        );
+
+        assert_eq!(
+            search_context.advance(),
+            Some(ScoredCandidate {
+                score: 30.0,
+                vector_id: 1
+            })
+        );
+        assert_eq!(
+            search_context.advance(),
+            Some(ScoredCandidate {
+                score: 60.0,
+                vector_id: 2
+            })
+        );
+        assert_eq!(
+            search_context.advance(),
+            Some(ScoredCandidate {
+                score: 90.0,
+                vector_id: 3
+            })
+        );
+    }
+
+    #[test]
+    fn search() {
+        let inverted_index = InvertedIndexBuilder::new()
+            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                weights: vec![1.0, 1.0, 1.0],
+            },
+            10,
+            &inverted_index,
+        );
+
+        assert_eq!(
+            search_context.search(),
+            vec![
+                ScoredCandidate {
+                    score: 90.0,
+                    vector_id: 3
+                },
+                ScoredCandidate {
+                    score: 60.0,
+                    vector_id: 2
+                },
+                ScoredCandidate {
+                    score: 30.0,
+                    vector_id: 1
+                },
+            ]
+        );
+    }
+
+    #[test]
+    fn search_with_hot_key() {
+        let inverted_index = InvertedIndexBuilder::new()
+            .add(
+                1,
+                PostingList::from(vec![
+                    (1, 10.0),
+                    (2, 20.0),
+                    (3, 30.0),
+                    (4, 1.0),
+                    (5, 2.0),
+                    (6, 3.0),
+                    (7, 4.0),
+                    (8, 5.0),
+                    (9, 6.0),
+                ]),
+            )
+            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                weights: vec![1.0, 1.0, 1.0],
+            },
+            3,
+            &inverted_index,
+        );
+
+        assert_eq!(
+            search_context.search(),
+            vec![
+                ScoredCandidate {
+                    score: 90.0,
+                    vector_id: 3
+                },
+                ScoredCandidate {
+                    score: 60.0,
+                    vector_id: 2
+                },
+                ScoredCandidate {
+                    score: 30.0,
+                    vector_id: 1
+                },
+            ]
+        );
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                weights: vec![1.0, 1.0, 1.0],
+            },
+            4,
+            &inverted_index,
+        );
+
+        assert_eq!(
+            search_context.search(),
+            vec![
+                ScoredCandidate {
+                    score: 90.0,
+                    vector_id: 3
+                },
+                ScoredCandidate {
+                    score: 60.0,
+                    vector_id: 2
+                },
+                ScoredCandidate {
+                    score: 30.0,
+                    vector_id: 1
+                },
+                ScoredCandidate {
+                    score: 6.0,
+                    vector_id: 9
+                },
+            ]
+        );
+    }
+
+    #[test]
+    fn prune_test() {
+        let inverted_index = InvertedIndexBuilder::new()
+            .add(
+                1,
+                PostingList::from(vec![
+                    (1, 10.0),
+                    (2, 20.0),
+                    (3, 30.0),
+                    (4, 1.0),
+                    (5, 2.0),
+                    (6, 3.0),
+                    (7, 4.0),
+                    (8, 5.0),
+                    (9, 6.0),
+                ]),
+            )
+            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                weights: vec![1.0, 1.0, 1.0],
+            },
+            3,
+            &inverted_index,
+        );
+
+        // initial state
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            9
+        );
+        assert_eq!(
+            search_context.advance(),
+            Some(ScoredCandidate {
+                score: 30.0,
+                vector_id: 1
+            })
+        );
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            8
+        );
+        assert!(!search_context.prune_longest_posting_list(30.0));
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            8
+        );
+
+        assert_eq!(
+            search_context.advance(),
+            Some(ScoredCandidate {
+                score: 60.0,
+                vector_id: 2
+            })
+        );
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            7
+        );
+        assert!(!search_context.prune_longest_posting_list(30.0));
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            7
+        );
+
+        assert_eq!(
+            search_context.advance(),
+            Some(ScoredCandidate {
+                score: 90.0,
+                vector_id: 3
+            })
+        );
+        // pruning can take place
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            6
+        );
+        assert!(search_context.prune_longest_posting_list(30.0));
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            0
+        );
+    }
+}

commit 0d4a3736590dc33b39db2aeea0a799c05ec632f3
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Sep 28 12:11:29 2023 +0200

    Move ScoredPointOffset into common (#2734)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 6c73ac74d..fc875e6cf 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,6 +1,6 @@
 use common::fixed_length_priority_queue::FixedLengthPriorityQueue;
+use common::types::ScoredPointOffset;
 
-use crate::common::scored_candidate::ScoredCandidate;
 use crate::common::sparse_vector::SparseVector;
 use crate::index::inverted_index::InvertedIndex;
 use crate::index::posting_list::PostingListIterator;
@@ -14,7 +14,7 @@ pub struct SearchContext<'a> {
     postings_iterators: Vec<IndexedPostingListIterator<'a>>,
     query: SparseVector,
     top: usize,
-    result_queue: FixedLengthPriorityQueue<ScoredCandidate>, // keep the largest elements and peek smallest
+    result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
 }
 
 impl<'a> SearchContext<'a> {
@@ -72,7 +72,7 @@ impl<'a> SearchContext<'a> {
     /// c,  30, 35, 51, 230
     /// b,  21, 34, 60, 200
     /// b,  30, 34, 60, 230
-    fn advance(&mut self) -> Option<ScoredCandidate> {
+    fn advance(&mut self) -> Option<ScoredPointOffset> {
         let min_record_id = Self::next_min(&self.postings_iterators)?;
         let mut score = 0.0;
 
@@ -92,9 +92,9 @@ impl<'a> SearchContext<'a> {
             }
         }
 
-        Some(ScoredCandidate {
+        Some(ScoredPointOffset {
             score,
-            vector_id: min_record_id,
+            idx: min_record_id,
         })
     }
 
@@ -123,7 +123,7 @@ impl<'a> SearchContext<'a> {
         });
     }
 
-    pub fn search(&mut self) -> Vec<ScoredCandidate> {
+    pub fn search(&mut self) -> Vec<ScoredPointOffset> {
         if self.postings_iterators.is_empty() {
             return Vec::new();
         }
@@ -209,23 +209,23 @@ mod tests {
 
         assert_eq!(
             search_context.advance(),
-            Some(ScoredCandidate {
+            Some(ScoredPointOffset {
                 score: 30.0,
-                vector_id: 1
+                idx: 1
             })
         );
         assert_eq!(
             search_context.advance(),
-            Some(ScoredCandidate {
+            Some(ScoredPointOffset {
                 score: 60.0,
-                vector_id: 2
+                idx: 2
             })
         );
         assert_eq!(
             search_context.advance(),
-            Some(ScoredCandidate {
+            Some(ScoredPointOffset {
                 score: 90.0,
-                vector_id: 3
+                idx: 3
             })
         );
     }
@@ -250,17 +250,17 @@ mod tests {
         assert_eq!(
             search_context.search(),
             vec![
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 90.0,
-                    vector_id: 3
+                    idx: 3
                 },
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 60.0,
-                    vector_id: 2
+                    idx: 2
                 },
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 30.0,
-                    vector_id: 1
+                    idx: 1
                 },
             ]
         );
@@ -299,17 +299,17 @@ mod tests {
         assert_eq!(
             search_context.search(),
             vec![
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 90.0,
-                    vector_id: 3
+                    idx: 3
                 },
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 60.0,
-                    vector_id: 2
+                    idx: 2
                 },
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 30.0,
-                    vector_id: 1
+                    idx: 1
                 },
             ]
         );
@@ -326,22 +326,19 @@ mod tests {
         assert_eq!(
             search_context.search(),
             vec![
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 90.0,
-                    vector_id: 3
+                    idx: 3
                 },
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 60.0,
-                    vector_id: 2
+                    idx: 2
                 },
-                ScoredCandidate {
+                ScoredPointOffset {
                     score: 30.0,
-                    vector_id: 1
-                },
-                ScoredCandidate {
-                    score: 6.0,
-                    vector_id: 9
+                    idx: 1
                 },
+                ScoredPointOffset { score: 6.0, idx: 9 },
             ]
         );
     }
@@ -385,9 +382,9 @@ mod tests {
         );
         assert_eq!(
             search_context.advance(),
-            Some(ScoredCandidate {
+            Some(ScoredPointOffset {
                 score: 30.0,
-                vector_id: 1
+                idx: 1
             })
         );
         assert_eq!(
@@ -406,9 +403,9 @@ mod tests {
 
         assert_eq!(
             search_context.advance(),
-            Some(ScoredCandidate {
+            Some(ScoredPointOffset {
                 score: 60.0,
-                vector_id: 2
+                idx: 2
             })
         );
         assert_eq!(
@@ -427,9 +424,9 @@ mod tests {
 
         assert_eq!(
             search_context.advance(),
-            Some(ScoredCandidate {
+            Some(ScoredPointOffset {
                 score: 90.0,
-                vector_id: 3
+                idx: 3
             })
         );
         // pruning can take place

commit c00e496e471483bbe296f1036f3fc305054104a0
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Oct 4 14:39:52 2023 +0200

    Sparse index persistence (#2718)
    
    * Sparse index persistence
    
    * code review
    
    * remove pub visibility

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index fc875e6cf..a6678d8d3 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -26,9 +26,9 @@ impl<'a> SearchContext<'a> {
         let mut postings_iterators = Vec::new();
 
         for (query_weight_offset, id) in query.indices.iter().enumerate() {
-            if let Some(posting) = inverted_index.get(id) {
+            if let Some(posting_list_iterator) = inverted_index.get(id) {
                 postings_iterators.push(IndexedPostingListIterator {
-                    posting_list_iterator: PostingListIterator::new(posting),
+                    posting_list_iterator,
                     query_weight_offset,
                 });
             }
@@ -187,24 +187,18 @@ impl<'a> SearchContext<'a> {
 #[cfg(test)]
 mod tests {
     use super::*;
-    use crate::index::inverted_index::InvertedIndexBuilder;
+    use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
+    use crate::index::inverted_index::inverted_index_ram::InvertedIndexBuilder;
     use crate::index::posting_list::PostingList;
 
-    #[test]
-    fn advance_basic_test() {
-        let inverted_index = InvertedIndexBuilder::new()
-            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
-
+    fn _advance_test(inverted_index: &InvertedIndex) {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
                 weights: vec![1.0, 1.0, 1.0],
             },
             10,
-            &inverted_index,
+            inverted_index,
         );
 
         assert_eq!(
@@ -231,20 +225,37 @@ mod tests {
     }
 
     #[test]
-    fn search() {
-        let inverted_index = InvertedIndexBuilder::new()
+    fn advance_test() {
+        let inverted_index_ram = InvertedIndexBuilder::new()
             .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .build();
 
+        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
+
+        // test with ram index
+        _advance_test(&inverted_index);
+
+        // test with mmap index
+        let tmp_dir_path = tempfile::Builder::new()
+            .prefix("test_index_dir")
+            .tempdir()
+            .unwrap();
+        let inverted_index_mmap =
+            InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
+        let inverted_index = InvertedIndex::Mmap(inverted_index_mmap);
+        _advance_test(&inverted_index);
+    }
+
+    fn _search_test(inverted_index: &InvertedIndex) {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
                 weights: vec![1.0, 1.0, 1.0],
             },
             10,
-            &inverted_index,
+            inverted_index,
         );
 
         assert_eq!(
@@ -267,33 +278,36 @@ mod tests {
     }
 
     #[test]
-    fn search_with_hot_key() {
-        let inverted_index = InvertedIndexBuilder::new()
-            .add(
-                1,
-                PostingList::from(vec![
-                    (1, 10.0),
-                    (2, 20.0),
-                    (3, 30.0),
-                    (4, 1.0),
-                    (5, 2.0),
-                    (6, 3.0),
-                    (7, 4.0),
-                    (8, 5.0),
-                    (9, 6.0),
-                ]),
-            )
+    fn search_test() {
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .build();
 
+        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
+        // test with ram index
+        _search_test(&inverted_index);
+
+        // test with mmap index
+        let tmp_dir_path = tempfile::Builder::new()
+            .prefix("test_index_dir")
+            .tempdir()
+            .unwrap();
+        let inverted_index_mmap =
+            InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
+        let inverted_index = InvertedIndex::Mmap(inverted_index_mmap);
+        _search_test(&inverted_index);
+    }
+
+    fn _search_with_hot_key_test(inverted_index: &InvertedIndex) {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
                 weights: vec![1.0, 1.0, 1.0],
             },
             3,
-            &inverted_index,
+            inverted_index,
         );
 
         assert_eq!(
@@ -320,7 +334,7 @@ mod tests {
                 weights: vec![1.0, 1.0, 1.0],
             },
             4,
-            &inverted_index,
+            inverted_index,
         );
 
         assert_eq!(
@@ -344,8 +358,8 @@ mod tests {
     }
 
     #[test]
-    fn prune_test() {
-        let inverted_index = InvertedIndexBuilder::new()
+    fn search_with_hot_key_test() {
+        let inverted_index_ram = InvertedIndexBuilder::new()
             .add(
                 1,
                 PostingList::from(vec![
@@ -364,13 +378,29 @@ mod tests {
             .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .build();
 
+        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
+        // test with ram index
+        _search_with_hot_key_test(&inverted_index);
+
+        // test with mmap index
+        let tmp_dir_path = tempfile::Builder::new()
+            .prefix("test_index_dir")
+            .tempdir()
+            .unwrap();
+        let inverted_index_mmap =
+            InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
+        let inverted_index = InvertedIndex::Mmap(inverted_index_mmap);
+        _search_with_hot_key_test(&inverted_index);
+    }
+
+    fn _prune_test(inverted_index: &InvertedIndex) {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
                 weights: vec![1.0, 1.0, 1.0],
             },
             3,
-            &inverted_index,
+            inverted_index,
         );
 
         // initial state
@@ -444,4 +474,41 @@ mod tests {
             0
         );
     }
+
+    #[test]
+    fn prune_test() {
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(
+                1,
+                PostingList::from(vec![
+                    (1, 10.0),
+                    (2, 20.0),
+                    (3, 30.0),
+                    (4, 1.0),
+                    (5, 2.0),
+                    (6, 3.0),
+                    (7, 4.0),
+                    (8, 5.0),
+                    (9, 6.0),
+                ]),
+            )
+            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
+
+        // test with ram index
+        _prune_test(&inverted_index);
+
+        // test with mmap index
+        let tmp_dir_path = tempfile::Builder::new()
+            .prefix("test_index_dir")
+            .tempdir()
+            .unwrap();
+        let inverted_index_mmap =
+            InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
+        let inverted_index = InvertedIndex::Mmap(inverted_index_mmap);
+        _prune_test(&inverted_index);
+    }
 }

commit 600835b668dc6c8d80c71d146db394d758a0289d
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Tue Oct 17 12:10:27 2023 +0200

    Upsert operation on Sparse RAM index (#2826)
    
    * Upsert operaiton on Sparse RAM index
    
    * code review Ivan
    
    * fix insertion of posting not at the end
    
    * cleaner shortcut of upsert

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index a6678d8d3..af24ee6c5 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -300,6 +300,85 @@ mod tests {
         _search_test(&inverted_index);
     }
 
+    #[test]
+    fn search_with_update_test() {
+        let mut inverted_index_ram = InvertedIndexBuilder::new()
+            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                weights: vec![1.0, 1.0, 1.0],
+            },
+            10,
+            &inverted_index,
+        );
+
+        assert_eq!(
+            search_context.search(),
+            vec![
+                ScoredPointOffset {
+                    score: 90.0,
+                    idx: 3
+                },
+                ScoredPointOffset {
+                    score: 60.0,
+                    idx: 2
+                },
+                ScoredPointOffset {
+                    score: 30.0,
+                    idx: 1
+                },
+            ]
+        );
+
+        // update index with new point
+        inverted_index_ram.upsert(
+            4,
+            SparseVector {
+                indices: vec![1, 2, 3],
+                weights: vec![40.0, 40.0, 40.0],
+            },
+        );
+        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                weights: vec![1.0, 1.0, 1.0],
+            },
+            10,
+            &inverted_index,
+        );
+
+        assert_eq!(
+            search_context.search(),
+            vec![
+                ScoredPointOffset {
+                    score: 120.0,
+                    idx: 4
+                },
+                ScoredPointOffset {
+                    score: 90.0,
+                    idx: 3
+                },
+                ScoredPointOffset {
+                    score: 60.0,
+                    idx: 2
+                },
+                ScoredPointOffset {
+                    score: 30.0,
+                    idx: 1
+                },
+            ]
+        );
+    }
+
     fn _search_with_hot_key_test(inverted_index: &InvertedIndex) {
         let mut search_context = SearchContext::new(
             SparseVector {

commit 935b759dbe545787dd2cf2d81bd1287bc0b6e278
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Oct 18 12:03:04 2023 +0200

    Sparse vector index integration (#2835)
    
    * inverted index as trait
    
    * introduce sparse vector index integration
    
    * sparse vectors search cancellation
    
    * clippy
    
    * expose helper for search sparse
    
    * code review

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index af24ee6c5..18f5be7c9 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,3 +1,6 @@
+use std::sync::atomic::AtomicBool;
+use std::sync::atomic::Ordering::Relaxed;
+
 use common::fixed_length_priority_queue::FixedLengthPriorityQueue;
 use common::types::ScoredPointOffset;
 
@@ -14,6 +17,7 @@ pub struct SearchContext<'a> {
     postings_iterators: Vec<IndexedPostingListIterator<'a>>,
     query: SparseVector,
     top: usize,
+    is_stopped: &'a AtomicBool,
     result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
 }
 
@@ -21,7 +25,8 @@ impl<'a> SearchContext<'a> {
     pub fn new(
         query: SparseVector,
         top: usize,
-        inverted_index: &'a InvertedIndex,
+        inverted_index: &'a impl InvertedIndex,
+        is_stopped: &'a AtomicBool,
     ) -> SearchContext<'a> {
         let mut postings_iterators = Vec::new();
 
@@ -39,6 +44,7 @@ impl<'a> SearchContext<'a> {
             postings_iterators,
             query,
             top,
+            is_stopped,
             result_queue,
         }
     }
@@ -128,6 +134,10 @@ impl<'a> SearchContext<'a> {
             return Vec::new();
         }
         while let Some(candidate) = self.advance() {
+            // check for cancellation
+            if self.is_stopped.load(Relaxed) {
+                break;
+            }
             // push candidate to result queue
             self.result_queue.push(candidate);
 
@@ -191,7 +201,8 @@ mod tests {
     use crate::index::inverted_index::inverted_index_ram::InvertedIndexBuilder;
     use crate::index::posting_list::PostingList;
 
-    fn _advance_test(inverted_index: &InvertedIndex) {
+    fn _advance_test(inverted_index: &impl InvertedIndex) {
+        let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
@@ -199,6 +210,7 @@ mod tests {
             },
             10,
             inverted_index,
+            &is_stopped,
         );
 
         assert_eq!(
@@ -232,10 +244,8 @@ mod tests {
             .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .build();
 
-        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
-
         // test with ram index
-        _advance_test(&inverted_index);
+        _advance_test(&inverted_index_ram);
 
         // test with mmap index
         let tmp_dir_path = tempfile::Builder::new()
@@ -244,11 +254,11 @@ mod tests {
             .unwrap();
         let inverted_index_mmap =
             InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
-        let inverted_index = InvertedIndex::Mmap(inverted_index_mmap);
-        _advance_test(&inverted_index);
+        _advance_test(&inverted_index_mmap);
     }
 
-    fn _search_test(inverted_index: &InvertedIndex) {
+    fn _search_test(inverted_index: &impl InvertedIndex) {
+        let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
@@ -256,6 +266,7 @@ mod tests {
             },
             10,
             inverted_index,
+            &is_stopped,
         );
 
         assert_eq!(
@@ -285,9 +296,8 @@ mod tests {
             .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .build();
 
-        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
         // test with ram index
-        _search_test(&inverted_index);
+        _search_test(&inverted_index_ram);
 
         // test with mmap index
         let tmp_dir_path = tempfile::Builder::new()
@@ -296,27 +306,26 @@ mod tests {
             .unwrap();
         let inverted_index_mmap =
             InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
-        let inverted_index = InvertedIndex::Mmap(inverted_index_mmap);
-        _search_test(&inverted_index);
+        _search_test(&inverted_index_mmap);
     }
 
     #[test]
     fn search_with_update_test() {
+        let is_stopped = AtomicBool::new(false);
         let mut inverted_index_ram = InvertedIndexBuilder::new()
             .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .build();
 
-        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
-
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
                 weights: vec![1.0, 1.0, 1.0],
             },
             10,
-            &inverted_index,
+            &inverted_index_ram,
+            &is_stopped,
         );
 
         assert_eq!(
@@ -345,15 +354,14 @@ mod tests {
                 weights: vec![40.0, 40.0, 40.0],
             },
         );
-        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
-
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
                 weights: vec![1.0, 1.0, 1.0],
             },
             10,
-            &inverted_index,
+            &inverted_index_ram,
+            &is_stopped,
         );
 
         assert_eq!(
@@ -379,7 +387,8 @@ mod tests {
         );
     }
 
-    fn _search_with_hot_key_test(inverted_index: &InvertedIndex) {
+    fn _search_with_hot_key_test(inverted_index: &impl InvertedIndex) {
+        let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
@@ -387,6 +396,7 @@ mod tests {
             },
             3,
             inverted_index,
+            &is_stopped,
         );
 
         assert_eq!(
@@ -414,6 +424,7 @@ mod tests {
             },
             4,
             inverted_index,
+            &is_stopped,
         );
 
         assert_eq!(
@@ -457,9 +468,8 @@ mod tests {
             .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .build();
 
-        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
         // test with ram index
-        _search_with_hot_key_test(&inverted_index);
+        _search_with_hot_key_test(&inverted_index_ram);
 
         // test with mmap index
         let tmp_dir_path = tempfile::Builder::new()
@@ -468,11 +478,11 @@ mod tests {
             .unwrap();
         let inverted_index_mmap =
             InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
-        let inverted_index = InvertedIndex::Mmap(inverted_index_mmap);
-        _search_with_hot_key_test(&inverted_index);
+        _search_with_hot_key_test(&inverted_index_mmap);
     }
 
-    fn _prune_test(inverted_index: &InvertedIndex) {
+    fn _prune_test(inverted_index: &impl InvertedIndex) {
+        let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
@@ -480,6 +490,7 @@ mod tests {
             },
             3,
             inverted_index,
+            &is_stopped,
         );
 
         // initial state
@@ -575,10 +586,8 @@ mod tests {
             .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
             .build();
 
-        let inverted_index = InvertedIndex::Ram(inverted_index_ram.clone());
-
         // test with ram index
-        _prune_test(&inverted_index);
+        _prune_test(&inverted_index_ram);
 
         // test with mmap index
         let tmp_dir_path = tempfile::Builder::new()
@@ -587,7 +596,6 @@ mod tests {
             .unwrap();
         let inverted_index_mmap =
             InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
-        let inverted_index = InvertedIndex::Mmap(inverted_index_mmap);
-        _prune_test(&inverted_index);
+        _prune_test(&inverted_index_mmap);
     }
 }

commit 1bafacd6f824597489fec1912e16f03ec1e41abe
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Tue Oct 31 11:52:45 2023 +0100

    Rename sparse vector values (#2892)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 18f5be7c9..adb99ed1b 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -93,7 +93,7 @@ impl<'a> SearchContext<'a> {
                 if record_id == min_record_id {
                     let element = posting_iterator.posting_list_iterator.next().unwrap();
                     score +=
-                        element.weight * self.query.weights[posting_iterator.query_weight_offset];
+                        element.weight * self.query.values[posting_iterator.query_weight_offset];
                 }
             }
         }
@@ -175,7 +175,7 @@ impl<'a> SearchContext<'a> {
         if let Some(element) = posting_iterator.posting_list_iterator.peek() {
             let max_weight_from_list = element.weight.max(element.max_next_weight);
             let max_score_contribution =
-                max_weight_from_list * self.query.weights[posting_query_offset];
+                max_weight_from_list * self.query.values[posting_query_offset];
             if max_score_contribution < min_score {
                 return match skip_to {
                     None => {
@@ -206,7 +206,7 @@ mod tests {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
-                weights: vec![1.0, 1.0, 1.0],
+                values: vec![1.0, 1.0, 1.0],
             },
             10,
             inverted_index,
@@ -262,7 +262,7 @@ mod tests {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
-                weights: vec![1.0, 1.0, 1.0],
+                values: vec![1.0, 1.0, 1.0],
             },
             10,
             inverted_index,
@@ -321,7 +321,7 @@ mod tests {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
-                weights: vec![1.0, 1.0, 1.0],
+                values: vec![1.0, 1.0, 1.0],
             },
             10,
             &inverted_index_ram,
@@ -351,13 +351,13 @@ mod tests {
             4,
             SparseVector {
                 indices: vec![1, 2, 3],
-                weights: vec![40.0, 40.0, 40.0],
+                values: vec![40.0, 40.0, 40.0],
             },
         );
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
-                weights: vec![1.0, 1.0, 1.0],
+                values: vec![1.0, 1.0, 1.0],
             },
             10,
             &inverted_index_ram,
@@ -392,7 +392,7 @@ mod tests {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
-                weights: vec![1.0, 1.0, 1.0],
+                values: vec![1.0, 1.0, 1.0],
             },
             3,
             inverted_index,
@@ -420,7 +420,7 @@ mod tests {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
-                weights: vec![1.0, 1.0, 1.0],
+                values: vec![1.0, 1.0, 1.0],
             },
             4,
             inverted_index,
@@ -486,7 +486,7 @@ mod tests {
         let mut search_context = SearchContext::new(
             SparseVector {
                 indices: vec![1, 2, 3],
-                weights: vec![1.0, 1.0, 1.0],
+                values: vec![1.0, 1.0, 1.0],
             },
             3,
             inverted_index,

commit 5c3c9012b74a8a5f89181b80ea806b3c6327ccc7
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Nov 2 15:30:43 2023 +0100

    Document and test underfetching with sparse vectors (#2908)
    
    * Document and test underfetching with sparse vectors
    
    * deduplicate test point ids

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index adb99ed1b..6f862e8df 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -196,9 +196,16 @@ impl<'a> SearchContext<'a> {
 
 #[cfg(test)]
 mod tests {
+    use std::collections::HashSet;
+
+    use rand::rngs::StdRng;
+    use rand::{Rng, SeedableRng};
+
     use super::*;
     use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
-    use crate::index::inverted_index::inverted_index_ram::InvertedIndexBuilder;
+    use crate::index::inverted_index::inverted_index_ram::{
+        InvertedIndexBuilder, InvertedIndexRam,
+    };
     use crate::index::posting_list::PostingList;
 
     fn _advance_test(inverted_index: &impl InvertedIndex) {
@@ -598,4 +605,107 @@ mod tests {
             InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
         _prune_test(&inverted_index_mmap);
     }
+
+    /// Generates a non empty sparse vector
+    pub fn random_sparse_vector<R: Rng + ?Sized>(rnd_gen: &mut R, max_size: usize) -> SparseVector {
+        let size = rnd_gen.gen_range(1..max_size);
+        let mut tuples: Vec<(i32, f64)> = vec![];
+
+        for i in 1..=size {
+            let no_skip = rnd_gen.gen_bool(0.5);
+            if no_skip {
+                tuples.push((i as i32, rnd_gen.gen_range(0.0..100.0)));
+            }
+        }
+
+        // make sure we have at least one vector
+        if tuples.is_empty() {
+            tuples.push((
+                rnd_gen.gen_range(1..max_size) as i32,
+                rnd_gen.gen_range(0.0..100.0),
+            ));
+        }
+
+        SparseVector::from(tuples)
+    }
+
+    /// Generates a random inverted index with `num_vectors` vectors
+    fn random_inverted_index<R: Rng + ?Sized>(
+        rnd_gen: &mut R,
+        num_vectors: u32,
+        max_sparse_dimension: usize,
+    ) -> InvertedIndexRam {
+        let mut inverted_index_ram = InvertedIndexRam::empty();
+
+        for i in 1..=num_vectors {
+            let vector = random_sparse_vector(rnd_gen, max_sparse_dimension);
+            inverted_index_ram.upsert(i, vector);
+        }
+        inverted_index_ram
+    }
+
+    #[test]
+    fn next_min_partial_scan_test() {
+        let num_vectors = 100;
+        let max_sparse_dimension = 25;
+        let mut rnd = StdRng::seed_from_u64(42);
+        let is_stopped = AtomicBool::new(false);
+        let inverted_index_ram = random_inverted_index(&mut rnd, num_vectors, max_sparse_dimension);
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                values: vec![1.0, 1.0, 1.0],
+            },
+            3,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        let mut all_next_min_observed = HashSet::new();
+
+        while let Some(next_min) =
+            SearchContext::next_min(search_context.postings_iterators.as_slice())
+        {
+            all_next_min_observed.insert(next_min);
+            let next_candidate_id = search_context.advance().map(|s| s.idx);
+            assert_eq!(next_candidate_id, Some(next_min));
+        }
+
+        // Not all vectors are observed because only the indices of the query vector are explored.
+        assert!(all_next_min_observed.len() < num_vectors as usize);
+    }
+
+    #[test]
+    fn next_min_full_scan_test() {
+        let num_vectors = 100;
+        let max_sparse_dimension = 25;
+        let mut rnd = StdRng::seed_from_u64(42);
+        let is_stopped = AtomicBool::new(false);
+        let inverted_index_ram = random_inverted_index(&mut rnd, num_vectors, max_sparse_dimension);
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: (1..=max_sparse_dimension as u32).collect(),
+                values: vec![1.0; max_sparse_dimension],
+            },
+            3,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        // initial state
+        let min = SearchContext::next_min(search_context.postings_iterators.as_slice());
+        // no side effect
+        assert_eq!(min, Some(1));
+        assert_eq!(min, Some(1));
+
+        // Complete scan over all vectors because the query vector contains all dimensions in the index.
+        for i in 1..num_vectors {
+            let before_min = SearchContext::next_min(search_context.postings_iterators.as_slice());
+            assert_eq!(before_min, Some(i));
+            let next = search_context.advance().map(|s| s.idx);
+            assert_eq!(next, Some(i));
+            let new_min = SearchContext::next_min(search_context.postings_iterators.as_slice());
+            assert_eq!(new_min, Some(i + 1));
+        }
+    }
 }

commit d5f98d8205f61dcfa53d0ecbd6c363c7d7aa501e
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Fri Nov 3 16:23:05 2023 +0100

    SparseVectorIndex implements VectorIndex (#2900)
    
    * SparseVector implements VectorIndex
    
    * dedicated telemetry
    
    * conflict
    
    * easy code reviews
    
    * simplify tracking indexed points count
    
    * move telemetry conversion to sparse file
    
    * move max_result_count out of inverted index trait
    
    * unify sparse vector fixtures
    
    * simpler conversion
    
    * add todo regarding OOM potential
    
    * reuse check deleted from raw scorer with TODO
    
    * change new to open to handle mmap index

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 6f862e8df..695c0d2f2 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -2,7 +2,7 @@ use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
 use common::fixed_length_priority_queue::FixedLengthPriorityQueue;
-use common::types::ScoredPointOffset;
+use common::types::{PointOffsetType, ScoredPointOffset};
 
 use crate::common::sparse_vector::SparseVector;
 use crate::index::inverted_index::InvertedIndex;
@@ -49,6 +49,8 @@ impl<'a> SearchContext<'a> {
         }
     }
 
+    /// Advance posting lists iterators and return the next candidate by increasing ids.
+    ///
     /// Example
     ///
     /// postings_iterators:
@@ -104,6 +106,9 @@ impl<'a> SearchContext<'a> {
         })
     }
 
+    /// Returns the next min record id from all posting list iterators
+    ///
+    /// returns None if all posting list iterators are exhausted
     fn next_min(to_inspect: &[IndexedPostingListIterator<'_>]) -> Option<u32> {
         let mut min_record_id = None;
 
@@ -129,7 +134,11 @@ impl<'a> SearchContext<'a> {
         });
     }
 
-    pub fn search(&mut self) -> Vec<ScoredPointOffset> {
+    /// Search for the top k results that satisfy the filter condition
+    pub fn search<F: Fn(PointOffsetType) -> bool>(
+        &mut self,
+        filter_condition: &F,
+    ) -> Vec<ScoredPointOffset> {
         if self.postings_iterators.is_empty() {
             return Vec::new();
         }
@@ -138,6 +147,10 @@ impl<'a> SearchContext<'a> {
             if self.is_stopped.load(Relaxed) {
                 break;
             }
+            // check filter condition
+            if !filter_condition(candidate.idx) {
+                continue;
+            }
             // push candidate to result queue
             self.result_queue.push(candidate);
 
@@ -202,12 +215,18 @@ mod tests {
     use rand::{Rng, SeedableRng};
 
     use super::*;
+    use crate::common::sparse_vector_fixture::random_sparse_vector;
     use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
     use crate::index::inverted_index::inverted_index_ram::{
         InvertedIndexBuilder, InvertedIndexRam,
     };
     use crate::index::posting_list::PostingList;
 
+    /// Match all filter condition for testing
+    fn match_all(_p: PointOffsetType) -> bool {
+        true
+    }
+
     fn _advance_test(inverted_index: &impl InvertedIndex) {
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
@@ -277,7 +296,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(),
+            search_context.search(&match_all),
             vec![
                 ScoredPointOffset {
                     score: 90.0,
@@ -336,7 +355,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(),
+            search_context.search(&match_all),
             vec![
                 ScoredPointOffset {
                     score: 90.0,
@@ -372,7 +391,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(),
+            search_context.search(&match_all),
             vec![
                 ScoredPointOffset {
                     score: 120.0,
@@ -407,7 +426,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(),
+            search_context.search(&match_all),
             vec![
                 ScoredPointOffset {
                     score: 90.0,
@@ -435,7 +454,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(),
+            search_context.search(&match_all),
             vec![
                 ScoredPointOffset {
                     score: 90.0,
@@ -606,29 +625,6 @@ mod tests {
         _prune_test(&inverted_index_mmap);
     }
 
-    /// Generates a non empty sparse vector
-    pub fn random_sparse_vector<R: Rng + ?Sized>(rnd_gen: &mut R, max_size: usize) -> SparseVector {
-        let size = rnd_gen.gen_range(1..max_size);
-        let mut tuples: Vec<(i32, f64)> = vec![];
-
-        for i in 1..=size {
-            let no_skip = rnd_gen.gen_bool(0.5);
-            if no_skip {
-                tuples.push((i as i32, rnd_gen.gen_range(0.0..100.0)));
-            }
-        }
-
-        // make sure we have at least one vector
-        if tuples.is_empty() {
-            tuples.push((
-                rnd_gen.gen_range(1..max_size) as i32,
-                rnd_gen.gen_range(0.0..100.0),
-            ));
-        }
-
-        SparseVector::from(tuples)
-    }
-
     /// Generates a random inverted index with `num_vectors` vectors
     fn random_inverted_index<R: Rng + ?Sized>(
         rnd_gen: &mut R,

commit dfb70c8621abe3a09aa9f479cf86fd5eeaf1947b
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Tue Nov 7 14:51:21 2023 +0100

    Faster search in sparse inverted index with unstable sort (#2937)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 695c0d2f2..5d2075c51 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -127,7 +127,7 @@ impl<'a> SearchContext<'a> {
     /// Make sure the longest posting list is at the head of the posting list iterators
     fn sort_posting_lists_by_len(&mut self) {
         // decreasing order
-        self.postings_iterators.sort_by(|a, b| {
+        self.postings_iterators.sort_unstable_by(|a, b| {
             b.posting_list_iterator
                 .len_to_end()
                 .cmp(&a.posting_list_iterator.len_to_end())

commit bc68840558f032ea60a6268477d54998130832f8
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Nov 15 14:35:42 2023 +0100

    Improve sparse index pruning (#3011)
    
    * Improve sparse index pruning
    
    * add test for promote longest
    
    * document and test possible underpruning

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 5d2075c51..dea2f6b43 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,3 +1,4 @@
+use std::cmp::Ordering;
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
@@ -81,18 +82,14 @@ impl<'a> SearchContext<'a> {
     /// b,  21, 34, 60, 200
     /// b,  30, 34, 60, 230
     fn advance(&mut self) -> Option<ScoredPointOffset> {
-        let min_record_id = Self::next_min(&self.postings_iterators)?;
+        let min_record_id = Self::next_min_id(&self.postings_iterators)?;
         let mut score = 0.0;
 
         // Iterate second time to advance posting iterators
         for posting_iterator in self.postings_iterators.iter_mut() {
-            if let Some(record_id) = posting_iterator
-                .posting_list_iterator
-                .peek()
-                .map(|element| element.record_id)
-            {
+            if let Some(element) = posting_iterator.posting_list_iterator.peek() {
                 // accumulate score for the current record id
-                if record_id == min_record_id {
+                if element.record_id == min_record_id {
                     let element = posting_iterator.posting_list_iterator.next().unwrap();
                     score +=
                         element.weight * self.query.values[posting_iterator.query_weight_offset];
@@ -109,14 +106,20 @@ impl<'a> SearchContext<'a> {
     /// Returns the next min record id from all posting list iterators
     ///
     /// returns None if all posting list iterators are exhausted
-    fn next_min(to_inspect: &[IndexedPostingListIterator<'_>]) -> Option<u32> {
+    fn next_min_id(to_inspect: &[IndexedPostingListIterator<'_>]) -> Option<u32> {
         let mut min_record_id = None;
 
-        // Iterate first time to find min record id at the head of the posting lists
+        // Iterate to find min record id at the head of the posting lists
         for posting_iterator in to_inspect.iter() {
             if let Some(next_element) = posting_iterator.posting_list_iterator.peek() {
-                if Some(next_element.record_id) < min_record_id || min_record_id.is_none() {
-                    min_record_id = Some(next_element.record_id);
+                match min_record_id {
+                    None => min_record_id = Some(next_element.record_id), // first record with matching id
+                    Some(min_id_seen) => {
+                        // update min record id if smaller
+                        if next_element.record_id < min_id_seen {
+                            min_record_id = Some(next_element.record_id);
+                        }
+                    }
                 }
             }
         }
@@ -125,13 +128,26 @@ impl<'a> SearchContext<'a> {
     }
 
     /// Make sure the longest posting list is at the head of the posting list iterators
-    fn sort_posting_lists_by_len(&mut self) {
-        // decreasing order
-        self.postings_iterators.sort_unstable_by(|a, b| {
-            b.posting_list_iterator
-                .len_to_end()
-                .cmp(&a.posting_list_iterator.len_to_end())
-        });
+    fn promote_longest_posting_lists_to_the_front(&mut self) {
+        // find index of longest posting list
+        let posting_index = self
+            .postings_iterators
+            .iter()
+            .enumerate()
+            .max_by(|(_, a), (_, b)| {
+                a.posting_list_iterator
+                    .len_to_end()
+                    .cmp(&b.posting_list_iterator.len_to_end())
+            })
+            .map(|(index, _)| index);
+
+        if let Some(posting_index) = posting_index {
+            // make sure it is not already at the head
+            if posting_index != 0 {
+                // swap longest posting list to the head
+                self.postings_iterators.swap(0, posting_index);
+            }
+        }
     }
 
     /// Search for the top k results that satisfy the filter condition
@@ -155,13 +171,15 @@ impl<'a> SearchContext<'a> {
             self.result_queue.push(candidate);
 
             // we potentially have enough results to prune low performing posting lists
+            // TODO(sparse) pruning is expensive, we should only do it when it makes sense (detect hot keys at runtime)
             if self.result_queue.len() == self.top {
                 // current min score
                 let min_score = self.result_queue.top().unwrap().score;
 
-                // sort posting lists by length to try to prune the longest one
-                self.sort_posting_lists_by_len();
+                // make sure the first posting list is the longest for pruning
+                self.promote_longest_posting_lists_to_the_front();
 
+                // prune posting list that cannot possibly contribute to the top results
                 self.prune_longest_posting_list(min_score);
             }
         }
@@ -174,35 +192,62 @@ impl<'a> SearchContext<'a> {
     /// Assumes longest posting list is at the head of the posting list iterators
     /// Returns true if the longest posting list was pruned
     pub fn prune_longest_posting_list(&mut self, min_score: f32) -> bool {
-        // compute skip target before acquiring mutable reference to posting list iterator
-        let skip_to = if self.postings_iterators.len() == 1 {
-            // if there is only one posting list iterator, we can skip to the end
-            None
-        } else {
-            // otherwise, we skip to the next min elements in the remaining posting list
-            Self::next_min(&self.postings_iterators[1..])
-        };
-
-        let posting_iterator = &mut self.postings_iterators[0];
-        let posting_query_offset = posting_iterator.query_weight_offset;
-        if let Some(element) = posting_iterator.posting_list_iterator.peek() {
-            let max_weight_from_list = element.weight.max(element.max_next_weight);
-            let max_score_contribution =
-                max_weight_from_list * self.query.values[posting_query_offset];
-            if max_score_contribution < min_score {
-                return match skip_to {
-                    None => {
-                        posting_iterator.posting_list_iterator.skip_to_end();
-                        true
+        // peek first element of longest posting list
+        let longest_posting_iterator = &self.postings_iterators[0];
+        if let Some(element) = longest_posting_iterator.posting_list_iterator.peek() {
+            let next_min_id_in_others = Self::next_min_id(&self.postings_iterators[1..]);
+            match next_min_id_in_others {
+                Some(next_min_id) => {
+                    match next_min_id.cmp(&element.record_id) {
+                        Ordering::Equal => {
+                            // if the next min id in the other posting lists is the same as the current one,
+                            // we can't prune the current element as it needs to be scored properly across posting lists
+                            return false;
+                        }
+                        Ordering::Less => {
+                            // we can't prune as there the other posting lists contains smaller smaller ids that need to scored first
+                            return false;
+                        }
+                        Ordering::Greater => {
+                            // next_min_id is > element.record_id there is a chance to prune up to `next_min_id`
+                            let posting_query_offset = longest_posting_iterator.query_weight_offset;
+                            // check against the max possible score using the `max_next_weight`
+                            // we can under prune as we should actually check the best score up to `next_min_id` - 1 only
+                            // instead of the max possible score but it is not possible to know the best score up to `next_min_id` - 1
+                            let max_weight_from_list = element.weight.max(element.max_next_weight);
+                            let max_score_contribution =
+                                max_weight_from_list * self.query.values[posting_query_offset];
+                            if max_score_contribution <= min_score {
+                                // prune to next_min_id
+                                let longest_posting_iterator =
+                                    &mut self.postings_iterators[0].posting_list_iterator;
+                                let position_before_pruning =
+                                    longest_posting_iterator.current_index;
+                                longest_posting_iterator.skip_to(next_min_id);
+                                let position_after_pruning = longest_posting_iterator.current_index;
+                                // check if pruning took place
+                                return position_before_pruning != position_after_pruning;
+                            }
+                        }
                     }
-                    Some(skip_to) => {
-                        let moved = posting_iterator.posting_list_iterator.skip_to(skip_to);
-                        moved.is_some()
+                }
+                None => {
+                    // the current posting list is the only one left, we can potentially skip it to the end
+                    let posting_query_offset = longest_posting_iterator.query_weight_offset;
+                    // check against the max possible score using the `max_next_weight`
+                    let max_weight_from_list = element.weight.max(element.max_next_weight);
+                    let max_score_contribution =
+                        max_weight_from_list * self.query.values[posting_query_offset];
+                    if max_score_contribution <= min_score {
+                        // prune to the end!
+                        let longest_posting_iterator = &mut self.postings_iterators[0];
+                        longest_posting_iterator.posting_list_iterator.skip_to_end();
+                        return true;
                     }
-                };
+                }
             }
         }
-        // no pruning occurred
+        // no pruning took place
         false
     }
 }
@@ -625,6 +670,135 @@ mod tests {
         _prune_test(&inverted_index_mmap);
     }
 
+    #[test]
+    fn pruning_single_to_end_test() {
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let is_stopped = AtomicBool::new(false);
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                values: vec![1.0, 1.0, 1.0],
+            },
+            1,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        // assuming we have gathered enough results and want to prune the longest posting list
+        assert!(search_context.prune_longest_posting_list(30.0));
+        // the longest posting list was pruned to the end
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            0
+        );
+    }
+
+    #[test]
+    fn pruning_multi_to_end_test() {
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(
+                1,
+                PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0), (4, 10.0)]),
+            )
+            .add(2, PostingList::from(vec![(6, 20.0), (7, 30.0)]))
+            .add(3, PostingList::from(vec![(5, 10.0), (6, 20.0), (7, 30.0)]))
+            .build();
+
+        let is_stopped = AtomicBool::new(false);
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                values: vec![1.0, 1.0, 1.0],
+            },
+            1,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        // assuming we have gathered enough results and want to prune the longest posting list
+        assert!(search_context.prune_longest_posting_list(30.0));
+        // the longest posting list was pruned to the end
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            0
+        );
+    }
+
+    #[test]
+    fn pruning_multi_under_prune_test() {
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(
+                1,
+                PostingList::from(vec![
+                    (1, 10.0),
+                    (2, 20.0),
+                    (3, 20.0),
+                    (4, 10.0),
+                    (6, 20.0),
+                    (7, 40.0),
+                ]),
+            )
+            .add(2, PostingList::from(vec![(6, 20.0), (7, 30.0)]))
+            .add(3, PostingList::from(vec![(5, 10.0), (6, 20.0), (7, 30.0)]))
+            .build();
+
+        let is_stopped = AtomicBool::new(false);
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                values: vec![1.0, 1.0, 1.0],
+            },
+            1,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        // one would expect this to prune up to `6` but it does not happen it practice because we are under pruning by design
+        // we should actually check the best score up to `6` - 1 only instead of the max possible score (40.0)
+        assert!(!search_context.prune_longest_posting_list(30.0));
+
+        assert!(search_context.prune_longest_posting_list(40.0));
+        // the longest posting list was pruned to the end
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            2 // 6, 7
+        );
+    }
+
+    #[test]
+    #[ignore] // TODO(sparse) make this test pass
+    fn pruning_does_not_skip_negative_score_test() {
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(
+                1,
+                PostingList::from(vec![(1, 1.0), (2, 2.0), (3, 3.0), (4, 1.0), (5, -40.0)]),
+            )
+            .build();
+
+        let is_stopped = AtomicBool::new(false);
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                values: vec![-1.0, 1.0, 1.0],
+            },
+            1,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        // no pruning because -1.0 * -40.0 > 30.0
+        assert!(!search_context.prune_longest_posting_list(30.0));
+    }
+
     /// Generates a random inverted index with `num_vectors` vectors
     fn random_inverted_index<R: Rng + ?Sized>(
         rnd_gen: &mut R,
@@ -660,7 +834,7 @@ mod tests {
         let mut all_next_min_observed = HashSet::new();
 
         while let Some(next_min) =
-            SearchContext::next_min(search_context.postings_iterators.as_slice())
+            SearchContext::next_min_id(search_context.postings_iterators.as_slice())
         {
             all_next_min_observed.insert(next_min);
             let next_candidate_id = search_context.advance().map(|s| s.idx);
@@ -689,19 +863,56 @@ mod tests {
         );
 
         // initial state
-        let min = SearchContext::next_min(search_context.postings_iterators.as_slice());
+        let min = SearchContext::next_min_id(search_context.postings_iterators.as_slice());
         // no side effect
         assert_eq!(min, Some(1));
         assert_eq!(min, Some(1));
 
         // Complete scan over all vectors because the query vector contains all dimensions in the index.
         for i in 1..num_vectors {
-            let before_min = SearchContext::next_min(search_context.postings_iterators.as_slice());
+            let before_min =
+                SearchContext::next_min_id(search_context.postings_iterators.as_slice());
             assert_eq!(before_min, Some(i));
             let next = search_context.advance().map(|s| s.idx);
             assert_eq!(next, Some(i));
-            let new_min = SearchContext::next_min(search_context.postings_iterators.as_slice());
+            let new_min = SearchContext::next_min_id(search_context.postings_iterators.as_slice());
             assert_eq!(new_min, Some(i + 1));
         }
     }
+
+    #[test]
+    fn promote_longest_test() {
+        let is_stopped = AtomicBool::new(false);
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0)]))
+            .add(2, PostingList::from(vec![(1, 10.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                values: vec![1.0, 1.0, 1.0],
+            },
+            3,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            2
+        );
+
+        search_context.promote_longest_posting_lists_to_the_front();
+
+        assert_eq!(
+            search_context.postings_iterators[0]
+                .posting_list_iterator
+                .len_to_end(),
+            3
+        );
+    }
 }

commit 6d0a48b2dc772e978dd560d9c265530859ea2a6d
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Nov 16 10:51:02 2023 +0100

    Deactivate sparse index pruning for negative query vectors (#3024)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index dea2f6b43..be35b69b4 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -20,6 +20,7 @@ pub struct SearchContext<'a> {
     top: usize,
     is_stopped: &'a AtomicBool,
     result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
+    use_pruning: bool,
 }
 
 impl<'a> SearchContext<'a> {
@@ -40,13 +41,17 @@ impl<'a> SearchContext<'a> {
             }
         }
         let result_queue = FixedLengthPriorityQueue::new(top);
-
+        // Query vectors with negative values can NOT use the pruning mechanism which relies on the pre-computed `max_next_weight`.
+        // The max contribution per posting list that we calculate is not made to compute the max value of two negative numbers.
+        // This is a limitation of the current pruning implementation.
+        let use_pruning = query.values.iter().all(|v| *v >= 0.0);
         SearchContext {
             postings_iterators,
             query,
             top,
             is_stopped,
             result_queue,
+            use_pruning,
         }
     }
 
@@ -172,7 +177,7 @@ impl<'a> SearchContext<'a> {
 
             // we potentially have enough results to prune low performing posting lists
             // TODO(sparse) pruning is expensive, we should only do it when it makes sense (detect hot keys at runtime)
-            if self.result_queue.len() == self.top {
+            if self.use_pruning && self.result_queue.len() == self.top {
                 // current min score
                 let min_score = self.result_queue.top().unwrap().score;
 
@@ -775,7 +780,6 @@ mod tests {
     }
 
     #[test]
-    #[ignore] // TODO(sparse) make this test pass
     fn pruning_does_not_skip_negative_score_test() {
         let inverted_index_ram = InvertedIndexBuilder::new()
             .add(
@@ -790,13 +794,54 @@ mod tests {
                 indices: vec![1, 2, 3],
                 values: vec![-1.0, 1.0, 1.0],
             },
-            1,
+            2,
             &inverted_index_ram,
             &is_stopped,
         );
 
-        // no pruning because -1.0 * -40.0 > 30.0
-        assert!(!search_context.prune_longest_posting_list(30.0));
+        // pruning is automatically deactivated because the query vector contains negative values
+        assert!(!search_context.use_pruning);
+        assert_eq!(
+            search_context.search(&match_all),
+            vec![
+                ScoredPointOffset {
+                    score: 40.0,
+                    idx: 5
+                },
+                ScoredPointOffset {
+                    score: -1.0,
+                    idx: 1
+                },
+            ]
+        );
+
+        // try again with pruning to show the problem
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                values: vec![-1.0, 1.0, 1.0],
+            },
+            2,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+        search_context.use_pruning = true;
+        assert!(search_context.use_pruning);
+
+        // the last value has been pruned although it could have contributed a high score -1 * -40 = 40
+        assert_eq!(
+            search_context.search(&match_all),
+            vec![
+                ScoredPointOffset {
+                    score: -1.0,
+                    idx: 1
+                },
+                ScoredPointOffset {
+                    score: -2.0,
+                    idx: 2
+                }
+            ]
+        );
     }
 
     /// Generates a random inverted index with `num_vectors` vectors

commit de390f51bfa39200fe443e981fab3e8d197f69fd
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Nov 20 15:58:10 2023 +0100

    Better heuristic for sparse vector pruning (#3048)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index be35b69b4..0481039ed 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -163,6 +163,7 @@ impl<'a> SearchContext<'a> {
         if self.postings_iterators.is_empty() {
             return Vec::new();
         }
+        let mut best_min_score = f32::MIN;
         while let Some(candidate) = self.advance() {
             // check for cancellation
             if self.is_stopped.load(Relaxed) {
@@ -179,13 +180,18 @@ impl<'a> SearchContext<'a> {
             // TODO(sparse) pruning is expensive, we should only do it when it makes sense (detect hot keys at runtime)
             if self.use_pruning && self.result_queue.len() == self.top {
                 // current min score
-                let min_score = self.result_queue.top().unwrap().score;
-
+                let new_min_score = self.result_queue.top().unwrap().score;
+                if new_min_score == best_min_score {
+                    // no improvement in lowest best score since last pruning - skip pruning
+                    continue;
+                } else {
+                    best_min_score = new_min_score;
+                }
                 // make sure the first posting list is the longest for pruning
                 self.promote_longest_posting_lists_to_the_front();
 
                 // prune posting list that cannot possibly contribute to the top results
-                self.prune_longest_posting_list(min_score);
+                self.prune_longest_posting_list(new_min_score);
             }
         }
         // posting iterators exhausted, return result queue

commit 2fae4e491d53476a3ab863e8f0feaaebede4b60f
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Nov 30 15:29:53 2023 +0100

    Plain search for inverted index (#3113)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 0481039ed..79905f202 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -55,6 +55,23 @@ impl<'a> SearchContext<'a> {
         }
     }
 
+    /// Return all results that overlap with the query vector
+    ///
+    /// The resulting sparse vectors are sorted by id and contains only values that overlap with the query vector
+    ///
+    /// This is a plain search without any pruning
+    fn plain_search(&mut self) -> Vec<(u32, SparseVector)> {
+        let mut result = Vec::new();
+        while let Some(next) = self.get_next() {
+            // check for cancellation
+            if self.is_stopped.load(Relaxed) {
+                break;
+            }
+            result.push(next);
+        }
+        result
+    }
+
     /// Advance posting lists iterators and return the next candidate by increasing ids.
     ///
     /// Example
@@ -108,6 +125,26 @@ impl<'a> SearchContext<'a> {
         })
     }
 
+    fn get_next(&mut self) -> Option<(u32, SparseVector)> {
+        let min_record_id = Self::next_min_id(&self.postings_iterators)?;
+        let mut indices = vec![];
+        let mut values = vec![];
+
+        // Iterate second time to advance posting iterators
+        for posting_iterator in self.postings_iterators.iter_mut() {
+            if let Some(element) = posting_iterator.posting_list_iterator.peek() {
+                // accumulate indices & values for the current record id
+                if element.record_id == min_record_id {
+                    let element = posting_iterator.posting_list_iterator.next().unwrap();
+                    indices.push(self.query.indices[posting_iterator.query_weight_offset]);
+                    values.push(element.weight)
+                }
+            }
+        }
+        let sparse_vector = SparseVector { indices, values };
+        Some((min_record_id, sparse_vector))
+    }
+
     /// Returns the next min record id from all posting list iterators
     ///
     /// returns None if all posting list iterators are exhausted
@@ -966,4 +1003,102 @@ mod tests {
             3
         );
     }
+
+    #[test]
+    fn plain_search_all_test() {
+        let is_stopped = AtomicBool::new(false);
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0)]))
+            .add(2, PostingList::from(vec![(1, 10.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 2, 3],
+                values: vec![1.0, 1.0, 1.0],
+            },
+            3,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        let sparse_vectors = search_context.plain_search();
+        assert_eq!(
+            sparse_vectors,
+            vec![
+                (
+                    1,
+                    SparseVector {
+                        indices: vec![1, 2, 3],
+                        values: vec![10.0, 10.0, 10.0]
+                    }
+                ),
+                (
+                    2,
+                    SparseVector {
+                        indices: vec![1, 3],
+                        values: vec![20.0, 20.0]
+                    }
+                ),
+                (
+                    3,
+                    SparseVector {
+                        indices: vec![2, 3],
+                        values: vec![30.0, 30.0]
+                    }
+                ),
+            ]
+        );
+    }
+
+    #[test]
+    fn plain_search_gap_test() {
+        let is_stopped = AtomicBool::new(false);
+        let inverted_index_ram = InvertedIndexBuilder::new()
+            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0)]))
+            .add(2, PostingList::from(vec![(1, 10.0), (3, 30.0)]))
+            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
+            .build();
+
+        // query vector has a gap for dimension 2
+        let mut search_context = SearchContext::new(
+            SparseVector {
+                indices: vec![1, 3],
+                values: vec![1.0, 1.0],
+            },
+            3,
+            &inverted_index_ram,
+            &is_stopped,
+        );
+
+        // the dimension 2 is absent in the result vectors
+        let sparse_vectors = search_context.plain_search();
+        assert_eq!(
+            sparse_vectors,
+            vec![
+                (
+                    1,
+                    SparseVector {
+                        indices: vec![1, 3],
+                        values: vec![10.0, 10.0]
+                    }
+                ),
+                (
+                    2,
+                    SparseVector {
+                        indices: vec![1, 3],
+                        values: vec![20.0, 20.0]
+                    }
+                ),
+                (
+                    3,
+                    SparseVector {
+                        indices: vec![3],
+                        values: vec![30.0]
+                    }
+                ),
+            ]
+        );
+    }
 }

commit 67b464174f38bc30ad254dead43de61f8c97bfc0
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Tue Dec 5 16:12:57 2023 +0100

    Plain search by ids in parse vector inverted index (#3161)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 79905f202..54a292408 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -55,21 +55,42 @@ impl<'a> SearchContext<'a> {
         }
     }
 
-    /// Return all results that overlap with the query vector
+    /// Score the query vector against the given ids.
     ///
-    /// The resulting sparse vectors are sorted by id and contains only values that overlap with the query vector
+    /// This is a plain search without any pruning.
     ///
-    /// This is a plain search without any pruning
-    fn plain_search(&mut self) -> Vec<(u32, SparseVector)> {
-        let mut result = Vec::new();
-        while let Some(next) = self.get_next() {
-            // check for cancellation
-            if self.is_stopped.load(Relaxed) {
-                break;
+    /// The results are not sorted.
+    fn plain_search(&mut self, ids: &[PointOffsetType]) -> Vec<ScoredPointOffset> {
+        let mut scores = Vec::with_capacity(ids.len());
+        for id in ids {
+            let mut indices = Vec::with_capacity(self.query.indices.len());
+            let mut values = Vec::with_capacity(self.query.values.len());
+            // collect indices and values for the current record id from the query's posting lists *only*
+            for posting_iterator in &self.postings_iterators {
+                // rely on binary search as the posting lists are sorted by record id
+                match posting_iterator
+                    .posting_list_iterator
+                    .elements
+                    .binary_search_by(|element| element.record_id.cmp(id))
+                {
+                    Err(_missing) => {} // no match for posting list
+                    Ok(element_index) => {
+                        // match for posting list
+                        let element =
+                            &posting_iterator.posting_list_iterator.elements[element_index];
+                        indices.push(self.query.indices[posting_iterator.query_weight_offset]);
+                        values.push(element.weight);
+                    }
+                }
             }
-            result.push(next);
+            // reconstruct sparse vector and score against query
+            let sparse_vector = SparseVector { indices, values };
+            scores.push(ScoredPointOffset {
+                score: sparse_vector.score(&self.query).unwrap_or(0.0),
+                idx: *id,
+            });
         }
-        result
+        scores
     }
 
     /// Advance posting lists iterators and return the next candidate by increasing ids.
@@ -125,26 +146,6 @@ impl<'a> SearchContext<'a> {
         })
     }
 
-    fn get_next(&mut self) -> Option<(u32, SparseVector)> {
-        let min_record_id = Self::next_min_id(&self.postings_iterators)?;
-        let mut indices = vec![];
-        let mut values = vec![];
-
-        // Iterate second time to advance posting iterators
-        for posting_iterator in self.postings_iterators.iter_mut() {
-            if let Some(element) = posting_iterator.posting_list_iterator.peek() {
-                // accumulate indices & values for the current record id
-                if element.record_id == min_record_id {
-                    let element = posting_iterator.posting_list_iterator.next().unwrap();
-                    indices.push(self.query.indices[posting_iterator.query_weight_offset]);
-                    values.push(element.weight)
-                }
-            }
-        }
-        let sparse_vector = SparseVector { indices, values };
-        Some((min_record_id, sparse_vector))
-    }
-
     /// Returns the next min record id from all posting list iterators
     ///
     /// returns None if all posting list iterators are exhausted
@@ -1023,31 +1024,22 @@ mod tests {
             &is_stopped,
         );
 
-        let sparse_vectors = search_context.plain_search();
+        let scores = search_context.plain_search(&[1, 2, 3]);
         assert_eq!(
-            sparse_vectors,
+            scores,
             vec![
-                (
-                    1,
-                    SparseVector {
-                        indices: vec![1, 2, 3],
-                        values: vec![10.0, 10.0, 10.0]
-                    }
-                ),
-                (
-                    2,
-                    SparseVector {
-                        indices: vec![1, 3],
-                        values: vec![20.0, 20.0]
-                    }
-                ),
-                (
-                    3,
-                    SparseVector {
-                        indices: vec![2, 3],
-                        values: vec![30.0, 30.0]
-                    }
-                ),
+                ScoredPointOffset {
+                    idx: 1,
+                    score: 30.0
+                },
+                ScoredPointOffset {
+                    idx: 2,
+                    score: 40.0
+                },
+                ScoredPointOffset {
+                    idx: 3,
+                    score: 60.0
+                }
             ]
         );
     }
@@ -1072,32 +1064,22 @@ mod tests {
             &is_stopped,
         );
 
-        // the dimension 2 is absent in the result vectors
-        let sparse_vectors = search_context.plain_search();
+        let scores = search_context.plain_search(&[1, 2, 3]);
         assert_eq!(
-            sparse_vectors,
+            scores,
             vec![
-                (
-                    1,
-                    SparseVector {
-                        indices: vec![1, 3],
-                        values: vec![10.0, 10.0]
-                    }
-                ),
-                (
-                    2,
-                    SparseVector {
-                        indices: vec![1, 3],
-                        values: vec![20.0, 20.0]
-                    }
-                ),
-                (
-                    3,
-                    SparseVector {
-                        indices: vec![3],
-                        values: vec![30.0]
-                    }
-                ),
+                ScoredPointOffset {
+                    idx: 1,
+                    score: 20.0 // the dimension 2 did not contribute to the score
+                },
+                ScoredPointOffset {
+                    idx: 2,
+                    score: 40.0
+                },
+                ScoredPointOffset {
+                    idx: 3,
+                    score: 30.0 // the dimension 2 did not contribute to the score
+                }
             ]
         );
     }

commit d5a705e0faaf667641b82e53708fb2119a44d272
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Tue Dec 5 20:32:23 2023 +0100

    Sparse vectors advanced search api support (#3128)
    
    * sparse vectors query scorer
    
    plain search test without internals
    
    fix sparse_vector_index_plain_search
    
    fix async scorer build
    
    fix unit tests
    
    are you happy fmt
    
    sparse index with full query support
    
    fix benches, use exact flag to force plain search
    
    add alias and comment to exact flag
    
    fix tests
    
    recommendations TODOs fix
    
    add simple test
    
    add todo
    
    refactor index
    
    test vs comparison dense and sparse discovery
    
    are you happy fmt
    
    propogate error from avg negatives
    
    reuse filtered points list
    
    rollback api changes
    
    better discovery test
    
    are you happy fmt
    
    rollback openapi
    
    fix build
    
    fix tests
    
    review remark recommendations
    
    review remarks
    
    review remarks
    
    codespell
    
    integrate plain search
    
    Update lib/collection/src/recommendations.rs
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    
    Update lib/collection/src/recommendations.rs
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    
    Update lib/collection/src/recommendations.rs
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    
    fix comment of plain search
    
    Update lib/collection/src/recommendations.rs
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    
    fix tests
    
    * simplify search query function

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 54a292408..4c532290f 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -55,14 +55,14 @@ impl<'a> SearchContext<'a> {
         }
     }
 
-    /// Score the query vector against the given ids.
-    ///
-    /// This is a plain search without any pruning.
-    ///
-    /// The results are not sorted.
-    fn plain_search(&mut self, ids: &[PointOffsetType]) -> Vec<ScoredPointOffset> {
-        let mut scores = Vec::with_capacity(ids.len());
+    /// Plain search against the given ids without any pruning
+    pub fn plain_search(&mut self, ids: &[PointOffsetType]) -> Vec<ScoredPointOffset> {
         for id in ids {
+            // check for cancellation
+            if self.is_stopped.load(Relaxed) {
+                break;
+            }
+
             let mut indices = Vec::with_capacity(self.query.indices.len());
             let mut values = Vec::with_capacity(self.query.values.len());
             // collect indices and values for the current record id from the query's posting lists *only*
@@ -85,12 +85,13 @@ impl<'a> SearchContext<'a> {
             }
             // reconstruct sparse vector and score against query
             let sparse_vector = SparseVector { indices, values };
-            scores.push(ScoredPointOffset {
+            self.result_queue.push(ScoredPointOffset {
                 score: sparse_vector.score(&self.query).unwrap_or(0.0),
                 idx: *id,
             });
         }
-        scores
+        let queue = std::mem::take(&mut self.result_queue);
+        queue.into_vec()
     }
 
     /// Advance posting lists iterators and return the next candidate by increasing ids.
@@ -1029,17 +1030,17 @@ mod tests {
             scores,
             vec![
                 ScoredPointOffset {
-                    idx: 1,
-                    score: 30.0
+                    idx: 3,
+                    score: 60.0
                 },
                 ScoredPointOffset {
                     idx: 2,
                     score: 40.0
                 },
                 ScoredPointOffset {
-                    idx: 3,
-                    score: 60.0
-                }
+                    idx: 1,
+                    score: 30.0
+                },
             ]
         );
     }
@@ -1068,10 +1069,6 @@ mod tests {
         assert_eq!(
             scores,
             vec![
-                ScoredPointOffset {
-                    idx: 1,
-                    score: 20.0 // the dimension 2 did not contribute to the score
-                },
                 ScoredPointOffset {
                     idx: 2,
                     score: 40.0
@@ -1079,7 +1076,11 @@ mod tests {
                 ScoredPointOffset {
                     idx: 3,
                     score: 30.0 // the dimension 2 did not contribute to the score
-                }
+                },
+                ScoredPointOffset {
+                    idx: 1,
+                    score: 20.0 // the dimension 2 did not contribute to the score
+                },
             ]
         );
     }

commit 2fdab78789298dace4a2ce2cd586be087b867bde
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Fri Dec 15 14:50:06 2023 +0000

    Faster sparse vectors plain search (#3231)
    
    * Faster sparse vectors plain search
    
    * no comments

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 4c532290f..e28a1743b 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -57,7 +57,11 @@ impl<'a> SearchContext<'a> {
 
     /// Plain search against the given ids without any pruning
     pub fn plain_search(&mut self, ids: &[PointOffsetType]) -> Vec<ScoredPointOffset> {
-        for id in ids {
+        // sort ids to fully leverage posting list iterator traversal
+        let mut sorted_ids = ids.to_vec();
+        sorted_ids.sort_unstable();
+
+        for id in sorted_ids {
             // check for cancellation
             if self.is_stopped.load(Relaxed) {
                 break;
@@ -66,18 +70,12 @@ impl<'a> SearchContext<'a> {
             let mut indices = Vec::with_capacity(self.query.indices.len());
             let mut values = Vec::with_capacity(self.query.values.len());
             // collect indices and values for the current record id from the query's posting lists *only*
-            for posting_iterator in &self.postings_iterators {
-                // rely on binary search as the posting lists are sorted by record id
-                match posting_iterator
-                    .posting_list_iterator
-                    .elements
-                    .binary_search_by(|element| element.record_id.cmp(id))
-                {
-                    Err(_missing) => {} // no match for posting list
-                    Ok(element_index) => {
+            for posting_iterator in self.postings_iterators.iter_mut() {
+                // rely on underlying binary search as the posting lists are sorted by record id
+                match posting_iterator.posting_list_iterator.skip_to(id) {
+                    None => {} // no match for posting list
+                    Some(element) => {
                         // match for posting list
-                        let element =
-                            &posting_iterator.posting_list_iterator.elements[element_index];
                         indices.push(self.query.indices[posting_iterator.query_weight_offset]);
                         values.push(element.weight);
                     }
@@ -87,7 +85,7 @@ impl<'a> SearchContext<'a> {
             let sparse_vector = SparseVector { indices, values };
             self.result_queue.push(ScoredPointOffset {
                 score: sparse_vector.score(&self.query).unwrap_or(0.0),
-                idx: *id,
+                idx: id,
             });
         }
         let queue = std::mem::take(&mut self.result_queue);
@@ -1025,7 +1023,7 @@ mod tests {
             &is_stopped,
         );
 
-        let scores = search_context.plain_search(&[1, 2, 3]);
+        let scores = search_context.plain_search(&[1, 3, 2]);
         assert_eq!(
             scores,
             vec![

commit b67a6d7f5c2cda7a1924c3b1d2b7a550e64c224e
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Dec 25 14:36:27 2023 +0100

    Optimize sparse inverted index advance (#3275)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index e28a1743b..d61c68e06 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -132,9 +132,10 @@ impl<'a> SearchContext<'a> {
             if let Some(element) = posting_iterator.posting_list_iterator.peek() {
                 // accumulate score for the current record id
                 if element.record_id == min_record_id {
-                    let element = posting_iterator.posting_list_iterator.next().unwrap();
                     score +=
                         element.weight * self.query.values[posting_iterator.query_weight_offset];
+                    // advance posting list iterator to next element
+                    posting_iterator.posting_list_iterator.advance();
                 }
             }
         }

commit da8eed2af0e06d9e371b314e6ecb26208ee824db
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Jan 8 10:27:54 2024 +0100

    Optimize sparse search by precomputing once the query info per posting interator (#3327)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index d61c68e06..17e8b60b3 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -6,12 +6,15 @@ use common::fixed_length_priority_queue::FixedLengthPriorityQueue;
 use common::types::{PointOffsetType, ScoredPointOffset};
 
 use crate::common::sparse_vector::SparseVector;
+use crate::common::types::{DimId, DimWeight};
 use crate::index::inverted_index::InvertedIndex;
 use crate::index::posting_list::PostingListIterator;
 
+/// Iterator over posting lists with a reference to the corresponding query index and weight
 pub struct IndexedPostingListIterator<'a> {
     posting_list_iterator: PostingListIterator<'a>,
-    query_weight_offset: usize,
+    query_index: DimId,
+    query_weight: DimWeight,
 }
 
 pub struct SearchContext<'a> {
@@ -34,9 +37,12 @@ impl<'a> SearchContext<'a> {
 
         for (query_weight_offset, id) in query.indices.iter().enumerate() {
             if let Some(posting_list_iterator) = inverted_index.get(id) {
+                let query_index = *id;
+                let query_weight = query.values[query_weight_offset];
                 postings_iterators.push(IndexedPostingListIterator {
                     posting_list_iterator,
-                    query_weight_offset,
+                    query_index,
+                    query_weight,
                 });
             }
         }
@@ -76,7 +82,7 @@ impl<'a> SearchContext<'a> {
                     None => {} // no match for posting list
                     Some(element) => {
                         // match for posting list
-                        indices.push(self.query.indices[posting_iterator.query_weight_offset]);
+                        indices.push(posting_iterator.query_index);
                         values.push(element.weight);
                     }
                 }
@@ -132,8 +138,7 @@ impl<'a> SearchContext<'a> {
             if let Some(element) = posting_iterator.posting_list_iterator.peek() {
                 // accumulate score for the current record id
                 if element.record_id == min_record_id {
-                    score +=
-                        element.weight * self.query.values[posting_iterator.query_weight_offset];
+                    score += element.weight * posting_iterator.query_weight;
                     // advance posting list iterator to next element
                     posting_iterator.posting_list_iterator.advance();
                 }
@@ -259,13 +264,12 @@ impl<'a> SearchContext<'a> {
                         }
                         Ordering::Greater => {
                             // next_min_id is > element.record_id there is a chance to prune up to `next_min_id`
-                            let posting_query_offset = longest_posting_iterator.query_weight_offset;
                             // check against the max possible score using the `max_next_weight`
                             // we can under prune as we should actually check the best score up to `next_min_id` - 1 only
                             // instead of the max possible score but it is not possible to know the best score up to `next_min_id` - 1
                             let max_weight_from_list = element.weight.max(element.max_next_weight);
                             let max_score_contribution =
-                                max_weight_from_list * self.query.values[posting_query_offset];
+                                max_weight_from_list * longest_posting_iterator.query_weight;
                             if max_score_contribution <= min_score {
                                 // prune to next_min_id
                                 let longest_posting_iterator =
@@ -282,11 +286,10 @@ impl<'a> SearchContext<'a> {
                 }
                 None => {
                     // the current posting list is the only one left, we can potentially skip it to the end
-                    let posting_query_offset = longest_posting_iterator.query_weight_offset;
                     // check against the max possible score using the `max_next_weight`
                     let max_weight_from_list = element.weight.max(element.max_next_weight);
                     let max_score_contribution =
-                        max_weight_from_list * self.query.values[posting_query_offset];
+                        max_weight_from_list * longest_posting_iterator.query_weight;
                     if max_score_contribution <= min_score {
                         // prune to the end!
                         let longest_posting_iterator = &mut self.postings_iterators[0];

commit 3bcb7a51229abcec6ce58d76547bcfdb35c49d61
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Jan 8 12:58:01 2024 +0100

    Check cancellation after filtering condition to speedup filtered sparse search (#3348)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 17e8b60b3..12a282fed 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -208,14 +208,14 @@ impl<'a> SearchContext<'a> {
         }
         let mut best_min_score = f32::MIN;
         while let Some(candidate) = self.advance() {
-            // check for cancellation
-            if self.is_stopped.load(Relaxed) {
-                break;
-            }
             // check filter condition
             if !filter_condition(candidate.idx) {
                 continue;
             }
+            // check for cancellation
+            if self.is_stopped.load(Relaxed) {
+                break;
+            }
             // push candidate to result queue
             self.result_queue.push(candidate);
 

commit f92a9af6d8a1657dabdc2b02883f9b37fc80581f
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Jan 10 08:25:20 2024 +0100

    Optimize inverted index search by tracking min record ids (#3347)
    
    * single pass for min record_id with look-ahead
    
    * Optimize inverted index by tracking min record ids in BinaryHeap

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 12a282fed..f519ae513 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -23,6 +23,7 @@ pub struct SearchContext<'a> {
     top: usize,
     is_stopped: &'a AtomicBool,
     result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
+    min_record_ids: FixedLengthPriorityQueue<PointOffsetType>, // min record ids across all posting lists
     use_pruning: bool,
 }
 
@@ -51,12 +52,20 @@ impl<'a> SearchContext<'a> {
         // The max contribution per posting list that we calculate is not made to compute the max value of two negative numbers.
         // This is a limitation of the current pruning implementation.
         let use_pruning = query.values.iter().all(|v| *v >= 0.0);
+        // find min record id across all posting lists
+        let mut min_record_ids = FixedLengthPriorityQueue::new(query.indices.len());
+        for posting_iterator in postings_iterators.iter() {
+            if let Some(element) = posting_iterator.posting_list_iterator.peek() {
+                min_record_ids.push(element.record_id);
+            }
+        }
         SearchContext {
             postings_iterators,
             query,
             top,
             is_stopped,
             result_queue,
+            min_record_ids,
             use_pruning,
         }
     }
@@ -130,24 +139,31 @@ impl<'a> SearchContext<'a> {
     /// b,  21, 34, 60, 200
     /// b,  30, 34, 60, 230
     fn advance(&mut self) -> Option<ScoredPointOffset> {
-        let min_record_id = Self::next_min_id(&self.postings_iterators)?;
+        // Get current min record id from all posting list iterators
+        let current_min_record_id = *self.min_record_ids.peek()?;
         let mut score = 0.0;
 
-        // Iterate second time to advance posting iterators
+        // Iterate to advance matching posting iterators
         for posting_iterator in self.postings_iterators.iter_mut() {
             if let Some(element) = posting_iterator.posting_list_iterator.peek() {
                 // accumulate score for the current record id
-                if element.record_id == min_record_id {
+                if element.record_id == current_min_record_id {
                     score += element.weight * posting_iterator.query_weight;
                     // advance posting list iterator to next element
                     posting_iterator.posting_list_iterator.advance();
+                    // pop min record id
+                    self.min_record_ids.pop();
+                    // look-ahead to find next min record id
+                    if let Some(next_element) = posting_iterator.posting_list_iterator.peek() {
+                        self.min_record_ids.push(next_element.record_id);
+                    }
                 }
             }
         }
 
         Some(ScoredPointOffset {
             score,
-            idx: min_record_id,
+            idx: current_min_record_id,
         })
     }
 
@@ -234,7 +250,16 @@ impl<'a> SearchContext<'a> {
                 self.promote_longest_posting_lists_to_the_front();
 
                 // prune posting list that cannot possibly contribute to the top results
-                self.prune_longest_posting_list(new_min_score);
+                let pruned = self.prune_longest_posting_list(new_min_score);
+                if pruned {
+                    // recompute new min record id for next iteration
+                    // the pruned posting list is always at the head and with the lowest record_id
+                    self.min_record_ids.pop();
+                    let new_min = self.postings_iterators[0].posting_list_iterator.peek();
+                    if let Some(next_element) = new_min {
+                        self.min_record_ids.push(next_element.record_id);
+                    }
+                }
             }
         }
         // posting iterators exhausted, return result queue

commit 7ceaf73a464e5d24f7414f8354e96c48608f9953
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Jan 10 11:28:53 2024 +0100

    Handle empty sparse vector search (#3368)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index f519ae513..59bee1677 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,4 +1,4 @@
-use std::cmp::Ordering;
+use std::cmp::{max, Ordering};
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
@@ -53,7 +53,7 @@ impl<'a> SearchContext<'a> {
         // This is a limitation of the current pruning implementation.
         let use_pruning = query.values.iter().all(|v| *v >= 0.0);
         // find min record id across all posting lists
-        let mut min_record_ids = FixedLengthPriorityQueue::new(query.indices.len());
+        let mut min_record_ids = FixedLengthPriorityQueue::new(max(query.indices.len(), 1));
         for posting_iterator in postings_iterators.iter() {
             if let Some(element) = posting_iterator.posting_list_iterator.peek() {
                 min_record_ids.push(element.record_id);
@@ -344,6 +344,19 @@ mod tests {
     };
     use crate::index::posting_list::PostingList;
 
+    #[test]
+    fn test_empty_query() {
+        let is_stopped = AtomicBool::new(false);
+        let index = InvertedIndexRam::empty();
+        let mut search_context = SearchContext::new(
+            SparseVector::default(), // empty query vector
+            10,
+            &index,
+            &is_stopped,
+        );
+        assert_eq!(search_context.search(&match_all), Vec::new());
+    }
+
     /// Match all filter condition for testing
     fn match_all(_p: PointOffsetType) -> bool {
         true

commit 3c87260a019c27c2904854cd0070a9f2c2e7fd2c
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Jan 17 11:02:55 2024 +0100

    Optimize sparse vector for real life distribution (#3393)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 59bee1677..a8873cb4c 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,4 +1,4 @@
-use std::cmp::{max, Ordering};
+use std::cmp::Ordering;
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
@@ -23,7 +23,7 @@ pub struct SearchContext<'a> {
     top: usize,
     is_stopped: &'a AtomicBool,
     result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
-    min_record_ids: FixedLengthPriorityQueue<PointOffsetType>, // min record ids across all posting lists
+    min_record_id: Option<PointOffsetType>, // min record ids across all posting lists
     use_pruning: bool,
 }
 
@@ -53,19 +53,14 @@ impl<'a> SearchContext<'a> {
         // This is a limitation of the current pruning implementation.
         let use_pruning = query.values.iter().all(|v| *v >= 0.0);
         // find min record id across all posting lists
-        let mut min_record_ids = FixedLengthPriorityQueue::new(max(query.indices.len(), 1));
-        for posting_iterator in postings_iterators.iter() {
-            if let Some(element) = posting_iterator.posting_list_iterator.peek() {
-                min_record_ids.push(element.record_id);
-            }
-        }
+        let min_record_id = Self::next_min_id(&postings_iterators);
         SearchContext {
             postings_iterators,
             query,
             top,
             is_stopped,
             result_queue,
-            min_record_ids,
+            min_record_id,
             use_pruning,
         }
     }
@@ -140,27 +135,32 @@ impl<'a> SearchContext<'a> {
     /// b,  30, 34, 60, 230
     fn advance(&mut self) -> Option<ScoredPointOffset> {
         // Get current min record id from all posting list iterators
-        let current_min_record_id = *self.min_record_ids.peek()?;
+        let current_min_record_id = self.min_record_id?;
         let mut score = 0.0;
-
+        let mut found = false;
         // Iterate to advance matching posting iterators
         for posting_iterator in self.postings_iterators.iter_mut() {
             if let Some(element) = posting_iterator.posting_list_iterator.peek() {
                 // accumulate score for the current record id
                 if element.record_id == current_min_record_id {
+                    found = true;
                     score += element.weight * posting_iterator.query_weight;
                     // advance posting list iterator to next element
                     posting_iterator.posting_list_iterator.advance();
-                    // pop min record id
-                    self.min_record_ids.pop();
-                    // look-ahead to find next min record id
-                    if let Some(next_element) = posting_iterator.posting_list_iterator.peek() {
-                        self.min_record_ids.push(next_element.record_id);
-                    }
                 }
             }
         }
 
+        // update min record id for next iteration
+        if found {
+            // assume the next min record id is the current one + 1
+            self.min_record_id = self.min_record_id.map(|min_id| min_id + 1);
+        } else {
+            // no match found, compute next min record id from all posting list iterators
+            self.min_record_id = Self::next_min_id(&self.postings_iterators);
+            return self.advance();
+        }
+
         Some(ScoredPointOffset {
             score,
             idx: current_min_record_id,
@@ -254,11 +254,7 @@ impl<'a> SearchContext<'a> {
                 if pruned {
                     // recompute new min record id for next iteration
                     // the pruned posting list is always at the head and with the lowest record_id
-                    self.min_record_ids.pop();
-                    let new_min = self.postings_iterators[0].posting_list_iterator.peek();
-                    if let Some(next_element) = new_min {
-                        self.min_record_ids.push(next_element.record_id);
-                    }
+                    self.min_record_id = Self::next_min_id(&self.postings_iterators);
                 }
             }
         }

commit c6fc008f0e0aef776db98893209ad847090bb8ba
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Jan 18 09:12:59 2024 +0100

    Optimize sparse search by deleting empty postings (#3413)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index a8873cb4c..53b0feea8 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -24,6 +24,7 @@ pub struct SearchContext<'a> {
     is_stopped: &'a AtomicBool,
     result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
     min_record_id: Option<PointOffsetType>, // min record ids across all posting lists
+    contains_empty_posting: bool, // whether the posting list iterators contain exhausted posting lists
     use_pruning: bool,
 }
 
@@ -54,6 +55,8 @@ impl<'a> SearchContext<'a> {
         let use_pruning = query.values.iter().all(|v| *v >= 0.0);
         // find min record id across all posting lists
         let min_record_id = Self::next_min_id(&postings_iterators);
+        // no empty posting lists at the beginning
+        let contains_empty_posting = false;
         SearchContext {
             postings_iterators,
             query,
@@ -61,6 +64,7 @@ impl<'a> SearchContext<'a> {
             is_stopped,
             result_queue,
             min_record_id,
+            contains_empty_posting,
             use_pruning,
         }
     }
@@ -148,6 +152,9 @@ impl<'a> SearchContext<'a> {
                     // advance posting list iterator to next element
                     posting_iterator.posting_list_iterator.advance();
                 }
+            } else {
+                // mark search context for cleanup if any posting list iterator is exhausted
+                self.contains_empty_posting = true;
             }
         }
 
@@ -235,6 +242,15 @@ impl<'a> SearchContext<'a> {
             // push candidate to result queue
             self.result_queue.push(candidate);
 
+            // remove empty posting lists if necessary
+            if self.contains_empty_posting {
+                self.postings_iterators.retain(|posting_iterator| {
+                    posting_iterator.posting_list_iterator.len_to_end() != 0
+                });
+                // reset flag
+                self.contains_empty_posting = false;
+            }
+
             // we potentially have enough results to prune low performing posting lists
             // TODO(sparse) pruning is expensive, we should only do it when it makes sense (detect hot keys at runtime)
             if self.use_pruning && self.result_queue.len() == self.top {
@@ -267,6 +283,9 @@ impl<'a> SearchContext<'a> {
     /// Assumes longest posting list is at the head of the posting list iterators
     /// Returns true if the longest posting list was pruned
     pub fn prune_longest_posting_list(&mut self, min_score: f32) -> bool {
+        if self.postings_iterators.is_empty() {
+            return false;
+        }
         // peek first element of longest posting list
         let longest_posting_iterator = &self.postings_iterators[0];
         if let Some(element) = longest_posting_iterator.posting_list_iterator.peek() {

commit 64a024ba5139e398fb21c033013da51267df38ad
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Fri Jan 19 14:04:07 2024 +0100

    Optimize sparse search reaching single posting list (#3424)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 53b0feea8..da3a85c01 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -174,6 +174,23 @@ impl<'a> SearchContext<'a> {
         })
     }
 
+    /// Compute scores for the last posting list quickly
+    fn process_last_posting_list<F: Fn(PointOffsetType) -> bool>(&mut self, filter_condition: &F) {
+        debug_assert_eq!(self.postings_iterators.len(), 1);
+        let posting = &self.postings_iterators[0];
+        for element in posting.posting_list_iterator.remaining_elements() {
+            // do not score if filter condition is not satisfied
+            if !filter_condition(element.record_id) {
+                continue;
+            }
+            let score = element.weight * posting.query_weight;
+            self.result_queue.push(ScoredPointOffset {
+                score,
+                idx: element.record_id,
+            });
+        }
+    }
+
     /// Returns the next min record id from all posting list iterators
     ///
     /// returns None if all posting list iterators are exhausted
@@ -249,10 +266,14 @@ impl<'a> SearchContext<'a> {
                 });
                 // reset flag
                 self.contains_empty_posting = false;
+                // if only one posting list left, we can score it quickly
+                if self.postings_iterators.len() == 1 {
+                    self.process_last_posting_list(filter_condition);
+                    break;
+                }
             }
 
             // we potentially have enough results to prune low performing posting lists
-            // TODO(sparse) pruning is expensive, we should only do it when it makes sense (detect hot keys at runtime)
             if self.use_pruning && self.result_queue.len() == self.top {
                 // current min score
                 let new_min_score = self.result_queue.top().unwrap().score;

commit 7d6a0972e8f1faa2c648b252e62f17fcf1354fe5
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Feb 5 15:47:11 2024 +0100

    Optimize sparse vector search with batched scoring (#3464)
    
    * Optimize sparse vector search with batched scoring
    
    * replace roaring bitmap by id generation
    
    * compute intersections in Vec instead of Map
    
    * cargo update ahash@0.8.7 --precise 0.8.5
    
    * let rustc handle the pattern match optimization
    
    * profiling done
    
    * remove Option and filter out zero scores
    
    * restore integration test assertion
    
    * filter based on min score to avoid work
    
    * decrease batch size and cleanup posting creation
    
    * remove outdated tests
    
    * remove dead test - I know where to find it if I need it

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index da3a85c01..310a8e088 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,9 +1,9 @@
-use std::cmp::Ordering;
+use std::cmp::{max, min, Ordering};
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
 use common::fixed_length_priority_queue::FixedLengthPriorityQueue;
-use common::types::{PointOffsetType, ScoredPointOffset};
+use common::types::{PointOffsetType, ScoreType, ScoredPointOffset};
 
 use crate::common::sparse_vector::SparseVector;
 use crate::common::types::{DimId, DimWeight};
@@ -17,14 +17,18 @@ pub struct IndexedPostingListIterator<'a> {
     query_weight: DimWeight,
 }
 
+/// Making this larger makes the search faster but uses more memory
+const ADVANCE_BATCH_SIZE: usize = 1_000;
+
 pub struct SearchContext<'a> {
     postings_iterators: Vec<IndexedPostingListIterator<'a>>,
     query: SparseVector,
     top: usize,
     is_stopped: &'a AtomicBool,
     result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
-    min_record_id: Option<PointOffsetType>, // min record ids across all posting lists
-    contains_empty_posting: bool, // whether the posting list iterators contain exhausted posting lists
+    min_record_id: Option<u32>, // min_record_id ids across all posting lists
+    max_record_id: u32,         // max_record_id ids across all posting lists
+    batch_scores: Vec<ScoreType>, // scores for the current batch
     use_pruning: bool,
 }
 
@@ -36,16 +40,32 @@ impl<'a> SearchContext<'a> {
         is_stopped: &'a AtomicBool,
     ) -> SearchContext<'a> {
         let mut postings_iterators = Vec::new();
-
+        // track min and max record ids across all posting lists
+        let mut max_record_id = 0;
+        let mut min_record_id = u32::MAX;
+        // iterate over query indices
         for (query_weight_offset, id) in query.indices.iter().enumerate() {
             if let Some(posting_list_iterator) = inverted_index.get(id) {
-                let query_index = *id;
-                let query_weight = query.values[query_weight_offset];
-                postings_iterators.push(IndexedPostingListIterator {
-                    posting_list_iterator,
-                    query_index,
-                    query_weight,
-                });
+                let posting_elements = posting_list_iterator.elements;
+                if !posting_elements.is_empty() {
+                    // check if new min
+                    let min_record_id_posting = posting_elements[0].record_id;
+                    min_record_id = min(min_record_id, min_record_id_posting);
+
+                    // check if new max
+                    let max_record_id_posting = posting_elements.last().unwrap().record_id;
+                    max_record_id = max(max_record_id, max_record_id_posting);
+
+                    // capture query info
+                    let query_index = *id;
+                    let query_weight = query.values[query_weight_offset];
+
+                    postings_iterators.push(IndexedPostingListIterator {
+                        posting_list_iterator,
+                        query_index,
+                        query_weight,
+                    });
+                }
             }
         }
         let result_queue = FixedLengthPriorityQueue::new(top);
@@ -53,10 +73,9 @@ impl<'a> SearchContext<'a> {
         // The max contribution per posting list that we calculate is not made to compute the max value of two negative numbers.
         // This is a limitation of the current pruning implementation.
         let use_pruning = query.values.iter().all(|v| *v >= 0.0);
-        // find min record id across all posting lists
-        let min_record_id = Self::next_min_id(&postings_iterators);
-        // no empty posting lists at the beginning
-        let contains_empty_posting = false;
+        // TODO pool this Vec to reuse memory across searches
+        let batch_scores = Vec::with_capacity(ADVANCE_BATCH_SIZE);
+        let min_record_id = Some(min_record_id);
         SearchContext {
             postings_iterators,
             query,
@@ -64,7 +83,8 @@ impl<'a> SearchContext<'a> {
             is_stopped,
             result_queue,
             min_record_id,
-            contains_empty_posting,
+            max_record_id,
+            batch_scores,
             use_pruning,
         }
     }
@@ -106,72 +126,49 @@ impl<'a> SearchContext<'a> {
         queue.into_vec()
     }
 
-    /// Advance posting lists iterators and return the next candidate by increasing ids.
-    ///
-    /// Example
-    ///
-    /// postings_iterators:
-    ///
-    /// 1,  30, 34, 60, 230
-    /// 10, 30, 35, 51, 230
-    /// 2,  21, 34, 60, 200
-    /// 2,  30, 34, 60, 230
-    ///
-    /// Next:
-    ///
-    /// a,  30, 34, 60, 230
-    /// 10, 30, 35, 51, 230
-    /// 2,  21, 34, 60, 200
-    /// 2,  30, 34, 60, 230
-    ///
-    /// Next:
-    ///
-    /// a,  30, 34, 60, 230
-    /// 10, 30, 35, 51, 230
-    /// b,  21, 34, 60, 200
-    /// b,  30, 34, 60, 230
-    ///
-    /// Next:
-    ///
-    /// a,  30, 34, 60, 230
-    /// c,  30, 35, 51, 230
-    /// b,  21, 34, 60, 200
-    /// b,  30, 34, 60, 230
-    fn advance(&mut self) -> Option<ScoredPointOffset> {
-        // Get current min record id from all posting list iterators
-        let current_min_record_id = self.min_record_id?;
-        let mut score = 0.0;
-        let mut found = false;
-        // Iterate to advance matching posting iterators
-        for posting_iterator in self.postings_iterators.iter_mut() {
-            if let Some(element) = posting_iterator.posting_list_iterator.peek() {
-                // accumulate score for the current record id
-                if element.record_id == current_min_record_id {
-                    found = true;
-                    score += element.weight * posting_iterator.query_weight;
-                    // advance posting list iterator to next element
-                    posting_iterator.posting_list_iterator.advance();
+    /// Advance posting lists iterators in a batch fashion.
+    fn advance_batch<F: Fn(PointOffsetType) -> bool>(
+        &mut self,
+        batch_start_id: PointOffsetType,
+        batch_last_id: PointOffsetType,
+        filter_condition: &F,
+    ) {
+        for posting in self.postings_iterators.iter_mut() {
+            for element in posting.posting_list_iterator.remaining_elements() {
+                let element_id = element.record_id;
+                if element_id > batch_last_id {
+                    // reaching end of the batch
+                    break;
                 }
-            } else {
-                // mark search context for cleanup if any posting list iterator is exhausted
-                self.contains_empty_posting = true;
+                let element_score = element.weight * posting.query_weight;
+                // update score for id
+                let local_id = (element_id - batch_start_id) as usize;
+                self.batch_scores[local_id] += element_score;
             }
+            // advance posting to the batch last id
+            posting.posting_list_iterator.skip_to(batch_last_id + 1);
         }
 
-        // update min record id for next iteration
-        if found {
-            // assume the next min record id is the current one + 1
-            self.min_record_id = self.min_record_id.map(|min_id| min_id + 1);
+        // publish only the non-zero scores above the current min
+        let min_score_to_beat = if self.result_queue.len() == self.top {
+            self.result_queue.top().map(|e| e.score)
         } else {
-            // no match found, compute next min record id from all posting list iterators
-            self.min_record_id = Self::next_min_id(&self.postings_iterators);
-            return self.advance();
+            None
+        };
+        for (local_index, &score) in self.batch_scores.iter().enumerate() {
+            if score != 0.0 && Some(score) > min_score_to_beat {
+                let real_id = batch_start_id + local_index as PointOffsetType;
+                // do not score if filter condition is not satisfied
+                if !filter_condition(real_id) {
+                    continue;
+                }
+                let score_point_offset = ScoredPointOffset {
+                    score,
+                    idx: real_id,
+                };
+                self.result_queue.push(score_point_offset);
+            }
         }
-
-        Some(ScoredPointOffset {
-            score,
-            idx: current_min_record_id,
-        })
     }
 
     /// Compute scores for the last posting list quickly
@@ -247,30 +244,49 @@ impl<'a> SearchContext<'a> {
             return Vec::new();
         }
         let mut best_min_score = f32::MIN;
-        while let Some(candidate) = self.advance() {
-            // check filter condition
-            if !filter_condition(candidate.idx) {
-                continue;
-            }
-            // check for cancellation
+        loop {
+            // check for cancellation (atomic amortized by batch)
             if self.is_stopped.load(Relaxed) {
                 break;
             }
-            // push candidate to result queue
-            self.result_queue.push(candidate);
+
+            // prepare next iterator of batched ids
+            let start_batch_id = match self.min_record_id {
+                Some(min_id) => min_id,
+                None => break, // all posting lists exhausted
+            };
+
+            // compute batch range of contiguous ids for the next batch
+            let last_batch_id = min(
+                start_batch_id + ADVANCE_BATCH_SIZE as u32,
+                self.max_record_id,
+            );
+            let batch_len = last_batch_id - start_batch_id + 1;
+
+            // init batch scores
+            self.batch_scores.clear();
+            self.batch_scores.resize(batch_len as usize, 0.0);
+
+            // advance and score posting lists iterators
+            self.advance_batch(start_batch_id, last_batch_id, filter_condition);
 
             // remove empty posting lists if necessary
-            if self.contains_empty_posting {
-                self.postings_iterators.retain(|posting_iterator| {
-                    posting_iterator.posting_list_iterator.len_to_end() != 0
-                });
-                // reset flag
-                self.contains_empty_posting = false;
-                // if only one posting list left, we can score it quickly
-                if self.postings_iterators.len() == 1 {
-                    self.process_last_posting_list(filter_condition);
-                    break;
-                }
+            self.postings_iterators.retain(|posting_iterator| {
+                posting_iterator.posting_list_iterator.len_to_end() != 0
+            });
+
+            // update min_record_id
+            self.min_record_id = Self::next_min_id(&self.postings_iterators);
+
+            // check if all posting lists are exhausted
+            if self.postings_iterators.is_empty() {
+                break;
+            }
+
+            // if only one posting list left, we can score it quickly
+            if self.postings_iterators.len() == 1 {
+                self.process_last_posting_list(filter_condition);
+                break;
             }
 
             // we potentially have enough results to prune low performing posting lists
@@ -289,8 +305,7 @@ impl<'a> SearchContext<'a> {
                 // prune posting list that cannot possibly contribute to the top results
                 let pruned = self.prune_longest_posting_list(new_min_score);
                 if pruned {
-                    // recompute new min record id for next iteration
-                    // the pruned posting list is always at the head and with the lowest record_id
+                    // update min_record_id
                     self.min_record_id = Self::next_min_id(&self.postings_iterators);
                 }
             }
@@ -367,10 +382,7 @@ impl<'a> SearchContext<'a> {
 
 #[cfg(test)]
 mod tests {
-    use std::collections::HashSet;
-
-    use rand::rngs::StdRng;
-    use rand::{Rng, SeedableRng};
+    use rand::Rng;
 
     use super::*;
     use crate::common::sparse_vector_fixture::random_sparse_vector;
@@ -398,62 +410,6 @@ mod tests {
         true
     }
 
-    fn _advance_test(inverted_index: &impl InvertedIndex) {
-        let is_stopped = AtomicBool::new(false);
-        let mut search_context = SearchContext::new(
-            SparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            10,
-            inverted_index,
-            &is_stopped,
-        );
-
-        assert_eq!(
-            search_context.advance(),
-            Some(ScoredPointOffset {
-                score: 30.0,
-                idx: 1
-            })
-        );
-        assert_eq!(
-            search_context.advance(),
-            Some(ScoredPointOffset {
-                score: 60.0,
-                idx: 2
-            })
-        );
-        assert_eq!(
-            search_context.advance(),
-            Some(ScoredPointOffset {
-                score: 90.0,
-                idx: 3
-            })
-        );
-    }
-
-    #[test]
-    fn advance_test() {
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
-
-        // test with ram index
-        _advance_test(&inverted_index_ram);
-
-        // test with mmap index
-        let tmp_dir_path = tempfile::Builder::new()
-            .prefix("test_index_dir")
-            .tempdir()
-            .unwrap();
-        let inverted_index_mmap =
-            InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
-        _advance_test(&inverted_index_mmap);
-    }
-
     fn _search_test(inverted_index: &impl InvertedIndex) {
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
@@ -678,124 +634,6 @@ mod tests {
         _search_with_hot_key_test(&inverted_index_mmap);
     }
 
-    fn _prune_test(inverted_index: &impl InvertedIndex) {
-        let is_stopped = AtomicBool::new(false);
-        let mut search_context = SearchContext::new(
-            SparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            3,
-            inverted_index,
-            &is_stopped,
-        );
-
-        // initial state
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            9
-        );
-        assert_eq!(
-            search_context.advance(),
-            Some(ScoredPointOffset {
-                score: 30.0,
-                idx: 1
-            })
-        );
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            8
-        );
-        assert!(!search_context.prune_longest_posting_list(30.0));
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            8
-        );
-
-        assert_eq!(
-            search_context.advance(),
-            Some(ScoredPointOffset {
-                score: 60.0,
-                idx: 2
-            })
-        );
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            7
-        );
-        assert!(!search_context.prune_longest_posting_list(30.0));
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            7
-        );
-
-        assert_eq!(
-            search_context.advance(),
-            Some(ScoredPointOffset {
-                score: 90.0,
-                idx: 3
-            })
-        );
-        // pruning can take place
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            6
-        );
-        assert!(search_context.prune_longest_posting_list(30.0));
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            0
-        );
-    }
-
-    #[test]
-    fn prune_test() {
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(
-                1,
-                PostingList::from(vec![
-                    (1, 10.0),
-                    (2, 20.0),
-                    (3, 30.0),
-                    (4, 1.0),
-                    (5, 2.0),
-                    (6, 3.0),
-                    (7, 4.0),
-                    (8, 5.0),
-                    (9, 6.0),
-                ]),
-            )
-            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
-
-        // test with ram index
-        _prune_test(&inverted_index_ram);
-
-        // test with mmap index
-        let tmp_dir_path = tempfile::Builder::new()
-            .prefix("test_index_dir")
-            .tempdir()
-            .unwrap();
-        let inverted_index_mmap =
-            InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
-        _prune_test(&inverted_index_mmap);
-    }
-
     #[test]
     fn pruning_single_to_end_test() {
         let inverted_index_ram = InvertedIndexBuilder::new()
@@ -900,71 +738,6 @@ mod tests {
         );
     }
 
-    #[test]
-    fn pruning_does_not_skip_negative_score_test() {
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(
-                1,
-                PostingList::from(vec![(1, 1.0), (2, 2.0), (3, 3.0), (4, 1.0), (5, -40.0)]),
-            )
-            .build();
-
-        let is_stopped = AtomicBool::new(false);
-        let mut search_context = SearchContext::new(
-            SparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![-1.0, 1.0, 1.0],
-            },
-            2,
-            &inverted_index_ram,
-            &is_stopped,
-        );
-
-        // pruning is automatically deactivated because the query vector contains negative values
-        assert!(!search_context.use_pruning);
-        assert_eq!(
-            search_context.search(&match_all),
-            vec![
-                ScoredPointOffset {
-                    score: 40.0,
-                    idx: 5
-                },
-                ScoredPointOffset {
-                    score: -1.0,
-                    idx: 1
-                },
-            ]
-        );
-
-        // try again with pruning to show the problem
-        let mut search_context = SearchContext::new(
-            SparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![-1.0, 1.0, 1.0],
-            },
-            2,
-            &inverted_index_ram,
-            &is_stopped,
-        );
-        search_context.use_pruning = true;
-        assert!(search_context.use_pruning);
-
-        // the last value has been pruned although it could have contributed a high score -1 * -40 = 40
-        assert_eq!(
-            search_context.search(&match_all),
-            vec![
-                ScoredPointOffset {
-                    score: -1.0,
-                    idx: 1
-                },
-                ScoredPointOffset {
-                    score: -2.0,
-                    idx: 2
-                }
-            ]
-        );
-    }
-
     /// Generates a random inverted index with `num_vectors` vectors
     fn random_inverted_index<R: Rng + ?Sized>(
         rnd_gen: &mut R,
@@ -980,72 +753,6 @@ mod tests {
         inverted_index_ram
     }
 
-    #[test]
-    fn next_min_partial_scan_test() {
-        let num_vectors = 100;
-        let max_sparse_dimension = 25;
-        let mut rnd = StdRng::seed_from_u64(42);
-        let is_stopped = AtomicBool::new(false);
-        let inverted_index_ram = random_inverted_index(&mut rnd, num_vectors, max_sparse_dimension);
-        let mut search_context = SearchContext::new(
-            SparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            3,
-            &inverted_index_ram,
-            &is_stopped,
-        );
-
-        let mut all_next_min_observed = HashSet::new();
-
-        while let Some(next_min) =
-            SearchContext::next_min_id(search_context.postings_iterators.as_slice())
-        {
-            all_next_min_observed.insert(next_min);
-            let next_candidate_id = search_context.advance().map(|s| s.idx);
-            assert_eq!(next_candidate_id, Some(next_min));
-        }
-
-        // Not all vectors are observed because only the indices of the query vector are explored.
-        assert!(all_next_min_observed.len() < num_vectors as usize);
-    }
-
-    #[test]
-    fn next_min_full_scan_test() {
-        let num_vectors = 100;
-        let max_sparse_dimension = 25;
-        let mut rnd = StdRng::seed_from_u64(42);
-        let is_stopped = AtomicBool::new(false);
-        let inverted_index_ram = random_inverted_index(&mut rnd, num_vectors, max_sparse_dimension);
-        let mut search_context = SearchContext::new(
-            SparseVector {
-                indices: (1..=max_sparse_dimension as u32).collect(),
-                values: vec![1.0; max_sparse_dimension],
-            },
-            3,
-            &inverted_index_ram,
-            &is_stopped,
-        );
-
-        // initial state
-        let min = SearchContext::next_min_id(search_context.postings_iterators.as_slice());
-        // no side effect
-        assert_eq!(min, Some(1));
-        assert_eq!(min, Some(1));
-
-        // Complete scan over all vectors because the query vector contains all dimensions in the index.
-        for i in 1..num_vectors {
-            let before_min =
-                SearchContext::next_min_id(search_context.postings_iterators.as_slice());
-            assert_eq!(before_min, Some(i));
-            let next = search_context.advance().map(|s| s.idx);
-            assert_eq!(next, Some(i));
-            let new_min = SearchContext::next_min_id(search_context.postings_iterators.as_slice());
-            assert_eq!(new_min, Some(i + 1));
-        }
-    }
-
     #[test]
     fn promote_longest_test() {
         let is_stopped = AtomicBool::new(false);

commit a51275b476b958a1db2a7de5298d8662d292c9e8
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Tue Feb 6 16:04:45 2024 +0100

    Optimize sparse search by advancing postings without binary search (#3527)
    
    * Optimize search by advancing posting list with binary search
    
    * better name for offset

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 310a8e088..a38d95c88 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -134,10 +134,18 @@ impl<'a> SearchContext<'a> {
         filter_condition: &F,
     ) {
         for posting in self.postings_iterators.iter_mut() {
-            for element in posting.posting_list_iterator.remaining_elements() {
+            // offset at which the posting list stops contributing to the batch (relative to the batch start)
+            let mut posting_stopped_at = None;
+            for (offset, element) in posting
+                .posting_list_iterator
+                .remaining_elements()
+                .iter()
+                .enumerate()
+            {
                 let element_id = element.record_id;
                 if element_id > batch_last_id {
                     // reaching end of the batch
+                    posting_stopped_at = Some(offset);
                     break;
                 }
                 let element_score = element.weight * posting.query_weight;
@@ -145,8 +153,17 @@ impl<'a> SearchContext<'a> {
                 let local_id = (element_id - batch_start_id) as usize;
                 self.batch_scores[local_id] += element_score;
             }
-            // advance posting to the batch last id
-            posting.posting_list_iterator.skip_to(batch_last_id + 1);
+            // advance posting list iterator
+            match posting_stopped_at {
+                None => {
+                    // posting list is exhausted before reaching the end of the batch
+                    posting.posting_list_iterator.skip_to_end();
+                }
+                Some(stopped_at) => {
+                    // posting list is not exhausted - advance to last id
+                    posting.posting_list_iterator.advance_by(stopped_at)
+                }
+            };
         }
 
         // publish only the non-zero scores above the current min

commit 02004c87209f0ea3d4d7c452b9dec951840cb6a2
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Feb 12 14:58:03 2024 +0100

    Pool larger memory batches for sparse vector search (#3560)
    
    * Pool larger memory batches for sparse vector search
    
    * rework naming
    
    * refine naming
    
    * address great comments
    
    * bump ADVANCE_BATCH_SIZE to use power of 2
    
    * 16k performs bad - trying 8k
    
    * 10k offers the best tradeoff

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index a38d95c88..3dc611b06 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -3,8 +3,9 @@ use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
 use common::fixed_length_priority_queue::FixedLengthPriorityQueue;
-use common::types::{PointOffsetType, ScoreType, ScoredPointOffset};
+use common::types::{PointOffsetType, ScoredPointOffset};
 
+use crate::common::scores_memory_pool::PooledScoresHandle;
 use crate::common::sparse_vector::SparseVector;
 use crate::common::types::{DimId, DimWeight};
 use crate::index::inverted_index::InvertedIndex;
@@ -17,28 +18,29 @@ pub struct IndexedPostingListIterator<'a> {
     query_weight: DimWeight,
 }
 
-/// Making this larger makes the search faster but uses more memory
-const ADVANCE_BATCH_SIZE: usize = 1_000;
+/// Making this larger makes the search faster but uses more (pooled) memory
+const ADVANCE_BATCH_SIZE: usize = 10_000;
 
-pub struct SearchContext<'a> {
+pub struct SearchContext<'a, 'b> {
     postings_iterators: Vec<IndexedPostingListIterator<'a>>,
     query: SparseVector,
     top: usize,
     is_stopped: &'a AtomicBool,
     result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
-    min_record_id: Option<u32>, // min_record_id ids across all posting lists
-    max_record_id: u32,         // max_record_id ids across all posting lists
-    batch_scores: Vec<ScoreType>, // scores for the current batch
+    min_record_id: Option<PointOffsetType>, // min_record_id ids across all posting lists
+    max_record_id: PointOffsetType,         // max_record_id ids across all posting lists
+    pooled: PooledScoresHandle<'b>,         // handle to pooled scores
     use_pruning: bool,
 }
 
-impl<'a> SearchContext<'a> {
+impl<'a, 'b> SearchContext<'a, 'b> {
     pub fn new(
         query: SparseVector,
         top: usize,
         inverted_index: &'a impl InvertedIndex,
+        pooled: PooledScoresHandle<'b>,
         is_stopped: &'a AtomicBool,
-    ) -> SearchContext<'a> {
+    ) -> SearchContext<'a, 'b> {
         let mut postings_iterators = Vec::new();
         // track min and max record ids across all posting lists
         let mut max_record_id = 0;
@@ -73,8 +75,6 @@ impl<'a> SearchContext<'a> {
         // The max contribution per posting list that we calculate is not made to compute the max value of two negative numbers.
         // This is a limitation of the current pruning implementation.
         let use_pruning = query.values.iter().all(|v| *v >= 0.0);
-        // TODO pool this Vec to reuse memory across searches
-        let batch_scores = Vec::with_capacity(ADVANCE_BATCH_SIZE);
         let min_record_id = Some(min_record_id);
         SearchContext {
             postings_iterators,
@@ -84,7 +84,7 @@ impl<'a> SearchContext<'a> {
             result_queue,
             min_record_id,
             max_record_id,
-            batch_scores,
+            pooled,
             use_pruning,
         }
     }
@@ -133,6 +133,11 @@ impl<'a> SearchContext<'a> {
         batch_last_id: PointOffsetType,
         filter_condition: &F,
     ) {
+        // init batch scores
+        let batch_len = batch_last_id - batch_start_id + 1;
+        self.pooled.scores.clear(); // keep underlying allocated memory
+        self.pooled.scores.resize(batch_len as usize, 0.0);
+
         for posting in self.postings_iterators.iter_mut() {
             // offset at which the posting list stops contributing to the batch (relative to the batch start)
             let mut posting_stopped_at = None;
@@ -151,7 +156,7 @@ impl<'a> SearchContext<'a> {
                 let element_score = element.weight * posting.query_weight;
                 // update score for id
                 let local_id = (element_id - batch_start_id) as usize;
-                self.batch_scores[local_id] += element_score;
+                self.pooled.scores[local_id] += element_score;
             }
             // advance posting list iterator
             match posting_stopped_at {
@@ -172,7 +177,7 @@ impl<'a> SearchContext<'a> {
         } else {
             None
         };
-        for (local_index, &score) in self.batch_scores.iter().enumerate() {
+        for (local_index, &score) in self.pooled.scores.iter().enumerate() {
             if score != 0.0 && Some(score) > min_score_to_beat {
                 let real_id = batch_start_id + local_index as PointOffsetType;
                 // do not score if filter condition is not satisfied
@@ -208,7 +213,7 @@ impl<'a> SearchContext<'a> {
     /// Returns the next min record id from all posting list iterators
     ///
     /// returns None if all posting list iterators are exhausted
-    fn next_min_id(to_inspect: &[IndexedPostingListIterator<'_>]) -> Option<u32> {
+    fn next_min_id(to_inspect: &[IndexedPostingListIterator<'_>]) -> Option<PointOffsetType> {
         let mut min_record_id = None;
 
         // Iterate to find min record id at the head of the posting lists
@@ -278,11 +283,6 @@ impl<'a> SearchContext<'a> {
                 start_batch_id + ADVANCE_BATCH_SIZE as u32,
                 self.max_record_id,
             );
-            let batch_len = last_batch_id - start_batch_id + 1;
-
-            // init batch scores
-            self.batch_scores.clear();
-            self.batch_scores.resize(batch_len as usize, 0.0);
 
             // advance and score posting lists iterators
             self.advance_batch(start_batch_id, last_batch_id, filter_condition);
@@ -399,9 +399,12 @@ impl<'a> SearchContext<'a> {
 
 #[cfg(test)]
 mod tests {
+    use std::sync::OnceLock;
+
     use rand::Rng;
 
     use super::*;
+    use crate::common::scores_memory_pool::ScoresMemoryPool;
     use crate::common::sparse_vector_fixture::random_sparse_vector;
     use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
     use crate::index::inverted_index::inverted_index_ram::{
@@ -409,6 +412,14 @@ mod tests {
     };
     use crate::index::posting_list::PostingList;
 
+    static TEST_SCORES_POOL: OnceLock<ScoresMemoryPool> = OnceLock::new();
+
+    fn get_pooled_scores() -> PooledScoresHandle<'static> {
+        TEST_SCORES_POOL
+            .get_or_init(ScoresMemoryPool::default)
+            .get()
+    }
+
     #[test]
     fn test_empty_query() {
         let is_stopped = AtomicBool::new(false);
@@ -417,6 +428,7 @@ mod tests {
             SparseVector::default(), // empty query vector
             10,
             &index,
+            get_pooled_scores(),
             &is_stopped,
         );
         assert_eq!(search_context.search(&match_all), Vec::new());
@@ -436,6 +448,7 @@ mod tests {
             },
             10,
             inverted_index,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -495,6 +508,7 @@ mod tests {
             },
             10,
             &inverted_index_ram,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -531,6 +545,7 @@ mod tests {
             },
             10,
             &inverted_index_ram,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -566,6 +581,7 @@ mod tests {
             },
             3,
             inverted_index,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -594,6 +610,7 @@ mod tests {
             },
             4,
             inverted_index,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -665,6 +682,7 @@ mod tests {
             },
             1,
             &inverted_index_ram,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -698,6 +716,7 @@ mod tests {
             },
             1,
             &inverted_index_ram,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -738,6 +757,7 @@ mod tests {
             },
             1,
             &inverted_index_ram,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -786,6 +806,7 @@ mod tests {
             },
             3,
             &inverted_index_ram,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -822,6 +843,7 @@ mod tests {
             },
             3,
             &inverted_index_ram,
+            get_pooled_scores(),
             &is_stopped,
         );
 
@@ -862,6 +884,7 @@ mod tests {
             },
             3,
             &inverted_index_ram,
+            get_pooled_scores(),
             &is_stopped,
         );
 

commit 6705f817320865b0bf8fcf09cdd339dabf029632
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Tue Feb 20 12:01:42 2024 +0100

    Optimize sparse vector index build time (#3605)
    
    * Optimize sparse vector index build time
    
    * rework index builder to reuse posting list builder
    
    * remove unecessary change
    
    * make it shorter

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 3dc611b06..cc2d45b0e 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -407,10 +407,8 @@ mod tests {
     use crate::common::scores_memory_pool::ScoresMemoryPool;
     use crate::common::sparse_vector_fixture::random_sparse_vector;
     use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
-    use crate::index::inverted_index::inverted_index_ram::{
-        InvertedIndexBuilder, InvertedIndexRam,
-    };
-    use crate::index::posting_list::PostingList;
+    use crate::index::inverted_index::inverted_index_ram::InvertedIndexRam;
+    use crate::index::inverted_index::inverted_index_ram_builder::InvertedIndexBuilder;
 
     static TEST_SCORES_POOL: OnceLock<ScoresMemoryPool> = OnceLock::new();
 
@@ -473,11 +471,11 @@ mod tests {
 
     #[test]
     fn search_test() {
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+        builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
+        builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
+        let inverted_index_ram = builder.build();
 
         // test with ram index
         _search_test(&inverted_index_ram);
@@ -495,11 +493,11 @@ mod tests {
     #[test]
     fn search_with_update_test() {
         let is_stopped = AtomicBool::new(false);
-        let mut inverted_index_ram = InvertedIndexBuilder::new()
-            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+        builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
+        builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
+        let mut inverted_index_ram = builder.build();
 
         let mut search_context = SearchContext::new(
             SparseVector {
@@ -636,24 +634,17 @@ mod tests {
 
     #[test]
     fn search_with_hot_key_test() {
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(
-                1,
-                PostingList::from(vec![
-                    (1, 10.0),
-                    (2, 20.0),
-                    (3, 30.0),
-                    (4, 1.0),
-                    (5, 2.0),
-                    (6, 3.0),
-                    (7, 4.0),
-                    (8, 5.0),
-                    (9, 6.0),
-                ]),
-            )
-            .add(2, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+        builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
+        builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
+        builder.add(4, [(1, 1.0)].into());
+        builder.add(5, [(1, 2.0)].into());
+        builder.add(6, [(1, 3.0)].into());
+        builder.add(7, [(1, 4.0)].into());
+        builder.add(8, [(1, 5.0)].into());
+        builder.add(9, [(1, 6.0)].into());
+        let inverted_index_ram = builder.build();
 
         // test with ram index
         _search_with_hot_key_test(&inverted_index_ram);
@@ -670,9 +661,11 @@ mod tests {
 
     #[test]
     fn pruning_single_to_end_test() {
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0)].into());
+        builder.add(2, [(1, 20.0)].into());
+        builder.add(3, [(1, 30.0)].into());
+        let inverted_index_ram = builder.build();
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
@@ -699,14 +692,14 @@ mod tests {
 
     #[test]
     fn pruning_multi_to_end_test() {
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(
-                1,
-                PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0), (4, 10.0)]),
-            )
-            .add(2, PostingList::from(vec![(6, 20.0), (7, 30.0)]))
-            .add(3, PostingList::from(vec![(5, 10.0), (6, 20.0), (7, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0)].into());
+        builder.add(2, [(1, 20.0)].into());
+        builder.add(3, [(1, 30.0)].into());
+        builder.add(5, [(3, 10.0)].into());
+        builder.add(6, [(2, 20.0), (3, 20.0)].into());
+        builder.add(7, [(2, 30.0), (3, 30.0)].into());
+        let inverted_index_ram = builder.build();
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
@@ -733,21 +726,15 @@ mod tests {
 
     #[test]
     fn pruning_multi_under_prune_test() {
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(
-                1,
-                PostingList::from(vec![
-                    (1, 10.0),
-                    (2, 20.0),
-                    (3, 20.0),
-                    (4, 10.0),
-                    (6, 20.0),
-                    (7, 40.0),
-                ]),
-            )
-            .add(2, PostingList::from(vec![(6, 20.0), (7, 30.0)]))
-            .add(3, PostingList::from(vec![(5, 10.0), (6, 20.0), (7, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0)].into());
+        builder.add(2, [(1, 20.0)].into());
+        builder.add(3, [(1, 20.0)].into());
+        builder.add(4, [(1, 10.0)].into());
+        builder.add(5, [(3, 10.0)].into());
+        builder.add(6, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
+        builder.add(7, [(1, 40.0), (2, 30.0), (3, 30.0)].into());
+        let inverted_index_ram = builder.build();
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
@@ -793,11 +780,11 @@ mod tests {
     #[test]
     fn promote_longest_test() {
         let is_stopped = AtomicBool::new(false);
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0)]))
-            .add(2, PostingList::from(vec![(1, 10.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+        builder.add(2, [(1, 20.0), (3, 20.0)].into());
+        builder.add(3, [(2, 30.0), (3, 30.0)].into());
+        let inverted_index_ram = builder.build();
 
         let mut search_context = SearchContext::new(
             SparseVector {
@@ -830,11 +817,11 @@ mod tests {
     #[test]
     fn plain_search_all_test() {
         let is_stopped = AtomicBool::new(false);
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0)]))
-            .add(2, PostingList::from(vec![(1, 10.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+        builder.add(2, [(1, 20.0), (3, 20.0)].into());
+        builder.add(3, [(1, 30.0), (3, 30.0)].into());
+        let inverted_index_ram = builder.build();
 
         let mut search_context = SearchContext::new(
             SparseVector {
@@ -870,11 +857,11 @@ mod tests {
     #[test]
     fn plain_search_gap_test() {
         let is_stopped = AtomicBool::new(false);
-        let inverted_index_ram = InvertedIndexBuilder::new()
-            .add(1, PostingList::from(vec![(1, 10.0), (2, 20.0)]))
-            .add(2, PostingList::from(vec![(1, 10.0), (3, 30.0)]))
-            .add(3, PostingList::from(vec![(1, 10.0), (2, 20.0), (3, 30.0)]))
-            .build();
+        let mut builder = InvertedIndexBuilder::new();
+        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+        builder.add(2, [(1, 20.0), (3, 20.0)].into());
+        builder.add(3, [(2, 30.0), (3, 30.0)].into());
+        let inverted_index_ram = builder.build();
 
         // query vector has a gap for dimension 2
         let mut search_context = SearchContext::new(

commit 0cfb3b0e1d579e5ce633432f640a7f25b6437740
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Fri Apr 19 13:27:21 2024 +0200

    Median based TopK for sparse vectors scoring (#4037)
    
    * Median based TopK for sparse vectors scoring
    
    * add test with identical scores

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index cc2d45b0e..7a9758675 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -2,7 +2,7 @@ use std::cmp::{max, min, Ordering};
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
-use common::fixed_length_priority_queue::FixedLengthPriorityQueue;
+use common::top_k::TopK;
 use common::types::{PointOffsetType, ScoredPointOffset};
 
 use crate::common::scores_memory_pool::PooledScoresHandle;
@@ -26,7 +26,7 @@ pub struct SearchContext<'a, 'b> {
     query: SparseVector,
     top: usize,
     is_stopped: &'a AtomicBool,
-    result_queue: FixedLengthPriorityQueue<ScoredPointOffset>, // keep the largest elements and peek smallest
+    top_results: TopK,
     min_record_id: Option<PointOffsetType>, // min_record_id ids across all posting lists
     max_record_id: PointOffsetType,         // max_record_id ids across all posting lists
     pooled: PooledScoresHandle<'b>,         // handle to pooled scores
@@ -70,7 +70,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
                 }
             }
         }
-        let result_queue = FixedLengthPriorityQueue::new(top);
+        let top_results = TopK::new(top);
         // Query vectors with negative values can NOT use the pruning mechanism which relies on the pre-computed `max_next_weight`.
         // The max contribution per posting list that we calculate is not made to compute the max value of two negative numbers.
         // This is a limitation of the current pruning implementation.
@@ -81,7 +81,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
             query,
             top,
             is_stopped,
-            result_queue,
+            top_results,
             min_record_id,
             max_record_id,
             pooled,
@@ -117,13 +117,13 @@ impl<'a, 'b> SearchContext<'a, 'b> {
             }
             // reconstruct sparse vector and score against query
             let sparse_vector = SparseVector { indices, values };
-            self.result_queue.push(ScoredPointOffset {
+            self.top_results.push(ScoredPointOffset {
                 score: sparse_vector.score(&self.query).unwrap_or(0.0),
                 idx: id,
             });
         }
-        let queue = std::mem::take(&mut self.result_queue);
-        queue.into_vec()
+        let top = std::mem::take(&mut self.top_results);
+        top.into_vec()
     }
 
     /// Advance posting lists iterators in a batch fashion.
@@ -171,14 +171,9 @@ impl<'a, 'b> SearchContext<'a, 'b> {
             };
         }
 
-        // publish only the non-zero scores above the current min
-        let min_score_to_beat = if self.result_queue.len() == self.top {
-            self.result_queue.top().map(|e| e.score)
-        } else {
-            None
-        };
         for (local_index, &score) in self.pooled.scores.iter().enumerate() {
-            if score != 0.0 && Some(score) > min_score_to_beat {
+            // publish only the non-zero scores above the current min to beat
+            if score != 0.0 && score > self.top_results.threshold() {
                 let real_id = batch_start_id + local_index as PointOffsetType;
                 // do not score if filter condition is not satisfied
                 if !filter_condition(real_id) {
@@ -188,7 +183,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
                     score,
                     idx: real_id,
                 };
-                self.result_queue.push(score_point_offset);
+                self.top_results.push(score_point_offset);
             }
         }
     }
@@ -203,7 +198,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
                 continue;
             }
             let score = element.weight * posting.query_weight;
-            self.result_queue.push(ScoredPointOffset {
+            self.top_results.push(ScoredPointOffset {
                 score,
                 idx: element.record_id,
             });
@@ -307,9 +302,9 @@ impl<'a, 'b> SearchContext<'a, 'b> {
             }
 
             // we potentially have enough results to prune low performing posting lists
-            if self.use_pruning && self.result_queue.len() == self.top {
+            if self.use_pruning && self.top_results.len() >= self.top {
                 // current min score
-                let new_min_score = self.result_queue.top().unwrap().score;
+                let new_min_score = self.top_results.threshold();
                 if new_min_score == best_min_score {
                     // no improvement in lowest best score since last pruning - skip pruning
                     continue;
@@ -328,7 +323,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
             }
         }
         // posting iterators exhausted, return result queue
-        let queue = std::mem::take(&mut self.result_queue);
+        let queue = std::mem::take(&mut self.top_results);
         queue.into_vec()
     }
 

commit 896cfe109d9a6dd5a9a4ab39422899d6d238a5c6
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Apr 29 14:54:14 2024 +0200

    Sparse idf dot (#4126)
    
    * introduce QueryContext, which accumulates runtime info needed for executing search
    
    * fmt
    
    * propagate query context into segment internals
    
    * [WIP] prepare idf stats for search query context
    
    * Split SparseVector and RemmapedSparseVector to guarantee we will not mix them up on the type level
    
    * implement filling of the query context with IDF statistics
    
    * implement re-weighting of the sparse query with idf
    
    * fmt
    
    * update idf param only if explicitly specified (more consistent with diff param update
    
    * replace idf bool with modifier enum, improve further extensibility
    
    * test and fixes
    
    * Update lib/collection/src/operations/types.rs
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    
    * review fixes
    
    * fmt
    
    ---------
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 7a9758675..573b18018 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -6,7 +6,7 @@ use common::top_k::TopK;
 use common::types::{PointOffsetType, ScoredPointOffset};
 
 use crate::common::scores_memory_pool::PooledScoresHandle;
-use crate::common::sparse_vector::SparseVector;
+use crate::common::sparse_vector::RemappedSparseVector;
 use crate::common::types::{DimId, DimWeight};
 use crate::index::inverted_index::InvertedIndex;
 use crate::index::posting_list::PostingListIterator;
@@ -23,7 +23,7 @@ const ADVANCE_BATCH_SIZE: usize = 10_000;
 
 pub struct SearchContext<'a, 'b> {
     postings_iterators: Vec<IndexedPostingListIterator<'a>>,
-    query: SparseVector,
+    query: RemappedSparseVector,
     top: usize,
     is_stopped: &'a AtomicBool,
     top_results: TopK,
@@ -35,7 +35,7 @@ pub struct SearchContext<'a, 'b> {
 
 impl<'a, 'b> SearchContext<'a, 'b> {
     pub fn new(
-        query: SparseVector,
+        query: RemappedSparseVector,
         top: usize,
         inverted_index: &'a impl InvertedIndex,
         pooled: PooledScoresHandle<'b>,
@@ -116,7 +116,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
                 }
             }
             // reconstruct sparse vector and score against query
-            let sparse_vector = SparseVector { indices, values };
+            let sparse_vector = RemappedSparseVector { indices, values };
             self.top_results.push(ScoredPointOffset {
                 score: sparse_vector.score(&self.query).unwrap_or(0.0),
                 idx: id,
@@ -400,6 +400,7 @@ mod tests {
 
     use super::*;
     use crate::common::scores_memory_pool::ScoresMemoryPool;
+    use crate::common::sparse_vector::SparseVector;
     use crate::common::sparse_vector_fixture::random_sparse_vector;
     use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
     use crate::index::inverted_index::inverted_index_ram::InvertedIndexRam;
@@ -418,7 +419,7 @@ mod tests {
         let is_stopped = AtomicBool::new(false);
         let index = InvertedIndexRam::empty();
         let mut search_context = SearchContext::new(
-            SparseVector::default(), // empty query vector
+            RemappedSparseVector::default(), // empty query vector
             10,
             &index,
             get_pooled_scores(),
@@ -435,7 +436,7 @@ mod tests {
     fn _search_test(inverted_index: &impl InvertedIndex) {
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -495,7 +496,7 @@ mod tests {
         let mut inverted_index_ram = builder.build();
 
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -526,13 +527,13 @@ mod tests {
         // update index with new point
         inverted_index_ram.upsert(
             4,
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![40.0, 40.0, 40.0],
             },
         );
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -568,7 +569,7 @@ mod tests {
     fn _search_with_hot_key_test(inverted_index: &impl InvertedIndex) {
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -597,7 +598,7 @@ mod tests {
         );
 
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -664,7 +665,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -698,7 +699,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -733,7 +734,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -766,7 +767,9 @@ mod tests {
         let mut inverted_index_ram = InvertedIndexRam::empty();
 
         for i in 1..=num_vectors {
-            let vector = random_sparse_vector(rnd_gen, max_sparse_dimension);
+            let SparseVector { indices, values } =
+                random_sparse_vector(rnd_gen, max_sparse_dimension);
+            let vector = RemappedSparseVector::new(indices, values).unwrap();
             inverted_index_ram.upsert(i, vector);
         }
         inverted_index_ram
@@ -782,7 +785,7 @@ mod tests {
         let inverted_index_ram = builder.build();
 
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -819,7 +822,7 @@ mod tests {
         let inverted_index_ram = builder.build();
 
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
@@ -860,7 +863,7 @@ mod tests {
 
         // query vector has a gap for dimension 2
         let mut search_context = SearchContext::new(
-            SparseVector {
+            RemappedSparseVector {
                 indices: vec![1, 3],
                 values: vec![1.0, 1.0],
             },

commit 3b778fec2b771a8c1f349bad5ca7a63983cd5fff
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Wed May 22 18:18:20 2024 +0000

    Compressed posting lists (#4253)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 573b18018..6a80bb215 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,10 +1,12 @@
 use std::cmp::{max, min, Ordering};
+use std::ops::ControlFlow;
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
 use common::top_k::TopK;
 use common::types::{PointOffsetType, ScoredPointOffset};
 
+use super::posting_list_common::PostingListIter;
 use crate::common::scores_memory_pool::PooledScoresHandle;
 use crate::common::sparse_vector::RemappedSparseVector;
 use crate::common::types::{DimId, DimWeight};
@@ -12,8 +14,8 @@ use crate::index::inverted_index::InvertedIndex;
 use crate::index::posting_list::PostingListIterator;
 
 /// Iterator over posting lists with a reference to the corresponding query index and weight
-pub struct IndexedPostingListIterator<'a> {
-    posting_list_iterator: PostingListIterator<'a>,
+pub struct IndexedPostingListIterator<T: PostingListIter> {
+    posting_list_iterator: T,
     query_index: DimId,
     query_weight: DimWeight,
 }
@@ -21,8 +23,8 @@ pub struct IndexedPostingListIterator<'a> {
 /// Making this larger makes the search faster but uses more (pooled) memory
 const ADVANCE_BATCH_SIZE: usize = 10_000;
 
-pub struct SearchContext<'a, 'b> {
-    postings_iterators: Vec<IndexedPostingListIterator<'a>>,
+pub struct SearchContext<'a, 'b, T: PostingListIter = PostingListIterator<'a>> {
+    postings_iterators: Vec<IndexedPostingListIterator<T>>,
     query: RemappedSparseVector,
     top: usize,
     is_stopped: &'a AtomicBool,
@@ -33,29 +35,28 @@ pub struct SearchContext<'a, 'b> {
     use_pruning: bool,
 }
 
-impl<'a, 'b> SearchContext<'a, 'b> {
+impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
     pub fn new(
         query: RemappedSparseVector,
         top: usize,
-        inverted_index: &'a impl InvertedIndex,
+        inverted_index: &'a impl InvertedIndex<Iter<'a> = T>,
         pooled: PooledScoresHandle<'b>,
         is_stopped: &'a AtomicBool,
-    ) -> SearchContext<'a, 'b> {
+    ) -> SearchContext<'a, 'b, T> {
         let mut postings_iterators = Vec::new();
         // track min and max record ids across all posting lists
         let mut max_record_id = 0;
         let mut min_record_id = u32::MAX;
         // iterate over query indices
         for (query_weight_offset, id) in query.indices.iter().enumerate() {
-            if let Some(posting_list_iterator) = inverted_index.get(id) {
-                let posting_elements = posting_list_iterator.elements;
-                if !posting_elements.is_empty() {
+            if let Some(mut it) = inverted_index.get(id) {
+                if let (Some(first), Some(last_id)) = (it.peek(), it.last_id()) {
                     // check if new min
-                    let min_record_id_posting = posting_elements[0].record_id;
+                    let min_record_id_posting = first.record_id;
                     min_record_id = min(min_record_id, min_record_id_posting);
 
                     // check if new max
-                    let max_record_id_posting = posting_elements.last().unwrap().record_id;
+                    let max_record_id_posting = last_id;
                     max_record_id = max(max_record_id, max_record_id_posting);
 
                     // capture query info
@@ -63,7 +64,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
                     let query_weight = query.values[query_weight_offset];
 
                     postings_iterators.push(IndexedPostingListIterator {
-                        posting_list_iterator,
+                        posting_list_iterator: it,
                         query_index,
                         query_weight,
                     });
@@ -74,7 +75,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
         // Query vectors with negative values can NOT use the pruning mechanism which relies on the pre-computed `max_next_weight`.
         // The max contribution per posting list that we calculate is not made to compute the max value of two negative numbers.
         // This is a limitation of the current pruning implementation.
-        let use_pruning = query.values.iter().all(|v| *v >= 0.0);
+        let use_pruning = T::reliable_max_next_weight() && query.values.iter().all(|v| *v >= 0.0);
         let min_record_id = Some(min_record_id);
         SearchContext {
             postings_iterators,
@@ -139,36 +140,19 @@ impl<'a, 'b> SearchContext<'a, 'b> {
         self.pooled.scores.resize(batch_len as usize, 0.0);
 
         for posting in self.postings_iterators.iter_mut() {
-            // offset at which the posting list stops contributing to the batch (relative to the batch start)
-            let mut posting_stopped_at = None;
-            for (offset, element) in posting
-                .posting_list_iterator
-                .remaining_elements()
-                .iter()
-                .enumerate()
-            {
+            posting.posting_list_iterator.try_for_each(|element| {
                 let element_id = element.record_id;
                 if element_id > batch_last_id {
                     // reaching end of the batch
-                    posting_stopped_at = Some(offset);
-                    break;
-                }
-                let element_score = element.weight * posting.query_weight;
-                // update score for id
-                let local_id = (element_id - batch_start_id) as usize;
-                self.pooled.scores[local_id] += element_score;
-            }
-            // advance posting list iterator
-            match posting_stopped_at {
-                None => {
-                    // posting list is exhausted before reaching the end of the batch
-                    posting.posting_list_iterator.skip_to_end();
-                }
-                Some(stopped_at) => {
-                    // posting list is not exhausted - advance to last id
-                    posting.posting_list_iterator.advance_by(stopped_at)
+                    ControlFlow::Break(())
+                } else {
+                    let element_score = element.weight * posting.query_weight;
+                    // update score for id
+                    let local_id = (element_id - batch_start_id) as usize;
+                    self.pooled.scores[local_id] += element_score;
+                    ControlFlow::Continue(())
                 }
-            };
+            });
         }
 
         for (local_index, &score) in self.pooled.scores.iter().enumerate() {
@@ -191,28 +175,29 @@ impl<'a, 'b> SearchContext<'a, 'b> {
     /// Compute scores for the last posting list quickly
     fn process_last_posting_list<F: Fn(PointOffsetType) -> bool>(&mut self, filter_condition: &F) {
         debug_assert_eq!(self.postings_iterators.len(), 1);
-        let posting = &self.postings_iterators[0];
-        for element in posting.posting_list_iterator.remaining_elements() {
+        let posting = &mut self.postings_iterators[0];
+        posting.posting_list_iterator.try_for_each(|element| {
             // do not score if filter condition is not satisfied
             if !filter_condition(element.record_id) {
-                continue;
+                return ControlFlow::Continue(());
             }
             let score = element.weight * posting.query_weight;
             self.top_results.push(ScoredPointOffset {
                 score,
                 idx: element.record_id,
             });
-        }
+            ControlFlow::<()>::Continue(())
+        });
     }
 
     /// Returns the next min record id from all posting list iterators
     ///
     /// returns None if all posting list iterators are exhausted
-    fn next_min_id(to_inspect: &[IndexedPostingListIterator<'_>]) -> Option<PointOffsetType> {
+    fn next_min_id(to_inspect: &mut [IndexedPostingListIterator<T>]) -> Option<PointOffsetType> {
         let mut min_record_id = None;
 
         // Iterate to find min record id at the head of the posting lists
-        for posting_iterator in to_inspect.iter() {
+        for posting_iterator in to_inspect.iter_mut() {
             if let Some(next_element) = posting_iterator.posting_list_iterator.peek() {
                 match min_record_id {
                     None => min_record_id = Some(next_element.record_id), // first record with matching id
@@ -288,7 +273,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
             });
 
             // update min_record_id
-            self.min_record_id = Self::next_min_id(&self.postings_iterators);
+            self.min_record_id = Self::next_min_id(&mut self.postings_iterators);
 
             // check if all posting lists are exhausted
             if self.postings_iterators.is_empty() {
@@ -318,7 +303,7 @@ impl<'a, 'b> SearchContext<'a, 'b> {
                 let pruned = self.prune_longest_posting_list(new_min_score);
                 if pruned {
                     // update min_record_id
-                    self.min_record_id = Self::next_min_id(&self.postings_iterators);
+                    self.min_record_id = Self::next_min_id(&mut self.postings_iterators);
                 }
             }
         }
@@ -335,9 +320,10 @@ impl<'a, 'b> SearchContext<'a, 'b> {
             return false;
         }
         // peek first element of longest posting list
-        let longest_posting_iterator = &self.postings_iterators[0];
+        let (longest_posting_iterator, rest_iterators) = self.postings_iterators.split_at_mut(1);
+        let longest_posting_iterator = &mut longest_posting_iterator[0];
         if let Some(element) = longest_posting_iterator.posting_list_iterator.peek() {
-            let next_min_id_in_others = Self::next_min_id(&self.postings_iterators[1..]);
+            let next_min_id_in_others = Self::next_min_id(rest_iterators);
             match next_min_id_in_others {
                 Some(next_min_id) => {
                     match next_min_id.cmp(&element.record_id) {
@@ -363,9 +349,10 @@ impl<'a, 'b> SearchContext<'a, 'b> {
                                 let longest_posting_iterator =
                                     &mut self.postings_iterators[0].posting_list_iterator;
                                 let position_before_pruning =
-                                    longest_posting_iterator.current_index;
+                                    longest_posting_iterator.current_index();
                                 longest_posting_iterator.skip_to(next_min_id);
-                                let position_after_pruning = longest_posting_iterator.current_index;
+                                let position_after_pruning =
+                                    longest_posting_iterator.current_index();
                                 // check if pruning took place
                                 return position_before_pruning != position_after_pruning;
                             }

commit da6853576234413b65596a3ccab6b1da497fd493
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Thu May 30 13:30:24 2024 +0000

    Improve performance of compressed posting list (#4350)
    
    * Improve performance of compressed posting list
    
    * Merge `compressed_idx` and `remainders_idx`

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 6a80bb215..b9c31a865 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,5 +1,4 @@
 use std::cmp::{max, min, Ordering};
-use std::ops::ControlFlow;
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
@@ -140,19 +139,18 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         self.pooled.scores.resize(batch_len as usize, 0.0);
 
         for posting in self.postings_iterators.iter_mut() {
-            posting.posting_list_iterator.try_for_each(|element| {
-                let element_id = element.record_id;
-                if element_id > batch_last_id {
-                    // reaching end of the batch
-                    ControlFlow::Break(())
-                } else {
-                    let element_score = element.weight * posting.query_weight;
-                    // update score for id
-                    let local_id = (element_id - batch_start_id) as usize;
-                    self.pooled.scores[local_id] += element_score;
-                    ControlFlow::Continue(())
-                }
-            });
+            posting.posting_list_iterator.for_each_till_id(
+                batch_last_id,
+                self.pooled.scores.as_mut_slice(),
+                #[inline(always)]
+                |scores, id, weight| {
+                    let element_score = weight * posting.query_weight;
+                    let local_id = (id - batch_start_id) as usize;
+                    // SAFETY: `id` is within `batch_start_id..=batch_last_id`
+                    // Thus, `local_id` is within `0..batch_len`.
+                    *unsafe { scores.get_unchecked_mut(local_id) } += element_score;
+                },
+            );
         }
 
         for (local_index, &score) in self.pooled.scores.iter().enumerate() {
@@ -176,18 +174,18 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
     fn process_last_posting_list<F: Fn(PointOffsetType) -> bool>(&mut self, filter_condition: &F) {
         debug_assert_eq!(self.postings_iterators.len(), 1);
         let posting = &mut self.postings_iterators[0];
-        posting.posting_list_iterator.try_for_each(|element| {
-            // do not score if filter condition is not satisfied
-            if !filter_condition(element.record_id) {
-                return ControlFlow::Continue(());
-            }
-            let score = element.weight * posting.query_weight;
-            self.top_results.push(ScoredPointOffset {
-                score,
-                idx: element.record_id,
-            });
-            ControlFlow::<()>::Continue(())
-        });
+        posting.posting_list_iterator.for_each_till_id(
+            PointOffsetType::MAX,
+            &mut (),
+            |_, id, weight| {
+                // do not score if filter condition is not satisfied
+                if !filter_condition(id) {
+                    return;
+                }
+                let score = weight * posting.query_weight;
+                self.top_results.push(ScoredPointOffset { score, idx: id });
+            },
+        );
     }
 
     /// Returns the next min record id from all posting list iterators

commit 2a9ce07d9317523abb65a803141d3cbe3b68ddea
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Thu May 30 20:58:00 2024 +0000

    Sparse: misc fixes (#4361)
    
    * Borrow cows
    * Hide sparse_vector_fixture under feature="testing"

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index b9c31a865..f96e3a4eb 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -379,6 +379,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
 
 #[cfg(test)]
 mod tests {
+    use std::borrow::Cow;
     use std::sync::OnceLock;
 
     use rand::Rng;
@@ -467,7 +468,8 @@ mod tests {
             .tempdir()
             .unwrap();
         let inverted_index_mmap =
-            InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
+            InvertedIndexMmap::from_ram_index(Cow::Borrowed(&inverted_index_ram), &tmp_dir_path)
+                .unwrap();
         _search_test(&inverted_index_mmap);
     }
 
@@ -636,7 +638,8 @@ mod tests {
             .tempdir()
             .unwrap();
         let inverted_index_mmap =
-            InvertedIndexMmap::convert_and_save(&inverted_index_ram, &tmp_dir_path).unwrap();
+            InvertedIndexMmap::from_ram_index(Cow::Borrowed(&inverted_index_ram), &tmp_dir_path)
+                .unwrap();
         _search_with_hot_key_test(&inverted_index_mmap);
     }
 

commit 0df90085f20131c75eac82b9db0393a93023b650
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Mon Jun 10 15:04:32 2024 +0000

    Make sparse vectors generic (#4364)
    
    * Make sparse vector generic
    
    * Generic search_context tests

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index f96e3a4eb..e9d43b594 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -378,19 +378,50 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
 }
 
 #[cfg(test)]
+#[generic_tests::define]
 mod tests {
+    use std::any::TypeId;
     use std::borrow::Cow;
     use std::sync::OnceLock;
 
     use rand::Rng;
+    use tempfile::TempDir;
 
     use super::*;
     use crate::common::scores_memory_pool::ScoresMemoryPool;
     use crate::common::sparse_vector::SparseVector;
     use crate::common::sparse_vector_fixture::random_sparse_vector;
-    use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
     use crate::index::inverted_index::inverted_index_ram::InvertedIndexRam;
     use crate::index::inverted_index::inverted_index_ram_builder::InvertedIndexBuilder;
+    use crate::index::inverted_index::{
+        inverted_index_compressed_immutable_ram, inverted_index_compressed_mmap,
+        inverted_index_immutable_ram, inverted_index_mmap,
+    };
+
+    // ---- Test instantiations ----
+
+    #[instantiate_tests(<InvertedIndexRam>)]
+    mod ram {}
+
+    #[instantiate_tests(<inverted_index_mmap::InvertedIndexMmap>)]
+    mod mmap {}
+
+    #[instantiate_tests(<inverted_index_immutable_ram::InvertedIndexImmutableRam>)]
+    mod iram {}
+
+    #[instantiate_tests(<inverted_index_compressed_immutable_ram::InvertedIndexImmutableRam<f32>>)]
+    mod iram_f32 {}
+
+    #[instantiate_tests(<inverted_index_compressed_immutable_ram::InvertedIndexImmutableRam<half::f16>>)]
+    mod iram_f16 {}
+
+    #[instantiate_tests(<inverted_index_compressed_mmap::InvertedIndexMmap<f32>>)]
+    mod mmap_f32 {}
+
+    #[instantiate_tests(<inverted_index_compressed_mmap::InvertedIndexMmap<half::f16>>)]
+    mod mmap_f16 {}
+
+    // --- End of test instantiations ---
 
     static TEST_SCORES_POOL: OnceLock<ScoresMemoryPool> = OnceLock::new();
 
@@ -400,26 +431,55 @@ mod tests {
             .get()
     }
 
+    /// Match all filter condition for testing
+    fn match_all(_p: PointOffsetType) -> bool {
+        true
+    }
+
+    /// Helper struct to store both an index and a temporary directory
+    struct TestIndex<I: InvertedIndex> {
+        index: I,
+        temp_dir: TempDir,
+    }
+
+    impl<I: InvertedIndex> TestIndex<I> {
+        fn from_ram(ram_index: InvertedIndexRam) -> Self {
+            let temp_dir = tempfile::Builder::new()
+                .prefix("test_index_dir")
+                .tempdir()
+                .unwrap();
+            TestIndex {
+                index: I::from_ram_index(Cow::Owned(ram_index), &temp_dir).unwrap(),
+                temp_dir,
+            }
+        }
+    }
+
     #[test]
-    fn test_empty_query() {
+    fn test_empty_query<I: InvertedIndex>() {
+        let index = TestIndex::<I>::from_ram(InvertedIndexRam::empty());
+
         let is_stopped = AtomicBool::new(false);
-        let index = InvertedIndexRam::empty();
         let mut search_context = SearchContext::new(
             RemappedSparseVector::default(), // empty query vector
             10,
-            &index,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
         assert_eq!(search_context.search(&match_all), Vec::new());
     }
 
-    /// Match all filter condition for testing
-    fn match_all(_p: PointOffsetType) -> bool {
-        true
-    }
+    #[test]
+    fn search_test<I: InvertedIndex>() {
+        let index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+            builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
+            builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
+            builder.build()
+        });
 
-    fn _search_test(inverted_index: &impl InvertedIndex) {
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
@@ -427,7 +487,7 @@ mod tests {
                 values: vec![1.0, 1.0, 1.0],
             },
             10,
-            inverted_index,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -452,43 +512,28 @@ mod tests {
     }
 
     #[test]
-    fn search_test() {
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-        builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
-        builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
-        let inverted_index_ram = builder.build();
-
-        // test with ram index
-        _search_test(&inverted_index_ram);
-
-        // test with mmap index
-        let tmp_dir_path = tempfile::Builder::new()
-            .prefix("test_index_dir")
-            .tempdir()
-            .unwrap();
-        let inverted_index_mmap =
-            InvertedIndexMmap::from_ram_index(Cow::Borrowed(&inverted_index_ram), &tmp_dir_path)
-                .unwrap();
-        _search_test(&inverted_index_mmap);
-    }
+    fn search_with_update_test<I: InvertedIndex + 'static>() {
+        if TypeId::of::<I>() != TypeId::of::<InvertedIndexRam>() {
+            // Only InvertedIndexRam supports upserts
+            return;
+        }
 
-    #[test]
-    fn search_with_update_test() {
-        let is_stopped = AtomicBool::new(false);
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-        builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
-        builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
-        let mut inverted_index_ram = builder.build();
+        let mut index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+            builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
+            builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
+            builder.build()
+        });
 
+        let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
             10,
-            &inverted_index_ram,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -510,9 +555,10 @@ mod tests {
                 },
             ]
         );
+        drop(search_context);
 
         // update index with new point
-        inverted_index_ram.upsert(
+        index.index.upsert(
             4,
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -525,7 +571,7 @@ mod tests {
                 values: vec![1.0, 1.0, 1.0],
             },
             10,
-            &inverted_index_ram,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -553,7 +599,22 @@ mod tests {
         );
     }
 
-    fn _search_with_hot_key_test(inverted_index: &impl InvertedIndex) {
+    #[test]
+    fn search_with_hot_key_test<I: InvertedIndex>() {
+        let index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+            builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
+            builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
+            builder.add(4, [(1, 1.0)].into());
+            builder.add(5, [(1, 2.0)].into());
+            builder.add(6, [(1, 3.0)].into());
+            builder.add(7, [(1, 4.0)].into());
+            builder.add(8, [(1, 5.0)].into());
+            builder.add(9, [(1, 6.0)].into());
+            builder.build()
+        });
+
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
@@ -561,7 +622,7 @@ mod tests {
                 values: vec![1.0, 1.0, 1.0],
             },
             3,
-            inverted_index,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -590,7 +651,7 @@ mod tests {
                 values: vec![1.0, 1.0, 1.0],
             },
             4,
-            inverted_index,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -616,40 +677,14 @@ mod tests {
     }
 
     #[test]
-    fn search_with_hot_key_test() {
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-        builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
-        builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
-        builder.add(4, [(1, 1.0)].into());
-        builder.add(5, [(1, 2.0)].into());
-        builder.add(6, [(1, 3.0)].into());
-        builder.add(7, [(1, 4.0)].into());
-        builder.add(8, [(1, 5.0)].into());
-        builder.add(9, [(1, 6.0)].into());
-        let inverted_index_ram = builder.build();
-
-        // test with ram index
-        _search_with_hot_key_test(&inverted_index_ram);
-
-        // test with mmap index
-        let tmp_dir_path = tempfile::Builder::new()
-            .prefix("test_index_dir")
-            .tempdir()
-            .unwrap();
-        let inverted_index_mmap =
-            InvertedIndexMmap::from_ram_index(Cow::Borrowed(&inverted_index_ram), &tmp_dir_path)
-                .unwrap();
-        _search_with_hot_key_test(&inverted_index_mmap);
-    }
-
-    #[test]
-    fn pruning_single_to_end_test() {
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0)].into());
-        builder.add(2, [(1, 20.0)].into());
-        builder.add(3, [(1, 30.0)].into());
-        let inverted_index_ram = builder.build();
+    fn pruning_single_to_end_test<I: InvertedIndex>() {
+        let index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0)].into());
+            builder.add(2, [(1, 20.0)].into());
+            builder.add(3, [(1, 30.0)].into());
+            builder.build()
+        });
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
@@ -658,7 +693,7 @@ mod tests {
                 values: vec![1.0, 1.0, 1.0],
             },
             1,
-            &inverted_index_ram,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -675,15 +710,17 @@ mod tests {
     }
 
     #[test]
-    fn pruning_multi_to_end_test() {
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0)].into());
-        builder.add(2, [(1, 20.0)].into());
-        builder.add(3, [(1, 30.0)].into());
-        builder.add(5, [(3, 10.0)].into());
-        builder.add(6, [(2, 20.0), (3, 20.0)].into());
-        builder.add(7, [(2, 30.0), (3, 30.0)].into());
-        let inverted_index_ram = builder.build();
+    fn pruning_multi_to_end_test<I: InvertedIndex>() {
+        let index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0)].into());
+            builder.add(2, [(1, 20.0)].into());
+            builder.add(3, [(1, 30.0)].into());
+            builder.add(5, [(3, 10.0)].into());
+            builder.add(6, [(2, 20.0), (3, 20.0)].into());
+            builder.add(7, [(2, 30.0), (3, 30.0)].into());
+            builder.build()
+        });
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
@@ -692,7 +729,7 @@ mod tests {
                 values: vec![1.0, 1.0, 1.0],
             },
             1,
-            &inverted_index_ram,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -709,16 +746,22 @@ mod tests {
     }
 
     #[test]
-    fn pruning_multi_under_prune_test() {
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0)].into());
-        builder.add(2, [(1, 20.0)].into());
-        builder.add(3, [(1, 20.0)].into());
-        builder.add(4, [(1, 10.0)].into());
-        builder.add(5, [(3, 10.0)].into());
-        builder.add(6, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
-        builder.add(7, [(1, 40.0), (2, 30.0), (3, 30.0)].into());
-        let inverted_index_ram = builder.build();
+    fn pruning_multi_under_prune_test<I: InvertedIndex>() {
+        if !I::Iter::reliable_max_next_weight() {
+            return;
+        }
+
+        let index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0)].into());
+            builder.add(2, [(1, 20.0)].into());
+            builder.add(3, [(1, 20.0)].into());
+            builder.add(4, [(1, 10.0)].into());
+            builder.add(5, [(3, 10.0)].into());
+            builder.add(6, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
+            builder.add(7, [(1, 40.0), (2, 30.0), (3, 30.0)].into());
+            builder.build()
+        });
 
         let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
@@ -727,7 +770,7 @@ mod tests {
                 values: vec![1.0, 1.0, 1.0],
             },
             1,
-            &inverted_index_ram,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -764,21 +807,23 @@ mod tests {
     }
 
     #[test]
-    fn promote_longest_test() {
-        let is_stopped = AtomicBool::new(false);
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-        builder.add(2, [(1, 20.0), (3, 20.0)].into());
-        builder.add(3, [(2, 30.0), (3, 30.0)].into());
-        let inverted_index_ram = builder.build();
+    fn promote_longest_test<I: InvertedIndex>() {
+        let index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+            builder.add(2, [(1, 20.0), (3, 20.0)].into());
+            builder.add(3, [(2, 30.0), (3, 30.0)].into());
+            builder.build()
+        });
 
+        let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
             3,
-            &inverted_index_ram,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -801,21 +846,23 @@ mod tests {
     }
 
     #[test]
-    fn plain_search_all_test() {
-        let is_stopped = AtomicBool::new(false);
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-        builder.add(2, [(1, 20.0), (3, 20.0)].into());
-        builder.add(3, [(1, 30.0), (3, 30.0)].into());
-        let inverted_index_ram = builder.build();
+    fn plain_search_all_test<I: InvertedIndex>() {
+        let index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+            builder.add(2, [(1, 20.0), (3, 20.0)].into());
+            builder.add(3, [(1, 30.0), (3, 30.0)].into());
+            builder.build()
+        });
 
+        let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
                 values: vec![1.0, 1.0, 1.0],
             },
             3,
-            &inverted_index_ram,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );
@@ -841,22 +888,24 @@ mod tests {
     }
 
     #[test]
-    fn plain_search_gap_test() {
-        let is_stopped = AtomicBool::new(false);
-        let mut builder = InvertedIndexBuilder::new();
-        builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-        builder.add(2, [(1, 20.0), (3, 20.0)].into());
-        builder.add(3, [(2, 30.0), (3, 30.0)].into());
-        let inverted_index_ram = builder.build();
+    fn plain_search_gap_test<I: InvertedIndex>() {
+        let index = TestIndex::<I>::from_ram({
+            let mut builder = InvertedIndexBuilder::new();
+            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
+            builder.add(2, [(1, 20.0), (3, 20.0)].into());
+            builder.add(3, [(2, 30.0), (3, 30.0)].into());
+            builder.build()
+        });
 
         // query vector has a gap for dimension 2
+        let is_stopped = AtomicBool::new(false);
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 3],
                 values: vec![1.0, 1.0],
             },
             3,
-            &inverted_index_ram,
+            &index.index,
             get_pooled_scores(),
             &is_stopped,
         );

commit df3aa29654269fa4a5948bdaf6ce067ef54622fc
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Jun 12 12:13:49 2024 +0200

    Fix inplace updates for sparse index (#4375)
    
    * include old vector into update function and clean posting lists accordingly
    
    * add integration test
    
    * fix counter
    
    * also remove old vector if the insertion is empty
    
    * clippy
    
    * borrow once
    
    * fix max_next_weight correcton on delete + test
    
    * vector index responsible for updating vector storage
    
    * review fixes
    
    * add debug assert

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index e9d43b594..a3d43c6b0 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -564,6 +564,7 @@ mod tests {
                 indices: vec![1, 2, 3],
                 values: vec![40.0, 40.0, 40.0],
             },
+            None,
         );
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
@@ -801,7 +802,7 @@ mod tests {
             let SparseVector { indices, values } =
                 random_sparse_vector(rnd_gen, max_sparse_dimension);
             let vector = RemappedSparseVector::new(indices, values).unwrap();
-            inverted_index_ram.upsert(i, vector);
+            inverted_index_ram.upsert(i, vector, None);
         }
         inverted_index_ram
     }

commit d62a455da1daaf0bcc23248bfa06c8803b0d3e8b
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Mon Jun 17 12:41:38 2024 +0000

    Integrate compressed posting list (attempt 2) (#4453)
    
    * Rename InvertedIndex* -> InvertedIndexCompressed*
    
    * Extract method VectorIndexEnum::fill_idf_statistics
    
    * Extend VectorIndexEnum with new variants
    
    * Introduce sparse::InvertedIndex::Version
    
    * Replace SparseVectorIndexVersion -> InvertedIndex::Version
    
    * Introduce sparse_vector_index::OpenArgs
    
    * SparseVectorIndex::open: do not build index if directory is empty
    
    Otherwise it would build the index twice since `SegmentBuilder::build()`
    calls `::open()`, then `::build_index()`. This restores the old (<=v1.9)
    behavior.
    
    * Renames

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index a3d43c6b0..4d9360dd5 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -391,34 +391,34 @@ mod tests {
     use crate::common::scores_memory_pool::ScoresMemoryPool;
     use crate::common::sparse_vector::SparseVector;
     use crate::common::sparse_vector_fixture::random_sparse_vector;
+    use crate::index::inverted_index::inverted_index_compressed_immutable_ram::InvertedIndexCompressedImmutableRam;
+    use crate::index::inverted_index::inverted_index_compressed_mmap::InvertedIndexCompressedMmap;
+    use crate::index::inverted_index::inverted_index_immutable_ram::InvertedIndexImmutableRam;
+    use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
     use crate::index::inverted_index::inverted_index_ram::InvertedIndexRam;
     use crate::index::inverted_index::inverted_index_ram_builder::InvertedIndexBuilder;
-    use crate::index::inverted_index::{
-        inverted_index_compressed_immutable_ram, inverted_index_compressed_mmap,
-        inverted_index_immutable_ram, inverted_index_mmap,
-    };
 
     // ---- Test instantiations ----
 
     #[instantiate_tests(<InvertedIndexRam>)]
     mod ram {}
 
-    #[instantiate_tests(<inverted_index_mmap::InvertedIndexMmap>)]
+    #[instantiate_tests(<InvertedIndexMmap>)]
     mod mmap {}
 
-    #[instantiate_tests(<inverted_index_immutable_ram::InvertedIndexImmutableRam>)]
+    #[instantiate_tests(<InvertedIndexImmutableRam>)]
     mod iram {}
 
-    #[instantiate_tests(<inverted_index_compressed_immutable_ram::InvertedIndexImmutableRam<f32>>)]
+    #[instantiate_tests(<InvertedIndexCompressedImmutableRam<f32>>)]
     mod iram_f32 {}
 
-    #[instantiate_tests(<inverted_index_compressed_immutable_ram::InvertedIndexImmutableRam<half::f16>>)]
+    #[instantiate_tests(<InvertedIndexCompressedImmutableRam<half::f16>>)]
     mod iram_f16 {}
 
-    #[instantiate_tests(<inverted_index_compressed_mmap::InvertedIndexMmap<f32>>)]
+    #[instantiate_tests(<InvertedIndexCompressedMmap<f32>>)]
     mod mmap_f32 {}
 
-    #[instantiate_tests(<inverted_index_compressed_mmap::InvertedIndexMmap<half::f16>>)]
+    #[instantiate_tests(<InvertedIndexCompressedMmap<half::f16>>)]
     mod mmap_f16 {}
 
     // --- End of test instantiations ---

commit a5cb30c2085834c83d840c921998cc518a3377d1
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Mon Jun 24 14:12:29 2024 +0000

    U8 quantization for sparse vector index (#4514)
    
    * U8 quantization for sparse index
    
    * Spelling

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 4d9360dd5..3cad8b048 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -391,6 +391,7 @@ mod tests {
     use crate::common::scores_memory_pool::ScoresMemoryPool;
     use crate::common::sparse_vector::SparseVector;
     use crate::common::sparse_vector_fixture::random_sparse_vector;
+    use crate::common::types::QuantizedU8;
     use crate::index::inverted_index::inverted_index_compressed_immutable_ram::InvertedIndexCompressedImmutableRam;
     use crate::index::inverted_index::inverted_index_compressed_mmap::InvertedIndexCompressedMmap;
     use crate::index::inverted_index::inverted_index_immutable_ram::InvertedIndexImmutableRam;
@@ -415,12 +416,24 @@ mod tests {
     #[instantiate_tests(<InvertedIndexCompressedImmutableRam<half::f16>>)]
     mod iram_f16 {}
 
+    #[instantiate_tests(<InvertedIndexCompressedImmutableRam<u8>>)]
+    mod iram_u8 {}
+
+    #[instantiate_tests(<InvertedIndexCompressedImmutableRam<QuantizedU8>>)]
+    mod iram_q8 {}
+
     #[instantiate_tests(<InvertedIndexCompressedMmap<f32>>)]
     mod mmap_f32 {}
 
     #[instantiate_tests(<InvertedIndexCompressedMmap<half::f16>>)]
     mod mmap_f16 {}
 
+    #[instantiate_tests(<InvertedIndexCompressedMmap<u8>>)]
+    mod mmap_u8 {}
+
+    #[instantiate_tests(<InvertedIndexCompressedMmap<QuantizedU8>>)]
+    mod mmap_q8 {}
+
     // --- End of test instantiations ---
 
     static TEST_SCORES_POOL: OnceLock<ScoresMemoryPool> = OnceLock::new();
@@ -455,6 +468,23 @@ mod tests {
         }
     }
 
+    /// Round scores to allow some quantization errors
+    fn round_scores<I: 'static>(mut scores: Vec<ScoredPointOffset>) -> Vec<ScoredPointOffset> {
+        let errors_allowed_for = [
+            TypeId::of::<InvertedIndexCompressedImmutableRam<QuantizedU8>>(),
+            TypeId::of::<InvertedIndexCompressedMmap<QuantizedU8>>(),
+        ];
+        if errors_allowed_for.contains(&TypeId::of::<I>()) {
+            let precision = 0.25;
+            scores.iter_mut().for_each(|score| {
+                score.score = (score.score / precision).round() * precision;
+            });
+            scores
+        } else {
+            scores
+        }
+    }
+
     #[test]
     fn test_empty_query<I: InvertedIndex>() {
         let index = TestIndex::<I>::from_ram(InvertedIndexRam::empty());
@@ -493,7 +523,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(&match_all),
+            round_scores::<I>(search_context.search(&match_all)),
             vec![
                 ScoredPointOffset {
                     score: 90.0,
@@ -539,7 +569,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(&match_all),
+            round_scores::<I>(search_context.search(&match_all)),
             vec![
                 ScoredPointOffset {
                     score: 90.0,
@@ -629,7 +659,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(&match_all),
+            round_scores::<I>(search_context.search(&match_all)),
             vec![
                 ScoredPointOffset {
                     score: 90.0,
@@ -658,7 +688,7 @@ mod tests {
         );
 
         assert_eq!(
-            search_context.search(&match_all),
+            round_scores::<I>(search_context.search(&match_all)),
             vec![
                 ScoredPointOffset {
                     score: 90.0,
@@ -870,7 +900,7 @@ mod tests {
 
         let scores = search_context.plain_search(&[1, 3, 2]);
         assert_eq!(
-            scores,
+            round_scores::<I>(scores),
             vec![
                 ScoredPointOffset {
                     idx: 3,
@@ -913,7 +943,7 @@ mod tests {
 
         let scores = search_context.plain_search(&[1, 2, 3]);
         assert_eq!(
-            scores,
+            round_scores::<I>(scores),
             vec![
                 ScoredPointOffset {
                     idx: 2,

commit 07c278ad51084c98adf9a7093619ffc5a73f87c9
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Mon Jul 22 08:19:19 2024 +0000

    Enable some of the pedantic clippy lints (#4715)
    
    * Use workspace lints
    
    * Enable lint: manual_let_else
    
    * Enable lint: enum_glob_use
    
    * Enable lint: filter_map_next
    
    * Enable lint: ref_as_ptr
    
    * Enable lint: ref_option_ref
    
    * Enable lint: manual_is_variant_and
    
    * Enable lint: flat_map_option
    
    * Enable lint: inefficient_to_string
    
    * Enable lint: implicit_clone
    
    * Enable lint: inconsistent_struct_constructor
    
    * Enable lint: unnecessary_wraps
    
    * Enable lint: needless_continue
    
    * Enable lint: unused_self
    
    * Enable lint: from_iter_instead_of_collect
    
    * Enable lint: uninlined_format_args
    
    * Enable lint: doc_link_with_quotes
    
    * Enable lint: needless_raw_string_hashes
    
    * Enable lint: used_underscore_binding
    
    * Enable lint: ptr_as_ptr
    
    * Enable lint: explicit_into_iter_loop
    
    * Enable lint: cast_lossless

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 3cad8b048..fedbfe5f0 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -251,9 +251,8 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
             }
 
             // prepare next iterator of batched ids
-            let start_batch_id = match self.min_record_id {
-                Some(min_id) => min_id,
-                None => break, // all posting lists exhausted
+            let Some(start_batch_id) = self.min_record_id else {
+                break;
             };
 
             // compute batch range of contiguous ids for the next batch

commit dafe172c4928c7487fc31f88171d27bad42d7147
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Thu Oct 17 16:24:13 2024 +0200

    Add HardwareCounterCell + CPU measurement for sparse vector search (#5239)
    
    * Add HardwareCounterCell and counting for sparse plain search
    
    * Add measurement for indexed sparse vector
    
    * add tests for calculations
    
    * move SegmentQueryContent higher in the call stack
    
    * move hardware counters inside the query context
    
    * fix clippy
    
    * Fix applying hardware measurements and add test for this
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index fedbfe5f0..647868c82 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -2,6 +2,7 @@ use std::cmp::{max, min, Ordering};
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 
+use common::counter::hardware_counter::HardwareCounterCell;
 use common::top_k::TopK;
 use common::types::{PointOffsetType, ScoredPointOffset};
 
@@ -32,6 +33,7 @@ pub struct SearchContext<'a, 'b, T: PostingListIter = PostingListIterator<'a>> {
     max_record_id: PointOffsetType,         // max_record_id ids across all posting lists
     pooled: PooledScoresHandle<'b>,         // handle to pooled scores
     use_pruning: bool,
+    hardware_counter: HardwareCounterCell,
 }
 
 impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
@@ -86,6 +88,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
             max_record_id,
             pooled,
             use_pruning,
+            hardware_counter: HardwareCounterCell::new(),
         }
     }
 
@@ -95,6 +98,8 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         let mut sorted_ids = ids.to_vec();
         sorted_ids.sort_unstable();
 
+        let cpu_counter = self.hardware_counter.cpu_counter_mut();
+
         for id in sorted_ids {
             // check for cancellation
             if self.is_stopped.load(Relaxed) {
@@ -115,6 +120,11 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
                     }
                 }
             }
+
+            // Accumulate the sum of the length of the retrieved sparse vector and the query vector length
+            // as measurement for CPU usage of plain search.
+            cpu_counter.incr_delta_mut(indices.len() + self.query.indices.len());
+
             // reconstruct sparse vector and score against query
             let sparse_vector = RemappedSparseVector { indices, values };
             self.top_results.push(ScoredPointOffset {
@@ -138,6 +148,8 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         self.pooled.scores.clear(); // keep underlying allocated memory
         self.pooled.scores.resize(batch_len as usize, 0.0);
 
+        let cpu_counter = self.hardware_counter.cpu_counter_mut();
+
         for posting in self.postings_iterators.iter_mut() {
             posting.posting_list_iterator.for_each_till_id(
                 batch_last_id,
@@ -149,6 +161,9 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
                     // SAFETY: `id` is within `batch_start_id..=batch_last_id`
                     // Thus, `local_id` is within `0..batch_len`.
                     *unsafe { scores.get_unchecked_mut(local_id) } += element_score;
+
+                    // Measure CPU usage of indexed sparse search.
+                    cpu_counter.incr_mut();
                 },
             );
         }
@@ -374,6 +389,11 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         // no pruning took place
         false
     }
+
+    /// Return the current hardware measurement counter.
+    pub fn hardware_counter(&self) -> &HardwareCounterCell {
+        &self.hardware_counter
+    }
 }
 
 #[cfg(test)]
@@ -538,6 +558,9 @@ mod tests {
                 },
             ]
         );
+
+        // len(QueryVector)=3 * len(vector)=3 => 3*3 => 9
+        assert_eq!(search_context.hardware_counter().cpu_counter().get(), 9);
     }
 
     #[test]
@@ -675,6 +698,12 @@ mod tests {
             ]
         );
 
+        // [ID=1] (Retrieve all 9 Vectors) => 9
+        // [ID=2] (Retrieve 1-3)           => 3
+        // [ID=3] (Retrieve 1-3)           => 3
+        //                       3 + 3 + 9 => 15
+        assert_eq!(search_context.hardware_counter.cpu_counter().get(), 15);
+
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -704,6 +733,10 @@ mod tests {
                 ScoredPointOffset { score: 6.0, idx: 9 },
             ]
         );
+
+        // No difference to previous calculation because it's the same amount of score
+        // calculations when increasing the "top" parameter.
+        assert_eq!(search_context.hardware_counter.cpu_counter().get(), 15);
     }
 
     #[test]
@@ -915,6 +948,12 @@ mod tests {
                 },
             ]
         );
+
+        // [ID=1] (Retrieve three sparse vectors (1,2,3)) + QueryLength=3 => 6
+        // [ID=2] (Retrieve two sparse vectors (1,3))     + QueryLength=3 => 5
+        // [ID=3] (Retrieve two sparse vectors (1,3))     + QueryLength=3 => 5
+        //                                                      6 + 5 + 5 => 16
+        assert_eq!(search_context.hardware_counter().cpu_counter().get(), 16);
     }
 
     #[test]
@@ -958,5 +997,11 @@ mod tests {
                 },
             ]
         );
+
+        // [ID=1] (Retrieve two sparse vectors (1,2)) + QueryLength=2 => 4
+        // [ID=2] (Retrieve two sparse vectors (1,3)) + QueryLength=2 => 4
+        // [ID=3] (Retrieve one sparse vector (3))    + QueryLength=2 => 3
+        //                                                  4 + 4 + 3 => 11
+        assert_eq!(search_context.hardware_counter().cpu_counter().get(), 11);
     }
 }

commit cd8efa8f17a6d6b45e6e8b54638ab6976d740aa5
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Fri Oct 25 09:52:18 2024 +0200

    Hw counter utilization checks (#5288)
    
    * Enforce usage of hardware counter values
    
    * improve comments
    
    * log a warning in release mode
    
    * some minor improvements
    
    * avoid cloning for hardware counter
    
    * fmt
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 647868c82..02b057bbe 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -391,8 +391,8 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
     }
 
     /// Return the current hardware measurement counter.
-    pub fn hardware_counter(&self) -> &HardwareCounterCell {
-        &self.hardware_counter
+    pub fn take_hardware_counter(&self) -> HardwareCounterCell {
+        self.hardware_counter.take()
     }
 }
 
@@ -560,7 +560,9 @@ mod tests {
         );
 
         // len(QueryVector)=3 * len(vector)=3 => 3*3 => 9
-        assert_eq!(search_context.hardware_counter().cpu_counter().get(), 9);
+        let counter = search_context.take_hardware_counter();
+        assert_eq!(counter.cpu_counter().get(), 9);
+        counter.discard_results();
     }
 
     #[test]
@@ -607,6 +609,7 @@ mod tests {
                 },
             ]
         );
+        search_context.take_hardware_counter().discard_results();
         drop(search_context);
 
         // update index with new point
@@ -650,6 +653,7 @@ mod tests {
                 },
             ]
         );
+        search_context.take_hardware_counter().discard_results();
     }
 
     #[test]
@@ -703,6 +707,7 @@ mod tests {
         // [ID=3] (Retrieve 1-3)           => 3
         //                       3 + 3 + 9 => 15
         assert_eq!(search_context.hardware_counter.cpu_counter().get(), 15);
+        search_context.take_hardware_counter().discard_results();
 
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
@@ -737,6 +742,7 @@ mod tests {
         // No difference to previous calculation because it's the same amount of score
         // calculations when increasing the "top" parameter.
         assert_eq!(search_context.hardware_counter.cpu_counter().get(), 15);
+        search_context.take_hardware_counter().discard_results();
     }
 
     #[test]
@@ -953,7 +959,9 @@ mod tests {
         // [ID=2] (Retrieve two sparse vectors (1,3))     + QueryLength=3 => 5
         // [ID=3] (Retrieve two sparse vectors (1,3))     + QueryLength=3 => 5
         //                                                      6 + 5 + 5 => 16
-        assert_eq!(search_context.hardware_counter().cpu_counter().get(), 16);
+        let hardware_counter = search_context.take_hardware_counter();
+        assert_eq!(hardware_counter.cpu_counter().get(), 16);
+        hardware_counter.discard_results();
     }
 
     #[test]
@@ -1002,6 +1010,8 @@ mod tests {
         // [ID=2] (Retrieve two sparse vectors (1,3)) + QueryLength=2 => 4
         // [ID=3] (Retrieve one sparse vector (3))    + QueryLength=2 => 3
         //                                                  4 + 4 + 3 => 11
-        assert_eq!(search_context.hardware_counter().cpu_counter().get(), 11);
+        let hardware_counter = search_context.take_hardware_counter();
+        assert_eq!(hardware_counter.cpu_counter().get(), 11);
+        hardware_counter.discard_results();
     }
 }

commit 04f63a6a7fc346839af22bfd03c4c2461f10e4ab
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Oct 30 13:59:25 2024 +0100

    batch increment of counter (#5331)
    
    * batch increment of counter
    
    * move cpu counter to posting list level
    
    * prefer incr_delta_mut

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 02b057bbe..d94a93ac7 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -148,8 +148,6 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         self.pooled.scores.clear(); // keep underlying allocated memory
         self.pooled.scores.resize(batch_len as usize, 0.0);
 
-        let cpu_counter = self.hardware_counter.cpu_counter_mut();
-
         for posting in self.postings_iterators.iter_mut() {
             posting.posting_list_iterator.for_each_till_id(
                 batch_last_id,
@@ -161,9 +159,6 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
                     // SAFETY: `id` is within `batch_start_id..=batch_last_id`
                     // Thus, `local_id` is within `0..batch_len`.
                     *unsafe { scores.get_unchecked_mut(local_id) } += element_score;
-
-                    // Measure CPU usage of indexed sparse search.
-                    cpu_counter.incr_mut();
                 },
             );
         }
@@ -258,6 +253,17 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         if self.postings_iterators.is_empty() {
             return Vec::new();
         }
+
+        {
+            // Measure CPU usage of indexed sparse search.
+            // Assume the complexity of the search as total volume of the posting lists
+            // that are traversed in the batched search.
+            let cpu_counter = self.hardware_counter.cpu_counter_mut();
+            for posting in self.postings_iterators.iter() {
+                cpu_counter.incr_delta_mut(posting.posting_list_iterator.len_to_end());
+            }
+        }
+
         let mut best_min_score = f32::MIN;
         loop {
             // check for cancellation (atomic amortized by batch)

commit 5aee24cc089b0ddedacb80c508e33d40fcea1950
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Tue Dec 10 12:12:36 2024 +0100

    Timeout aware hardware counter (#5555)
    
    * Make hardware counting timeout aware
    
    * improve test
    
    * rebuild everything
    
    * fmt
    
    * post-rebase fixes
    
    * upd tests
    
    * fix tests
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index d94a93ac7..75461d752 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -43,6 +43,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         inverted_index: &'a impl InvertedIndex<Iter<'a> = T>,
         pooled: PooledScoresHandle<'b>,
         is_stopped: &'a AtomicBool,
+        hardware_counter: HardwareCounterCell,
     ) -> SearchContext<'a, 'b, T> {
         let mut postings_iterators = Vec::new();
         // track min and max record ids across all posting lists
@@ -88,7 +89,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
             max_record_id,
             pooled,
             use_pruning,
-            hardware_counter: HardwareCounterCell::new(),
+            hardware_counter,
         }
     }
 
@@ -395,11 +396,6 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         // no pruning took place
         false
     }
-
-    /// Return the current hardware measurement counter.
-    pub fn take_hardware_counter(&self) -> HardwareCounterCell {
-        self.hardware_counter.take()
-    }
 }
 
 #[cfg(test)]
@@ -409,6 +405,7 @@ mod tests {
     use std::borrow::Cow;
     use std::sync::OnceLock;
 
+    use common::counter::hardware_accumulator::HwMeasurementAcc;
     use rand::Rng;
     use tempfile::TempDir;
 
@@ -521,6 +518,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            HardwareCounterCell::new(),
         );
         assert_eq!(search_context.search(&match_all), Vec::new());
     }
@@ -536,6 +534,8 @@ mod tests {
         });
 
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -545,6 +545,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         assert_eq!(
@@ -565,10 +566,10 @@ mod tests {
             ]
         );
 
+        drop(search_context);
+
         // len(QueryVector)=3 * len(vector)=3 => 3*3 => 9
-        let counter = search_context.take_hardware_counter();
-        assert_eq!(counter.cpu_counter().get(), 9);
-        counter.discard_results();
+        assert_eq!(accumulator.get_cpu(), 9);
     }
 
     #[test]
@@ -587,6 +588,8 @@ mod tests {
         });
 
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -596,6 +599,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         assert_eq!(
@@ -615,7 +619,6 @@ mod tests {
                 },
             ]
         );
-        search_context.take_hardware_counter().discard_results();
         drop(search_context);
 
         // update index with new point
@@ -627,6 +630,7 @@ mod tests {
             },
             None,
         );
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -636,6 +640,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         assert_eq!(
@@ -659,7 +664,6 @@ mod tests {
                 },
             ]
         );
-        search_context.take_hardware_counter().discard_results();
     }
 
     #[test]
@@ -679,6 +683,8 @@ mod tests {
         });
 
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -688,6 +694,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         assert_eq!(
@@ -708,13 +715,15 @@ mod tests {
             ]
         );
 
+        drop(search_context);
         // [ID=1] (Retrieve all 9 Vectors) => 9
         // [ID=2] (Retrieve 1-3)           => 3
         // [ID=3] (Retrieve 1-3)           => 3
         //                       3 + 3 + 9 => 15
-        assert_eq!(search_context.hardware_counter.cpu_counter().get(), 15);
-        search_context.take_hardware_counter().discard_results();
+        assert_eq!(accumulator.get_cpu(), 15);
 
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -724,6 +733,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         assert_eq!(
@@ -745,10 +755,11 @@ mod tests {
             ]
         );
 
+        drop(search_context);
+
         // No difference to previous calculation because it's the same amount of score
         // calculations when increasing the "top" parameter.
-        assert_eq!(search_context.hardware_counter.cpu_counter().get(), 15);
-        search_context.take_hardware_counter().discard_results();
+        assert_eq!(accumulator.get_cpu(), 15);
     }
 
     #[test]
@@ -762,6 +773,8 @@ mod tests {
         });
 
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -771,6 +784,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         // assuming we have gathered enough results and want to prune the longest posting list
@@ -798,6 +812,8 @@ mod tests {
         });
 
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -807,6 +823,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         // assuming we have gathered enough results and want to prune the longest posting list
@@ -839,6 +856,8 @@ mod tests {
         });
 
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -848,6 +867,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         // one would expect this to prune up to `6` but it does not happen it practice because we are under pruning by design
@@ -892,6 +912,8 @@ mod tests {
         });
 
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -901,6 +923,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         assert_eq!(
@@ -931,6 +954,8 @@ mod tests {
         });
 
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -940,6 +965,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         let scores = search_context.plain_search(&[1, 3, 2]);
@@ -961,13 +987,13 @@ mod tests {
             ]
         );
 
+        drop(search_context);
+
         // [ID=1] (Retrieve three sparse vectors (1,2,3)) + QueryLength=3 => 6
         // [ID=2] (Retrieve two sparse vectors (1,3))     + QueryLength=3 => 5
         // [ID=3] (Retrieve two sparse vectors (1,3))     + QueryLength=3 => 5
         //                                                      6 + 5 + 5 => 16
-        let hardware_counter = search_context.take_hardware_counter();
-        assert_eq!(hardware_counter.cpu_counter().get(), 16);
-        hardware_counter.discard_results();
+        assert_eq!(accumulator.get_cpu(), 16);
     }
 
     #[test]
@@ -982,6 +1008,8 @@ mod tests {
 
         // query vector has a gap for dimension 2
         let is_stopped = AtomicBool::new(false);
+        let accumulator = HwMeasurementAcc::new();
+        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 3],
@@ -991,6 +1019,7 @@ mod tests {
             &index.index,
             get_pooled_scores(),
             &is_stopped,
+            hardware_counter,
         );
 
         let scores = search_context.plain_search(&[1, 2, 3]);
@@ -1012,12 +1041,12 @@ mod tests {
             ]
         );
 
+        drop(search_context);
+
         // [ID=1] (Retrieve two sparse vectors (1,2)) + QueryLength=2 => 4
         // [ID=2] (Retrieve two sparse vectors (1,3)) + QueryLength=2 => 4
         // [ID=3] (Retrieve one sparse vector (3))    + QueryLength=2 => 3
         //                                                  4 + 4 + 3 => 11
-        let hardware_counter = search_context.take_hardware_counter();
-        assert_eq!(hardware_counter.cpu_counter().get(), 11);
-        hardware_counter.discard_results();
+        assert_eq!(accumulator.get_cpu(), 11);
     }
 }

commit 1a4cc2258917d9ea5e3739c7737a49797aa9ecbd
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Fri Jan 17 15:37:13 2025 +0100

    Cleanup `#[allow(dead_code)]` annotations (#5818)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 75461d752..81f90d9b0 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -474,7 +474,7 @@ mod tests {
     /// Helper struct to store both an index and a temporary directory
     struct TestIndex<I: InvertedIndex> {
         index: I,
-        temp_dir: TempDir,
+        _temp_dir: TempDir,
     }
 
     impl<I: InvertedIndex> TestIndex<I> {
@@ -485,7 +485,7 @@ mod tests {
                 .unwrap();
             TestIndex {
                 index: I::from_ram_index(Cow::Owned(ram_index), &temp_dir).unwrap(),
-                temp_dir,
+                _temp_dir: temp_dir,
             }
         }
     }
@@ -885,6 +885,7 @@ mod tests {
     }
 
     /// Generates a random inverted index with `num_vectors` vectors
+    #[allow(dead_code)]
     fn random_inverted_index<R: Rng + ?Sized>(
         rnd_gen: &mut R,
         num_vectors: u32,

commit 77f65ef95fe83c80c05a947e4f94d35538108d85
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Thu Jan 30 10:23:35 2025 +0100

    HwCounter rename IO metrics (#5898)
    
    * Rename io metrics and add vector_io_write
    
    * Chore: Cleanup obsolete TODOs and simplify retrieving HardwareCounterCells (#5899)

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 81f90d9b0..f9fa23fd3 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -535,7 +535,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -589,7 +589,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -630,7 +630,7 @@ mod tests {
             },
             None,
         );
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -684,7 +684,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -723,7 +723,7 @@ mod tests {
         assert_eq!(accumulator.get_cpu(), 15);
 
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -774,7 +774,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -813,7 +813,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -857,7 +857,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -914,7 +914,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -956,7 +956,7 @@ mod tests {
 
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 2, 3],
@@ -1010,7 +1010,7 @@ mod tests {
         // query vector has a gap for dimension 2
         let is_stopped = AtomicBool::new(false);
         let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = HardwareCounterCell::new_with_accumulator(accumulator.clone());
+        let hardware_counter = accumulator.get_counter_cell();
         let mut search_context = SearchContext::new(
             RemappedSparseVector {
                 indices: vec![1, 3],

commit 8ad2b34265448ec01b89d4093de5fbb1a86dcd4d
Author: Tim Vise <tim+github@visee.me>
Date:   Tue Feb 25 11:21:25 2025 +0100

    Bump Rust edition to 2024 (#6042)
    
    * Bump Rust edition to 2024
    
    * gen is a reserved keyword now
    
    * Remove ref mut on references
    
    * Mark extern C as unsafe
    
    * Wrap unsafe function bodies in unsafe block
    
    * Geo hash implements Copy, don't reference but pass by value instead
    
    * Replace secluded self import with parent
    
    * Update execute_cluster_read_operation with new match semantics
    
    * Fix lifetime issue
    
    * Replace map_or with is_none_or
    
    * set_var is unsafe now
    
    * Reformat

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index f9fa23fd3..8cad95cd0 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -1,4 +1,4 @@
-use std::cmp::{max, min, Ordering};
+use std::cmp::{Ordering, max, min};
 use std::sync::atomic::AtomicBool;
 use std::sync::atomic::Ordering::Relaxed;
 

commit ad4743a85ff316d191fa55a445c7506892e7f6d1
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Mar 24 13:15:04 2025 +0100

    vector-io-read measurement on query (#6197)
    
    * remove mut getters from HardwareCounterCell, as mutability is not useful
    
    * introduce vector-io multiplier
    
    * remove RealCpuMeasurement structure
    
    * set vector-io reads multipliers
    
    * account vector reads in dense scorers
    
    * fmt
    
    * fix tests
    
    * propagate hw_counter into posting list iterator
    
    * fmt
    
    * fix test
    
    * wip: measure of sparse iterator
    
    * fmt
    
    * optimize skip_to
    
    * minor refactoring
    
    * keep current PointOffset in iterator to prevent unnecessary reads from memory
    
    * adjust sparse search cpu cost - account for datatype
    
    * fix test
    
    * refactor search_context tests
    
    * move tests into a module
    
    * introduce more tests
    
    * grammar
    
    * review fixes
    
    * fix clippy
    
    * fix clippy again
    
    * change disposable -> new

diff --git a/lib/sparse/src/index/search_context.rs b/lib/sparse/src/index/search_context.rs
index 8cad95cd0..42092e01c 100644
--- a/lib/sparse/src/index/search_context.rs
+++ b/lib/sparse/src/index/search_context.rs
@@ -8,7 +8,7 @@ use common::types::{PointOffsetType, ScoredPointOffset};
 
 use super::posting_list_common::PostingListIter;
 use crate::common::scores_memory_pool::PooledScoresHandle;
-use crate::common::sparse_vector::RemappedSparseVector;
+use crate::common::sparse_vector::{RemappedSparseVector, score_vectors};
 use crate::common::types::{DimId, DimWeight};
 use crate::index::inverted_index::InvertedIndex;
 use crate::index::posting_list::PostingListIterator;
@@ -33,7 +33,7 @@ pub struct SearchContext<'a, 'b, T: PostingListIter = PostingListIterator<'a>> {
     max_record_id: PointOffsetType,         // max_record_id ids across all posting lists
     pooled: PooledScoresHandle<'b>,         // handle to pooled scores
     use_pruning: bool,
-    hardware_counter: HardwareCounterCell,
+    hardware_counter: &'a HardwareCounterCell,
 }
 
 impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
@@ -43,7 +43,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         inverted_index: &'a impl InvertedIndex<Iter<'a> = T>,
         pooled: PooledScoresHandle<'b>,
         is_stopped: &'a AtomicBool,
-        hardware_counter: HardwareCounterCell,
+        hardware_counter: &'a HardwareCounterCell,
     ) -> SearchContext<'a, 'b, T> {
         let mut postings_iterators = Vec::new();
         // track min and max record ids across all posting lists
@@ -51,7 +51,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         let mut min_record_id = u32::MAX;
         // iterate over query indices
         for (query_weight_offset, id) in query.indices.iter().enumerate() {
-            if let Some(mut it) = inverted_index.get(id) {
+            if let Some(mut it) = inverted_index.get(*id, hardware_counter) {
                 if let (Some(first), Some(last_id)) = (it.peek(), it.last_id()) {
                     // check if new min
                     let min_record_id_posting = first.record_id;
@@ -93,22 +93,26 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         }
     }
 
+    const DEFAULT_SCORE: f32 = 0.0;
+
     /// Plain search against the given ids without any pruning
     pub fn plain_search(&mut self, ids: &[PointOffsetType]) -> Vec<ScoredPointOffset> {
         // sort ids to fully leverage posting list iterator traversal
         let mut sorted_ids = ids.to_vec();
         sorted_ids.sort_unstable();
 
-        let cpu_counter = self.hardware_counter.cpu_counter_mut();
+        let cpu_counter = self.hardware_counter.cpu_counter();
 
+        let mut indices = Vec::with_capacity(self.query.indices.len());
+        let mut values = Vec::with_capacity(self.query.values.len());
         for id in sorted_ids {
             // check for cancellation
             if self.is_stopped.load(Relaxed) {
                 break;
             }
 
-            let mut indices = Vec::with_capacity(self.query.indices.len());
-            let mut values = Vec::with_capacity(self.query.values.len());
+            indices.clear();
+            values.clear();
             // collect indices and values for the current record id from the query's posting lists *only*
             for posting_iterator in self.postings_iterators.iter_mut() {
                 // rely on underlying binary search as the posting lists are sorted by record id
@@ -122,14 +126,22 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
                 }
             }
 
+            if values.is_empty() {
+                continue;
+            }
+
             // Accumulate the sum of the length of the retrieved sparse vector and the query vector length
             // as measurement for CPU usage of plain search.
-            cpu_counter.incr_delta_mut(indices.len() + self.query.indices.len());
+            cpu_counter
+                .incr_delta(self.query.indices.len() + values.len() * size_of::<DimWeight>());
 
             // reconstruct sparse vector and score against query
-            let sparse_vector = RemappedSparseVector { indices, values };
+            let sparse_score =
+                score_vectors(&indices, &values, &self.query.indices, &self.query.values)
+                    .unwrap_or(Self::DEFAULT_SCORE);
+
             self.top_results.push(ScoredPointOffset {
-                score: sparse_vector.score(&self.query).unwrap_or(0.0),
+                score: sparse_score,
                 idx: id,
             });
         }
@@ -224,7 +236,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
     }
 
     /// Make sure the longest posting list is at the head of the posting list iterators
-    fn promote_longest_posting_lists_to_the_front(&mut self) {
+    pub(crate) fn promote_longest_posting_lists_to_the_front(&mut self) {
         // find index of longest posting list
         let posting_index = self
             .postings_iterators
@@ -246,6 +258,14 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         }
     }
 
+    /// How many elements are left in the posting list iterator
+    #[cfg(test)]
+    pub(crate) fn posting_list_len(&self, idx: usize) -> usize {
+        self.postings_iterators[idx]
+            .posting_list_iterator
+            .len_to_end()
+    }
+
     /// Search for the top k results that satisfy the filter condition
     pub fn search<F: Fn(PointOffsetType) -> bool>(
         &mut self,
@@ -259,10 +279,13 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
             // Measure CPU usage of indexed sparse search.
             // Assume the complexity of the search as total volume of the posting lists
             // that are traversed in the batched search.
-            let cpu_counter = self.hardware_counter.cpu_counter_mut();
+            let mut cpu_cost = 0;
+
             for posting in self.postings_iterators.iter() {
-                cpu_counter.incr_delta_mut(posting.posting_list_iterator.len_to_end());
+                cpu_cost += posting.posting_list_iterator.len_to_end()
+                    * posting.posting_list_iterator.element_size();
             }
+            self.hardware_counter.cpu_counter().incr_delta(cpu_cost);
         }
 
         let mut best_min_score = f32::MIN;
@@ -397,657 +420,3 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {
         false
     }
 }
-
-#[cfg(test)]
-#[generic_tests::define]
-mod tests {
-    use std::any::TypeId;
-    use std::borrow::Cow;
-    use std::sync::OnceLock;
-
-    use common::counter::hardware_accumulator::HwMeasurementAcc;
-    use rand::Rng;
-    use tempfile::TempDir;
-
-    use super::*;
-    use crate::common::scores_memory_pool::ScoresMemoryPool;
-    use crate::common::sparse_vector::SparseVector;
-    use crate::common::sparse_vector_fixture::random_sparse_vector;
-    use crate::common::types::QuantizedU8;
-    use crate::index::inverted_index::inverted_index_compressed_immutable_ram::InvertedIndexCompressedImmutableRam;
-    use crate::index::inverted_index::inverted_index_compressed_mmap::InvertedIndexCompressedMmap;
-    use crate::index::inverted_index::inverted_index_immutable_ram::InvertedIndexImmutableRam;
-    use crate::index::inverted_index::inverted_index_mmap::InvertedIndexMmap;
-    use crate::index::inverted_index::inverted_index_ram::InvertedIndexRam;
-    use crate::index::inverted_index::inverted_index_ram_builder::InvertedIndexBuilder;
-
-    // ---- Test instantiations ----
-
-    #[instantiate_tests(<InvertedIndexRam>)]
-    mod ram {}
-
-    #[instantiate_tests(<InvertedIndexMmap>)]
-    mod mmap {}
-
-    #[instantiate_tests(<InvertedIndexImmutableRam>)]
-    mod iram {}
-
-    #[instantiate_tests(<InvertedIndexCompressedImmutableRam<f32>>)]
-    mod iram_f32 {}
-
-    #[instantiate_tests(<InvertedIndexCompressedImmutableRam<half::f16>>)]
-    mod iram_f16 {}
-
-    #[instantiate_tests(<InvertedIndexCompressedImmutableRam<u8>>)]
-    mod iram_u8 {}
-
-    #[instantiate_tests(<InvertedIndexCompressedImmutableRam<QuantizedU8>>)]
-    mod iram_q8 {}
-
-    #[instantiate_tests(<InvertedIndexCompressedMmap<f32>>)]
-    mod mmap_f32 {}
-
-    #[instantiate_tests(<InvertedIndexCompressedMmap<half::f16>>)]
-    mod mmap_f16 {}
-
-    #[instantiate_tests(<InvertedIndexCompressedMmap<u8>>)]
-    mod mmap_u8 {}
-
-    #[instantiate_tests(<InvertedIndexCompressedMmap<QuantizedU8>>)]
-    mod mmap_q8 {}
-
-    // --- End of test instantiations ---
-
-    static TEST_SCORES_POOL: OnceLock<ScoresMemoryPool> = OnceLock::new();
-
-    fn get_pooled_scores() -> PooledScoresHandle<'static> {
-        TEST_SCORES_POOL
-            .get_or_init(ScoresMemoryPool::default)
-            .get()
-    }
-
-    /// Match all filter condition for testing
-    fn match_all(_p: PointOffsetType) -> bool {
-        true
-    }
-
-    /// Helper struct to store both an index and a temporary directory
-    struct TestIndex<I: InvertedIndex> {
-        index: I,
-        _temp_dir: TempDir,
-    }
-
-    impl<I: InvertedIndex> TestIndex<I> {
-        fn from_ram(ram_index: InvertedIndexRam) -> Self {
-            let temp_dir = tempfile::Builder::new()
-                .prefix("test_index_dir")
-                .tempdir()
-                .unwrap();
-            TestIndex {
-                index: I::from_ram_index(Cow::Owned(ram_index), &temp_dir).unwrap(),
-                _temp_dir: temp_dir,
-            }
-        }
-    }
-
-    /// Round scores to allow some quantization errors
-    fn round_scores<I: 'static>(mut scores: Vec<ScoredPointOffset>) -> Vec<ScoredPointOffset> {
-        let errors_allowed_for = [
-            TypeId::of::<InvertedIndexCompressedImmutableRam<QuantizedU8>>(),
-            TypeId::of::<InvertedIndexCompressedMmap<QuantizedU8>>(),
-        ];
-        if errors_allowed_for.contains(&TypeId::of::<I>()) {
-            let precision = 0.25;
-            scores.iter_mut().for_each(|score| {
-                score.score = (score.score / precision).round() * precision;
-            });
-            scores
-        } else {
-            scores
-        }
-    }
-
-    #[test]
-    fn test_empty_query<I: InvertedIndex>() {
-        let index = TestIndex::<I>::from_ram(InvertedIndexRam::empty());
-
-        let is_stopped = AtomicBool::new(false);
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector::default(), // empty query vector
-            10,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            HardwareCounterCell::new(),
-        );
-        assert_eq!(search_context.search(&match_all), Vec::new());
-    }
-
-    #[test]
-    fn search_test<I: InvertedIndex>() {
-        let index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-            builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
-            builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
-            builder.build()
-        });
-
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            10,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        assert_eq!(
-            round_scores::<I>(search_context.search(&match_all)),
-            vec![
-                ScoredPointOffset {
-                    score: 90.0,
-                    idx: 3
-                },
-                ScoredPointOffset {
-                    score: 60.0,
-                    idx: 2
-                },
-                ScoredPointOffset {
-                    score: 30.0,
-                    idx: 1
-                },
-            ]
-        );
-
-        drop(search_context);
-
-        // len(QueryVector)=3 * len(vector)=3 => 3*3 => 9
-        assert_eq!(accumulator.get_cpu(), 9);
-    }
-
-    #[test]
-    fn search_with_update_test<I: InvertedIndex + 'static>() {
-        if TypeId::of::<I>() != TypeId::of::<InvertedIndexRam>() {
-            // Only InvertedIndexRam supports upserts
-            return;
-        }
-
-        let mut index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-            builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
-            builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
-            builder.build()
-        });
-
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            10,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        assert_eq!(
-            round_scores::<I>(search_context.search(&match_all)),
-            vec![
-                ScoredPointOffset {
-                    score: 90.0,
-                    idx: 3
-                },
-                ScoredPointOffset {
-                    score: 60.0,
-                    idx: 2
-                },
-                ScoredPointOffset {
-                    score: 30.0,
-                    idx: 1
-                },
-            ]
-        );
-        drop(search_context);
-
-        // update index with new point
-        index.index.upsert(
-            4,
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![40.0, 40.0, 40.0],
-            },
-            None,
-        );
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            10,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        assert_eq!(
-            search_context.search(&match_all),
-            vec![
-                ScoredPointOffset {
-                    score: 120.0,
-                    idx: 4
-                },
-                ScoredPointOffset {
-                    score: 90.0,
-                    idx: 3
-                },
-                ScoredPointOffset {
-                    score: 60.0,
-                    idx: 2
-                },
-                ScoredPointOffset {
-                    score: 30.0,
-                    idx: 1
-                },
-            ]
-        );
-    }
-
-    #[test]
-    fn search_with_hot_key_test<I: InvertedIndex>() {
-        let index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-            builder.add(2, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
-            builder.add(3, [(1, 30.0), (2, 30.0), (3, 30.0)].into());
-            builder.add(4, [(1, 1.0)].into());
-            builder.add(5, [(1, 2.0)].into());
-            builder.add(6, [(1, 3.0)].into());
-            builder.add(7, [(1, 4.0)].into());
-            builder.add(8, [(1, 5.0)].into());
-            builder.add(9, [(1, 6.0)].into());
-            builder.build()
-        });
-
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            3,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        assert_eq!(
-            round_scores::<I>(search_context.search(&match_all)),
-            vec![
-                ScoredPointOffset {
-                    score: 90.0,
-                    idx: 3
-                },
-                ScoredPointOffset {
-                    score: 60.0,
-                    idx: 2
-                },
-                ScoredPointOffset {
-                    score: 30.0,
-                    idx: 1
-                },
-            ]
-        );
-
-        drop(search_context);
-        // [ID=1] (Retrieve all 9 Vectors) => 9
-        // [ID=2] (Retrieve 1-3)           => 3
-        // [ID=3] (Retrieve 1-3)           => 3
-        //                       3 + 3 + 9 => 15
-        assert_eq!(accumulator.get_cpu(), 15);
-
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            4,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        assert_eq!(
-            round_scores::<I>(search_context.search(&match_all)),
-            vec![
-                ScoredPointOffset {
-                    score: 90.0,
-                    idx: 3
-                },
-                ScoredPointOffset {
-                    score: 60.0,
-                    idx: 2
-                },
-                ScoredPointOffset {
-                    score: 30.0,
-                    idx: 1
-                },
-                ScoredPointOffset { score: 6.0, idx: 9 },
-            ]
-        );
-
-        drop(search_context);
-
-        // No difference to previous calculation because it's the same amount of score
-        // calculations when increasing the "top" parameter.
-        assert_eq!(accumulator.get_cpu(), 15);
-    }
-
-    #[test]
-    fn pruning_single_to_end_test<I: InvertedIndex>() {
-        let index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0)].into());
-            builder.add(2, [(1, 20.0)].into());
-            builder.add(3, [(1, 30.0)].into());
-            builder.build()
-        });
-
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            1,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        // assuming we have gathered enough results and want to prune the longest posting list
-        assert!(search_context.prune_longest_posting_list(30.0));
-        // the longest posting list was pruned to the end
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            0
-        );
-    }
-
-    #[test]
-    fn pruning_multi_to_end_test<I: InvertedIndex>() {
-        let index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0)].into());
-            builder.add(2, [(1, 20.0)].into());
-            builder.add(3, [(1, 30.0)].into());
-            builder.add(5, [(3, 10.0)].into());
-            builder.add(6, [(2, 20.0), (3, 20.0)].into());
-            builder.add(7, [(2, 30.0), (3, 30.0)].into());
-            builder.build()
-        });
-
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            1,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        // assuming we have gathered enough results and want to prune the longest posting list
-        assert!(search_context.prune_longest_posting_list(30.0));
-        // the longest posting list was pruned to the end
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            0
-        );
-    }
-
-    #[test]
-    fn pruning_multi_under_prune_test<I: InvertedIndex>() {
-        if !I::Iter::reliable_max_next_weight() {
-            return;
-        }
-
-        let index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0)].into());
-            builder.add(2, [(1, 20.0)].into());
-            builder.add(3, [(1, 20.0)].into());
-            builder.add(4, [(1, 10.0)].into());
-            builder.add(5, [(3, 10.0)].into());
-            builder.add(6, [(1, 20.0), (2, 20.0), (3, 20.0)].into());
-            builder.add(7, [(1, 40.0), (2, 30.0), (3, 30.0)].into());
-            builder.build()
-        });
-
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            1,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        // one would expect this to prune up to `6` but it does not happen it practice because we are under pruning by design
-        // we should actually check the best score up to `6` - 1 only instead of the max possible score (40.0)
-        assert!(!search_context.prune_longest_posting_list(30.0));
-
-        assert!(search_context.prune_longest_posting_list(40.0));
-        // the longest posting list was pruned to the end
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            2 // 6, 7
-        );
-    }
-
-    /// Generates a random inverted index with `num_vectors` vectors
-    #[allow(dead_code)]
-    fn random_inverted_index<R: Rng + ?Sized>(
-        rnd_gen: &mut R,
-        num_vectors: u32,
-        max_sparse_dimension: usize,
-    ) -> InvertedIndexRam {
-        let mut inverted_index_ram = InvertedIndexRam::empty();
-
-        for i in 1..=num_vectors {
-            let SparseVector { indices, values } =
-                random_sparse_vector(rnd_gen, max_sparse_dimension);
-            let vector = RemappedSparseVector::new(indices, values).unwrap();
-            inverted_index_ram.upsert(i, vector, None);
-        }
-        inverted_index_ram
-    }
-
-    #[test]
-    fn promote_longest_test<I: InvertedIndex>() {
-        let index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-            builder.add(2, [(1, 20.0), (3, 20.0)].into());
-            builder.add(3, [(2, 30.0), (3, 30.0)].into());
-            builder.build()
-        });
-
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            3,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            2
-        );
-
-        search_context.promote_longest_posting_lists_to_the_front();
-
-        assert_eq!(
-            search_context.postings_iterators[0]
-                .posting_list_iterator
-                .len_to_end(),
-            3
-        );
-    }
-
-    #[test]
-    fn plain_search_all_test<I: InvertedIndex>() {
-        let index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-            builder.add(2, [(1, 20.0), (3, 20.0)].into());
-            builder.add(3, [(1, 30.0), (3, 30.0)].into());
-            builder.build()
-        });
-
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 2, 3],
-                values: vec![1.0, 1.0, 1.0],
-            },
-            3,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        let scores = search_context.plain_search(&[1, 3, 2]);
-        assert_eq!(
-            round_scores::<I>(scores),
-            vec![
-                ScoredPointOffset {
-                    idx: 3,
-                    score: 60.0
-                },
-                ScoredPointOffset {
-                    idx: 2,
-                    score: 40.0
-                },
-                ScoredPointOffset {
-                    idx: 1,
-                    score: 30.0
-                },
-            ]
-        );
-
-        drop(search_context);
-
-        // [ID=1] (Retrieve three sparse vectors (1,2,3)) + QueryLength=3 => 6
-        // [ID=2] (Retrieve two sparse vectors (1,3))     + QueryLength=3 => 5
-        // [ID=3] (Retrieve two sparse vectors (1,3))     + QueryLength=3 => 5
-        //                                                      6 + 5 + 5 => 16
-        assert_eq!(accumulator.get_cpu(), 16);
-    }
-
-    #[test]
-    fn plain_search_gap_test<I: InvertedIndex>() {
-        let index = TestIndex::<I>::from_ram({
-            let mut builder = InvertedIndexBuilder::new();
-            builder.add(1, [(1, 10.0), (2, 10.0), (3, 10.0)].into());
-            builder.add(2, [(1, 20.0), (3, 20.0)].into());
-            builder.add(3, [(2, 30.0), (3, 30.0)].into());
-            builder.build()
-        });
-
-        // query vector has a gap for dimension 2
-        let is_stopped = AtomicBool::new(false);
-        let accumulator = HwMeasurementAcc::new();
-        let hardware_counter = accumulator.get_counter_cell();
-        let mut search_context = SearchContext::new(
-            RemappedSparseVector {
-                indices: vec![1, 3],
-                values: vec![1.0, 1.0],
-            },
-            3,
-            &index.index,
-            get_pooled_scores(),
-            &is_stopped,
-            hardware_counter,
-        );
-
-        let scores = search_context.plain_search(&[1, 2, 3]);
-        assert_eq!(
-            round_scores::<I>(scores),
-            vec![
-                ScoredPointOffset {
-                    idx: 2,
-                    score: 40.0
-                },
-                ScoredPointOffset {
-                    idx: 3,
-                    score: 30.0 // the dimension 2 did not contribute to the score
-                },
-                ScoredPointOffset {
-                    idx: 1,
-                    score: 20.0 // the dimension 2 did not contribute to the score
-                },
-            ]
-        );
-
-        drop(search_context);
-
-        // [ID=1] (Retrieve two sparse vectors (1,2)) + QueryLength=2 => 4
-        // [ID=2] (Retrieve two sparse vectors (1,3)) + QueryLength=2 => 4
-        // [ID=3] (Retrieve one sparse vector (3))    + QueryLength=2 => 3
-        //                                                  4 + 4 + 3 => 11
-        assert_eq!(accumulator.get_cpu(), 11);
-    }
-}

