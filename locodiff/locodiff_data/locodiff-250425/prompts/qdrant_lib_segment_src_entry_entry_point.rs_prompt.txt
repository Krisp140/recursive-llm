# Instructions

You are being benchmarked. You will see the output of a git log command, and from that must infer the current state of a file. Think carefully, as you must output the exact state of the file to earn full marks.

**Important:** Your goal is to reproduce the file's content *exactly* as it exists at the final commit, even if the code appears broken, buggy, or contains obvious errors. Do **not** try to "fix" the code. Attempting to correct issues will result in a poor score, as this benchmark evaluates your ability to reproduce the precise state of the file based on its history.

# Required Response Format

Wrap the content of the file in triple backticks (```). Any text outside the final closing backticks will be ignored. End your response after outputting the closing backticks.

# Example Response

```python
#!/usr/bin/env python
print('Hello, world!')
```

# File History

> git log -p --cc --topo-order --reverse -- lib/segment/src/entry/entry_point.rs

commit 4db98b8a3a6a37822786090c8cba9f7b29dc1002
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sun Jul 5 00:58:29 2020 +0200

    start implementing simple segment

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
new file mode 100644
index 000000000..c89286145
--- /dev/null
+++ b/lib/segment/src/entry/entry_point.rs
@@ -0,0 +1,61 @@
+use thiserror::Error;
+use std::path::Path;
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType};
+use std::result;
+
+
+/// Trait for versionable & saveable objects.
+pub trait VersionedPersistable {
+    fn persist(&self, directory: &Path) -> SeqNumberType;
+    fn load(directory: &Path) -> Self;
+
+    /// Save latest persisted version in memory, so the object will not be saved too much times
+    fn ack_persistance(&mut self, version: SeqNumberType);
+}
+
+
+#[derive(Error, Debug)]
+pub enum OperationError {
+    #[error("Vector inserting error: expected dim: {expected_dim}, got {received_dim}")]
+    WrongVector { expected_dim: usize, received_dim: usize },
+    #[error("Wrong operation ordering: segment state:{SeqNumberType}, operation: {operation_num}")]
+    SeqError { current_state: SeqNumberType, operation_num: SeqNumberType},
+    #[error("No point with id {missed_point_id} found")]
+    PointIdError { missed_point_id: PointIdType },
+    #[error("Payload `{key}` type mismatch for point {point_id}: expected: {required_type}, got {received_type}")]
+    PayloadError {
+        point_id: PointIdType,
+        key: PayloadKeyType,
+        required_type: String,
+        received_type: String
+    },
+}
+
+pub type Result<T> = result::Result<T, OperationError>;
+
+
+/// Define all operations which can be performed with Segment.
+/// Assume, that all operations are idempotent - which means that
+///     no matter how much time they will consequently executed - storage state will be the same.
+pub trait SegmentEntry {
+    /// Get current update version of the segement
+    fn version(&self) -> SeqNumberType;
+
+    fn search(&self,
+              vector: &Vec<VectorElementType>,
+              filter: Option<&Filter>,
+              top: usize) -> Vec<(PointIdType, ScoreType)>;
+
+    fn upsert_point(&mut self, op_num: SeqNumberType, point_id: PointIdType, vector: &Vec<VectorElementType>) -> Result<bool>;
+
+    fn delete_point(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
+
+    fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: PayloadKeyType, payload: PayloadType) -> Result<bool>;
+
+    fn delete_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: PayloadKeyType) -> Result<bool>;
+
+    fn clear_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
+
+    fn wipe_payload(&mut self, op_num: SeqNumberType) -> Result<bool>;
+}
+

commit 3e20bc59ae6b5c8852859ec037d92bee1db09238
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Mon Jul 6 15:20:27 2020 +0200

    implement functions at segment entry point

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index c89286145..b878eb53f 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -2,6 +2,7 @@ use thiserror::Error;
 use std::path::Path;
 use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType};
 use std::result;
+use crate::payload_storage::payload_storage::TheMap;
 
 
 /// Trait for versionable & saveable objects.
@@ -18,17 +19,10 @@ pub trait VersionedPersistable {
 pub enum OperationError {
     #[error("Vector inserting error: expected dim: {expected_dim}, got {received_dim}")]
     WrongVector { expected_dim: usize, received_dim: usize },
-    #[error("Wrong operation ordering: segment state:{SeqNumberType}, operation: {operation_num}")]
+    #[error("Wrong operation ordering: segment state:{current_state}, operation: {operation_num}")]
     SeqError { current_state: SeqNumberType, operation_num: SeqNumberType},
     #[error("No point with id {missed_point_id} found")]
-    PointIdError { missed_point_id: PointIdType },
-    #[error("Payload `{key}` type mismatch for point {point_id}: expected: {required_type}, got {received_type}")]
-    PayloadError {
-        point_id: PointIdType,
-        key: PayloadKeyType,
-        required_type: String,
-        received_type: String
-    },
+    PointIdError { missed_point_id: PointIdType }
 }
 
 pub type Result<T> = result::Result<T, OperationError>;
@@ -50,12 +44,16 @@ pub trait SegmentEntry {
 
     fn delete_point(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
 
-    fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: PayloadKeyType, payload: PayloadType) -> Result<bool>;
+    fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType, payload: PayloadType) -> Result<bool>;
 
-    fn delete_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: PayloadKeyType) -> Result<bool>;
+    fn delete_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType) -> Result<bool>;
 
     fn clear_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
 
     fn wipe_payload(&mut self, op_num: SeqNumberType) -> Result<bool>;
+
+    fn vector(&self, point_id: PointIdType) -> Result<Vec<VectorElementType>>;
+
+    fn payload(&self, point_id: PointIdType) -> Result<TheMap<PayloadKeyType, PayloadType>>;
 }
 

commit 03c86e7f655b5d8440628eb25885d654d43a6499
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Mon Jul 6 23:50:21 2020 +0200

    add simple segment builder

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index b878eb53f..755236424 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -55,5 +55,7 @@ pub trait SegmentEntry {
     fn vector(&self, point_id: PointIdType) -> Result<Vec<VectorElementType>>;
 
     fn payload(&self, point_id: PointIdType) -> Result<TheMap<PayloadKeyType, PayloadType>>;
+
+    // ToDo: Add statistics APIs: num vectors, mem usage
 }
 

commit 29f75a0ecc3d41ebffc0a58928fffd54bf0cc508
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Mon Jul 13 00:18:10 2020 +0200

    refactor distance, start segment manager implementation

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 755236424..977679e9f 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use thiserror::Error;
 use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType};
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType, SearchParams};
 use std::result;
 use crate::payload_storage::payload_storage::TheMap;
 
@@ -38,7 +38,9 @@ pub trait SegmentEntry {
     fn search(&self,
               vector: &Vec<VectorElementType>,
               filter: Option<&Filter>,
-              top: usize) -> Vec<(PointIdType, ScoreType)>;
+              top: usize,
+              params: Option<&SearchParams>,
+    ) -> Vec<(PointIdType, ScoreType)>;
 
     fn upsert_point(&mut self, op_num: SeqNumberType, point_id: PointIdType, vector: &Vec<VectorElementType>) -> Result<bool>;
 

commit bf8b2f002725ed041e7bba353114b818f1b613a0
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Tue Jul 14 15:02:57 2020 +0200

    add vector count

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 977679e9f..6db538198 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -58,6 +58,12 @@ pub trait SegmentEntry {
 
     fn payload(&self, point_id: PointIdType) -> Result<TheMap<PayloadKeyType, PayloadType>>;
 
-    // ToDo: Add statistics APIs: num vectors, mem usage
+    /// Check if there is point with `point_id` in this segment.
+    fn has_point(&self, point_id: PointIdType) -> bool;
+
+    /// Return number of vectors in this segment
+    fn vectors_count(&self) -> usize;
+
+    // ToDo: Add statistics APIs: mem usage
 }
 

commit 5215e7996e218614c0bb8f4fdfa5d1867c8b75c1
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sat Jul 18 17:17:23 2020 +0200

    parallel segments searcher + test

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 6db538198..b327f8e11 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use thiserror::Error;
 use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType, SearchParams};
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint};
 use std::result;
 use crate::payload_storage::payload_storage::TheMap;
 
@@ -32,7 +32,7 @@ pub type Result<T> = result::Result<T, OperationError>;
 /// Assume, that all operations are idempotent - which means that
 ///     no matter how much time they will consequently executed - storage state will be the same.
 pub trait SegmentEntry {
-    /// Get current update version of the segement
+    /// Get current update version of the segment
     fn version(&self) -> SeqNumberType;
 
     fn search(&self,
@@ -40,7 +40,7 @@ pub trait SegmentEntry {
               filter: Option<&Filter>,
               top: usize,
               params: Option<&SearchParams>,
-    ) -> Vec<(PointIdType, ScoreType)>;
+    ) -> Vec<ScoredPoint>;
 
     fn upsert_point(&mut self, op_num: SeqNumberType, point_id: PointIdType, vector: &Vec<VectorElementType>) -> Result<bool>;
 

commit 22e6d8e2956d6f841aa7e236417ff43cf22c8758
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Mon Jul 20 23:57:02 2020 +0200

    point insert operation in segment manager

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index b327f8e11..3b441c8d7 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -16,6 +16,7 @@ pub trait VersionedPersistable {
 
 
 #[derive(Error, Debug)]
+#[error("{0}")]
 pub enum OperationError {
     #[error("Vector inserting error: expected dim: {expected_dim}, got {received_dim}")]
     WrongVector { expected_dim: usize, received_dim: usize },

commit a5bb6487686a115aa1934fd4f02634feb79a5519
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Mon Jul 27 14:17:32 2020 +0200

    implement points retrieval + refactor updater

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 3b441c8d7..f7eb17e68 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,8 +1,7 @@
 use thiserror::Error;
 use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint};
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap};
 use std::result;
-use crate::payload_storage::payload_storage::TheMap;
 
 
 /// Trait for versionable & saveable objects.

commit 7178468e7befd65ccc379db50b965cf9361c630d
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Mon Jul 27 19:22:51 2020 +0200

    cargo fix

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index f7eb17e68..5ac9e91f3 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use thiserror::Error;
 use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, ScoreType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap};
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap};
 use std::result;
 
 

commit ec8b34c15cd6ad207a4f5160cfd138dc186094ea
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Tue Aug 4 14:47:52 2020 +0200

    start update listener

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 5ac9e91f3..356ab08f4 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -40,7 +40,7 @@ pub trait SegmentEntry {
               filter: Option<&Filter>,
               top: usize,
               params: Option<&SearchParams>,
-    ) -> Vec<ScoredPoint>;
+    ) -> Result<Vec<ScoredPoint>>;
 
     fn upsert_point(&mut self, op_num: SeqNumberType, point_id: PointIdType, vector: &Vec<VectorElementType>) -> Result<bool>;
 

commit 8aa31aaf38e75322d04f9921b3732794e736a684
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Tue Aug 11 00:35:44 2020 +0200

    refactor error handling in collections, refactor update method to future

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 356ab08f4..cb44ea716 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -19,8 +19,6 @@ pub trait VersionedPersistable {
 pub enum OperationError {
     #[error("Vector inserting error: expected dim: {expected_dim}, got {received_dim}")]
     WrongVector { expected_dim: usize, received_dim: usize },
-    #[error("Wrong operation ordering: segment state:{current_state}, operation: {operation_num}")]
-    SeqError { current_state: SeqNumberType, operation_num: SeqNumberType},
     #[error("No point with id {missed_point_id} found")]
     PointIdError { missed_point_id: PointIdType }
 }

commit ae4f5e498385d1cd6f7ad44de18c06ef214dbf8b
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sat Aug 15 14:23:24 2020 +0200

    WIP segment optimizer

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index cb44ea716..08a144867 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use thiserror::Error;
 use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap};
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentStats};
 use std::result;
 
 
@@ -62,6 +62,7 @@ pub trait SegmentEntry {
     /// Return number of vectors in this segment
     fn vectors_count(&self) -> usize;
 
-    // ToDo: Add statistics APIs: mem usage
+    fn info(&self) -> SegmentStats;
+
 }
 

commit ef343499b8ed22461da4eef8c965330e32478a4c
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sat Aug 15 15:24:41 2020 +0200

    add is_appendable flag for segment

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 08a144867..f98a046fd 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -33,6 +33,9 @@ pub trait SegmentEntry {
     /// Get current update version of the segment
     fn version(&self) -> SeqNumberType;
 
+    /// Defines if it is possible to dynamically add new points to this segment or not
+    fn is_appendable(&self) -> bool;
+
     fn search(&self,
               vector: &Vec<VectorElementType>,
               filter: Option<&Filter>,

commit 9effaec4ae44cdf46aab68f6ecb2c9d9b7138c25
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sun Aug 16 14:13:57 2020 +0200

    go with copy of all deleted ids into query, replace refcell with atomic refcell

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index f98a046fd..7f8aeb27e 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -47,6 +47,8 @@ pub trait SegmentEntry {
 
     fn delete_point(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
 
+    fn set_full_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: TheMap<PayloadKeyType, PayloadType>)-> Result<bool>;
+
     fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType, payload: PayloadType) -> Result<bool>;
 
     fn delete_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType) -> Result<bool>;

commit f39b42152b21a3b0507030d1742ca23c1aae858c
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sun Aug 16 16:52:13 2020 +0200

    implemented proxy segment + removed wipe operation due to complications in proxy segment implementation

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 7f8aeb27e..755ba3050 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -55,8 +55,6 @@ pub trait SegmentEntry {
 
     fn clear_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
 
-    fn wipe_payload(&mut self, op_num: SeqNumberType) -> Result<bool>;
-
     fn vector(&self, point_id: PointIdType) -> Result<Vec<VectorElementType>>;
 
     fn payload(&self, point_id: PointIdType) -> Result<TheMap<PayloadKeyType, PayloadType>>;

commit 8404de759432f6f6df4780199f0dd6d5c0fd65d2
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Mon Aug 17 01:36:11 2020 +0200

    WIP vacuum optimizer: segment rebuilding option is required

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 755ba3050..3380e32d1 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use thiserror::Error;
 use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentStats};
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo};
 use std::result;
 
 
@@ -33,9 +33,6 @@ pub trait SegmentEntry {
     /// Get current update version of the segment
     fn version(&self) -> SeqNumberType;
 
-    /// Defines if it is possible to dynamically add new points to this segment or not
-    fn is_appendable(&self) -> bool;
-
     fn search(&self,
               vector: &Vec<VectorElementType>,
               filter: Option<&Filter>,
@@ -65,7 +62,7 @@ pub trait SegmentEntry {
     /// Return number of vectors in this segment
     fn vectors_count(&self) -> usize;
 
-    fn info(&self) -> SegmentStats;
+    fn info(&self) -> SegmentInfo;
 
 }
 

commit 57dcaad4994578fdbc886642604ec53b4edf24d8
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Mon Aug 31 23:23:29 2020 +0200

    refactor segment optimizer

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 3380e32d1..a4d4d8a0f 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -56,6 +56,8 @@ pub trait SegmentEntry {
 
     fn payload(&self, point_id: PointIdType) -> Result<TheMap<PayloadKeyType, PayloadType>>;
 
+    fn iter_points(&self) -> Box<dyn Iterator<Item=PointIdType> + '_>;
+
     /// Check if there is point with `point_id` in this segment.
     fn has_point(&self, point_id: PointIdType) -> bool;
 

commit 45e64debc5cba28cfc9c94d9a20914607a80529b
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sun Sep 13 23:45:37 2020 +0200

    WIP: persistent segment

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index a4d4d8a0f..36e32944f 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -2,6 +2,7 @@ use thiserror::Error;
 use std::path::Path;
 use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo};
 use std::result;
+use sled::Error;
 
 
 /// Trait for versionable & saveable objects.
@@ -20,11 +21,22 @@ pub enum OperationError {
     #[error("Vector inserting error: expected dim: {expected_dim}, got {received_dim}")]
     WrongVector { expected_dim: usize, received_dim: usize },
     #[error("No point with id {missed_point_id} found")]
-    PointIdError { missed_point_id: PointIdType }
+    PointIdError { missed_point_id: PointIdType },
+    #[error("Service runtime error: {description}")]
+    ServiceError { description: String }
+}
+
+
+impl From<Error> for OperationError {
+    fn from(err: Error) -> Self {
+        OperationError::ServiceError { description: format!("persistence error: {:?}", err) }
+    }
 }
 
 pub type Result<T> = result::Result<T, OperationError>;
 
+pub type OperationResult<T> = result::Result<T, OperationError>;
+
 
 /// Define all operations which can be performed with Segment.
 /// Assume, that all operations are idempotent - which means that

commit e51d8bfec50751e7cf3f62268ddc532fc750ec2a
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sun Sep 20 20:59:58 2020 +0200

    WIP: persistace

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 36e32944f..433d2b072 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -3,6 +3,8 @@ use std::path::Path;
 use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo};
 use std::result;
 use sled::Error;
+use std::io::Error as IoError;
+use atomicwrites::Error as AtomicIoError;
 
 
 /// Trait for versionable & saveable objects.
@@ -23,9 +25,25 @@ pub enum OperationError {
     #[error("No point with id {missed_point_id} found")]
     PointIdError { missed_point_id: PointIdType },
     #[error("Service runtime error: {description}")]
-    ServiceError { description: String }
+    ServiceError { description: String },
 }
 
+impl<E> From<AtomicIoError<E>> for OperationError {
+    fn from(err: AtomicIoError<E>) -> Self {
+        match err {
+            AtomicIoError::Internal(io_err) => OperationError::from(io_err),
+            AtomicIoError::User(_user_err) => OperationError::ServiceError {
+                description: format!("Unknown atomic write error")
+            },
+        }
+    }
+}
+
+impl From<IoError> for OperationError {
+    fn from(err: IoError) -> Self {
+        OperationError::ServiceError { description: format!("{}", err) }
+    }
+}
 
 impl From<Error> for OperationError {
     fn from(err: Error) -> Self {
@@ -38,7 +56,7 @@ pub type Result<T> = result::Result<T, OperationError>;
 pub type OperationResult<T> = result::Result<T, OperationError>;
 
 
-/// Define all operations which can be performed with Segment.
+/// Define all operations which can be performed with Segment or Segment-like entity.
 /// Assume, that all operations are idempotent - which means that
 ///     no matter how much time they will consequently executed - storage state will be the same.
 pub trait SegmentEntry {
@@ -56,7 +74,7 @@ pub trait SegmentEntry {
 
     fn delete_point(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
 
-    fn set_full_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: TheMap<PayloadKeyType, PayloadType>)-> Result<bool>;
+    fn set_full_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: TheMap<PayloadKeyType, PayloadType>) -> Result<bool>;
 
     fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType, payload: PayloadType) -> Result<bool>;
 
@@ -78,5 +96,11 @@ pub trait SegmentEntry {
 
     fn info(&self) -> SegmentInfo;
 
+    /// Flushes current segment state into a persistent storage, if possible
+    /// Returns maximum version number which is guaranteed to be persisted.
+    fn flush(&self) -> Result<SeqNumberType>;
+
+    /// Removes all persisted data and forces to destroy segment
+    fn drop(self) -> Result<()>;
 }
 

commit 7495fd1d81bd13d9260a84c36142141d601a51e2
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Tue Sep 29 13:15:18 2020 +0200

    storage type selection in optimizer

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 433d2b072..1fbe2ba28 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use thiserror::Error;
 use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo};
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo, SegmentConfig};
 use std::result;
 use sled::Error;
 use std::io::Error as IoError;
@@ -94,8 +94,12 @@ pub trait SegmentEntry {
     /// Return number of vectors in this segment
     fn vectors_count(&self) -> usize;
 
+    /// Get current stats of the segment
     fn info(&self) -> SegmentInfo;
 
+    /// Get segment configuration
+    fn config(&self) -> SegmentConfig;
+
     /// Flushes current segment state into a persistent storage, if possible
     /// Returns maximum version number which is guaranteed to be persisted.
     fn flush(&self) -> Result<SeqNumberType>;

commit e8961628847bfcbb7f88f52b59e7245dab4970c5
Author: Andrey Vasnetsov <vasnetsov93@gmail.com>
Date:   Sun Oct 4 21:08:41 2020 +0200

    removing old segments data after optimization

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 1fbe2ba28..2c744eb2c 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -105,6 +105,6 @@ pub trait SegmentEntry {
     fn flush(&self) -> Result<SeqNumberType>;
 
     /// Removes all persisted data and forces to destroy segment
-    fn drop(self) -> Result<()>;
+    fn drop_data(&mut self) -> Result<()>;
 }
 

commit bb879a3f80295d81146dbe6cea1a0f4a05c5fe89
Author: Andrei Vasnetsov <andrei.vasnetsov@moberries.com>
Date:   Tue Oct 20 21:21:33 2020 +0200

    do not update unappendable collections + update vectors directly in simple segments

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 2c744eb2c..f117d984c 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -51,8 +51,6 @@ impl From<Error> for OperationError {
     }
 }
 
-pub type Result<T> = result::Result<T, OperationError>;
-
 pub type OperationResult<T> = result::Result<T, OperationError>;
 
 
@@ -68,23 +66,23 @@ pub trait SegmentEntry {
               filter: Option<&Filter>,
               top: usize,
               params: Option<&SearchParams>,
-    ) -> Result<Vec<ScoredPoint>>;
+    ) -> OperationResult<Vec<ScoredPoint>>;
 
-    fn upsert_point(&mut self, op_num: SeqNumberType, point_id: PointIdType, vector: &Vec<VectorElementType>) -> Result<bool>;
+    fn upsert_point(&mut self, op_num: SeqNumberType, point_id: PointIdType, vector: &Vec<VectorElementType>) -> OperationResult<bool>;
 
-    fn delete_point(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
+    fn delete_point(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> OperationResult<bool>;
 
-    fn set_full_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: TheMap<PayloadKeyType, PayloadType>) -> Result<bool>;
+    fn set_full_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: TheMap<PayloadKeyType, PayloadType>) -> OperationResult<bool>;
 
-    fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType, payload: PayloadType) -> Result<bool>;
+    fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType, payload: PayloadType) -> OperationResult<bool>;
 
-    fn delete_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType) -> Result<bool>;
+    fn delete_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType) -> OperationResult<bool>;
 
-    fn clear_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> Result<bool>;
+    fn clear_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> OperationResult<bool>;
 
-    fn vector(&self, point_id: PointIdType) -> Result<Vec<VectorElementType>>;
+    fn vector(&self, point_id: PointIdType) -> OperationResult<Vec<VectorElementType>>;
 
-    fn payload(&self, point_id: PointIdType) -> Result<TheMap<PayloadKeyType, PayloadType>>;
+    fn payload(&self, point_id: PointIdType) -> OperationResult<TheMap<PayloadKeyType, PayloadType>>;
 
     fn iter_points(&self) -> Box<dyn Iterator<Item=PointIdType> + '_>;
 
@@ -100,11 +98,14 @@ pub trait SegmentEntry {
     /// Get segment configuration
     fn config(&self) -> SegmentConfig;
 
+    /// Get current stats of the segment
+    fn is_appendable(&self) -> bool;
+
     /// Flushes current segment state into a persistent storage, if possible
     /// Returns maximum version number which is guaranteed to be persisted.
-    fn flush(&self) -> Result<SeqNumberType>;
+    fn flush(&self) -> OperationResult<SeqNumberType>;
 
     /// Removes all persisted data and forces to destroy segment
-    fn drop_data(&mut self) -> Result<()>;
+    fn drop_data(&mut self) -> OperationResult<()>;
 }
 

commit 0909b70c2cddee57a60559d1320bf1e01f99aed0
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Sun Dec 13 00:26:55 2020 +0100

    replace sled with rocksdb

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index f117d984c..73b6d09d2 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -2,9 +2,9 @@ use thiserror::Error;
 use std::path::Path;
 use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo, SegmentConfig};
 use std::result;
-use sled::Error;
 use std::io::Error as IoError;
 use atomicwrites::Error as AtomicIoError;
+use rocksdb::Error;
 
 
 /// Trait for versionable & saveable objects.
@@ -47,7 +47,7 @@ impl From<IoError> for OperationError {
 
 impl From<Error> for OperationError {
     fn from(err: Error) -> Self {
-        OperationError::ServiceError { description: format!("persistence error: {:?}", err) }
+        OperationError::ServiceError { description: format!("persistence error: {}", err) }
     }
 }
 

commit e5d7ac7721f16360e71d4358b5e524c65e0a9b87
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Sat Nov 21 00:47:19 2020 +0100

    extend payload storage interface + start functions for creating struct index

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 73b6d09d2..88cae4a96 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -24,6 +24,8 @@ pub enum OperationError {
     WrongVector { expected_dim: usize, received_dim: usize },
     #[error("No point with id {missed_point_id} found")]
     PointIdError { missed_point_id: PointIdType },
+    #[error("Payload type does not match with previously given for field {field_name}. Expected: {expected_type}")]
+    TypeError { field_name: PayloadKeyType, expected_type: String },
     #[error("Service runtime error: {description}")]
     ServiceError { description: String },
 }

commit 725c33aab2758093511f04bd41c82659134d20f8
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Mar 16 21:13:22 2021 +0100

    endpoint option to manage indexes

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 88cae4a96..d9a8bb1b7 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -109,5 +109,11 @@ pub trait SegmentEntry {
 
     /// Removes all persisted data and forces to destroy segment
     fn drop_data(&mut self) -> OperationResult<()>;
+
+    /// Delete field index, if exists
+    fn delete_field_index(&mut self, op_num: SeqNumberType, key: &PayloadKeyType) -> OperationResult<bool>;
+
+    /// Create index for a payload field, if not exists
+    fn create_field_index(&mut self, op_num: SeqNumberType, key: &PayloadKeyType) -> OperationResult<bool>;
 }
 

commit 398da04aad196c6a40ba35ac004a4f3a6a256d5e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Mar 30 01:54:55 2021 +0200

    add indexing optimizer + enable mmap and structure index rebuilding + fix issues

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index d9a8bb1b7..a918c9fc3 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use thiserror::Error;
 use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo, SegmentConfig};
+use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo, SegmentConfig, SegmentType};
 use std::result;
 use std::io::Error as IoError;
 use atomicwrites::Error as AtomicIoError;
@@ -94,6 +94,12 @@ pub trait SegmentEntry {
     /// Return number of vectors in this segment
     fn vectors_count(&self) -> usize;
 
+    /// Number of vectors, marked as deleted
+    fn deleted_count(&self) -> usize;
+
+    /// Get segment type
+    fn segment_type(&self) -> SegmentType;
+
     /// Get current stats of the segment
     fn info(&self) -> SegmentInfo;
 

commit e0636b492065b1c94604216be55bb3a97da0078e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Mar 30 18:50:13 2021 +0200

    optimized segment building in a separate directory

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index a918c9fc3..e8431ff3f 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -121,5 +121,8 @@ pub trait SegmentEntry {
 
     /// Create index for a payload field, if not exists
     fn create_field_index(&mut self, op_num: SeqNumberType, key: &PayloadKeyType) -> OperationResult<bool>;
+
+    /// Get indexed fields
+    fn get_indexed_fields(&self) -> Vec<PayloadKeyType>;
 }
 

commit a633e625f3ef909eba1f0b3455e46dc19cd0c1c0
Author: Joan Fontanals <jfontanalsmartinez@gmail.com>
Date:   Wed May 26 23:59:57 2021 +0200

    allow set full payload from serde_json Values (#15)
    
    * allow set full payload from serde_json Values
    
    * move payloadinterface and variant to segment
    
    * expose direct json string in segment
    
    * refactor extract function
    
    * handle from payloadinterface
    
    * add test on filter nested
    
    * update lib/segment/src/segment.rs
    
    Co-authored-by: Andrey Vasnetsov <vasnetsov93@gmail.com>
    
    * use payloadinterface in collection
    
    Co-authored-by: Andrey Vasnetsov <vasnetsov93@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index e8431ff3f..272b1ac77 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -76,6 +76,8 @@ pub trait SegmentEntry {
 
     fn set_full_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: TheMap<PayloadKeyType, PayloadType>) -> OperationResult<bool>;
 
+    fn set_full_payload_with_value(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: &str) -> OperationResult<bool>;
+
     fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType, payload: PayloadType) -> OperationResult<bool>;
 
     fn delete_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType) -> OperationResult<bool>;

commit c83ddec2cbc25e2ddd60019e3001bb17aeefcba7
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu May 27 00:54:44 2021 +0200

    refactor for PR #15

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 272b1ac77..1367b6a2e 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -53,6 +53,12 @@ impl From<Error> for OperationError {
     }
 }
 
+impl From<serde_json::Error> for OperationError {
+    fn from(err: serde_json::Error) -> Self {
+        OperationError::ServiceError { description: format!("Json error: {}", err) }
+    }
+}
+
 pub type OperationResult<T> = result::Result<T, OperationError>;
 
 
@@ -76,7 +82,7 @@ pub trait SegmentEntry {
 
     fn set_full_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: TheMap<PayloadKeyType, PayloadType>) -> OperationResult<bool>;
 
-    fn set_full_payload_with_value(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: &str) -> OperationResult<bool>;
+    fn set_full_payload_with_json(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: &str) -> OperationResult<bool>;
 
     fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType, payload: PayloadType) -> OperationResult<bool>;
 

commit d30e6fa8ee7e5dc1d58298f099cffea5fa20f02f
Author: trean <trean.mi@gmail.com>
Date:   Sun Jun 20 15:30:12 2021 +0200

    Implementation of points scroll API #38 (#40)
    
    * WIP: filtered points iterator #38
    
    * add paginated filtered point request function #38
    
    * add scroll api + openapi definitions #38
    
    * fix openapi #38

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 1367b6a2e..1a2ad0210 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -96,6 +96,9 @@ pub trait SegmentEntry {
 
     fn iter_points(&self) -> Box<dyn Iterator<Item=PointIdType> + '_>;
 
+    /// Paginate over points which satisfies filtering condition starting with `offset` id including.
+    fn read_filtered<'a>(&'a self, offset: PointIdType, limit: usize, filter: Option<&'a Filter>) -> Vec<PointIdType>;
+
     /// Check if there is point with `point_id` in this segment.
     fn has_point(&self, point_id: PointIdType) -> bool;
 

commit a667747369deabec7ef719bad17b0941619b46b1
Author: Konstantin <kgrech@users.noreply.github.com>
Date:   Tue Jun 29 09:17:50 2021 +0100

    Applied and enforced rust fmt code formatting tool (#48)
    
    * Apply cargo fmt command
    
    * Enabled cargo fmt on build

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 1a2ad0210..18b73687b 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,11 +1,13 @@
-use thiserror::Error;
-use std::path::Path;
-use crate::types::{SeqNumberType, VectorElementType, Filter, PointIdType, PayloadKeyType, PayloadType, SearchParams, ScoredPoint, TheMap, SegmentInfo, SegmentConfig, SegmentType};
-use std::result;
-use std::io::Error as IoError;
+use crate::types::{
+    Filter, PayloadKeyType, PayloadType, PointIdType, ScoredPoint, SearchParams, SegmentConfig,
+    SegmentInfo, SegmentType, SeqNumberType, TheMap, VectorElementType,
+};
 use atomicwrites::Error as AtomicIoError;
 use rocksdb::Error;
-
+use std::io::Error as IoError;
+use std::path::Path;
+use std::result;
+use thiserror::Error;
 
 /// Trait for versionable & saveable objects.
 pub trait VersionedPersistable {
@@ -16,16 +18,21 @@ pub trait VersionedPersistable {
     fn ack_persistance(&mut self, version: SeqNumberType);
 }
 
-
 #[derive(Error, Debug)]
 #[error("{0}")]
 pub enum OperationError {
     #[error("Vector inserting error: expected dim: {expected_dim}, got {received_dim}")]
-    WrongVector { expected_dim: usize, received_dim: usize },
+    WrongVector {
+        expected_dim: usize,
+        received_dim: usize,
+    },
     #[error("No point with id {missed_point_id} found")]
     PointIdError { missed_point_id: PointIdType },
     #[error("Payload type does not match with previously given for field {field_name}. Expected: {expected_type}")]
-    TypeError { field_name: PayloadKeyType, expected_type: String },
+    TypeError {
+        field_name: PayloadKeyType,
+        expected_type: String,
+    },
     #[error("Service runtime error: {description}")]
     ServiceError { description: String },
 }
@@ -35,7 +42,7 @@ impl<E> From<AtomicIoError<E>> for OperationError {
         match err {
             AtomicIoError::Internal(io_err) => OperationError::from(io_err),
             AtomicIoError::User(_user_err) => OperationError::ServiceError {
-                description: format!("Unknown atomic write error")
+                description: format!("Unknown atomic write error"),
             },
         }
     }
@@ -43,25 +50,30 @@ impl<E> From<AtomicIoError<E>> for OperationError {
 
 impl From<IoError> for OperationError {
     fn from(err: IoError) -> Self {
-        OperationError::ServiceError { description: format!("{}", err) }
+        OperationError::ServiceError {
+            description: format!("{}", err),
+        }
     }
 }
 
 impl From<Error> for OperationError {
     fn from(err: Error) -> Self {
-        OperationError::ServiceError { description: format!("persistence error: {}", err) }
+        OperationError::ServiceError {
+            description: format!("persistence error: {}", err),
+        }
     }
 }
 
 impl From<serde_json::Error> for OperationError {
     fn from(err: serde_json::Error) -> Self {
-        OperationError::ServiceError { description: format!("Json error: {}", err) }
+        OperationError::ServiceError {
+            description: format!("Json error: {}", err),
+        }
     }
 }
 
 pub type OperationResult<T> = result::Result<T, OperationError>;
 
-
 /// Define all operations which can be performed with Segment or Segment-like entity.
 /// Assume, that all operations are idempotent - which means that
 ///     no matter how much time they will consequently executed - storage state will be the same.
@@ -69,35 +81,78 @@ pub trait SegmentEntry {
     /// Get current update version of the segment
     fn version(&self) -> SeqNumberType;
 
-    fn search(&self,
-              vector: &Vec<VectorElementType>,
-              filter: Option<&Filter>,
-              top: usize,
-              params: Option<&SearchParams>,
+    fn search(
+        &self,
+        vector: &Vec<VectorElementType>,
+        filter: Option<&Filter>,
+        top: usize,
+        params: Option<&SearchParams>,
     ) -> OperationResult<Vec<ScoredPoint>>;
 
-    fn upsert_point(&mut self, op_num: SeqNumberType, point_id: PointIdType, vector: &Vec<VectorElementType>) -> OperationResult<bool>;
-
-    fn delete_point(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> OperationResult<bool>;
-
-    fn set_full_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: TheMap<PayloadKeyType, PayloadType>) -> OperationResult<bool>;
-
-    fn set_full_payload_with_json(&mut self, op_num: SeqNumberType, point_id: PointIdType, full_payload: &str) -> OperationResult<bool>;
-
-    fn set_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType, payload: PayloadType) -> OperationResult<bool>;
-
-    fn delete_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType, key: &PayloadKeyType) -> OperationResult<bool>;
-
-    fn clear_payload(&mut self, op_num: SeqNumberType, point_id: PointIdType) -> OperationResult<bool>;
+    fn upsert_point(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+        vector: &Vec<VectorElementType>,
+    ) -> OperationResult<bool>;
+
+    fn delete_point(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+    ) -> OperationResult<bool>;
+
+    fn set_full_payload(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+        full_payload: TheMap<PayloadKeyType, PayloadType>,
+    ) -> OperationResult<bool>;
+
+    fn set_full_payload_with_json(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+        full_payload: &str,
+    ) -> OperationResult<bool>;
+
+    fn set_payload(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+        key: &PayloadKeyType,
+        payload: PayloadType,
+    ) -> OperationResult<bool>;
+
+    fn delete_payload(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+        key: &PayloadKeyType,
+    ) -> OperationResult<bool>;
+
+    fn clear_payload(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+    ) -> OperationResult<bool>;
 
     fn vector(&self, point_id: PointIdType) -> OperationResult<Vec<VectorElementType>>;
 
-    fn payload(&self, point_id: PointIdType) -> OperationResult<TheMap<PayloadKeyType, PayloadType>>;
+    fn payload(
+        &self,
+        point_id: PointIdType,
+    ) -> OperationResult<TheMap<PayloadKeyType, PayloadType>>;
 
-    fn iter_points(&self) -> Box<dyn Iterator<Item=PointIdType> + '_>;
+    fn iter_points(&self) -> Box<dyn Iterator<Item = PointIdType> + '_>;
 
     /// Paginate over points which satisfies filtering condition starting with `offset` id including.
-    fn read_filtered<'a>(&'a self, offset: PointIdType, limit: usize, filter: Option<&'a Filter>) -> Vec<PointIdType>;
+    fn read_filtered<'a>(
+        &'a self,
+        offset: PointIdType,
+        limit: usize,
+        filter: Option<&'a Filter>,
+    ) -> Vec<PointIdType>;
 
     /// Check if there is point with `point_id` in this segment.
     fn has_point(&self, point_id: PointIdType) -> bool;
@@ -128,12 +183,19 @@ pub trait SegmentEntry {
     fn drop_data(&mut self) -> OperationResult<()>;
 
     /// Delete field index, if exists
-    fn delete_field_index(&mut self, op_num: SeqNumberType, key: &PayloadKeyType) -> OperationResult<bool>;
+    fn delete_field_index(
+        &mut self,
+        op_num: SeqNumberType,
+        key: &PayloadKeyType,
+    ) -> OperationResult<bool>;
 
     /// Create index for a payload field, if not exists
-    fn create_field_index(&mut self, op_num: SeqNumberType, key: &PayloadKeyType) -> OperationResult<bool>;
+    fn create_field_index(
+        &mut self,
+        op_num: SeqNumberType,
+        key: &PayloadKeyType,
+    ) -> OperationResult<bool>;
 
     /// Get indexed fields
     fn get_indexed_fields(&self) -> Vec<PayloadKeyType>;
 }
-

commit d796c9da42377f11ae15b6941baa53963bda27ab
Author: Konstantin <kgrech@users.noreply.github.com>
Date:   Fri Jul 2 14:17:04 2021 +0100

    Avoid useless vector copy during scoring (#51)
    
    * Avoid vector copy during scoring
    
    * Fixing ptr_arg clippy rules for &[VectorElementType]

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 18b73687b..a85587f13 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -83,7 +83,7 @@ pub trait SegmentEntry {
 
     fn search(
         &self,
-        vector: &Vec<VectorElementType>,
+        vector: &[VectorElementType],
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,
@@ -93,7 +93,7 @@ pub trait SegmentEntry {
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
-        vector: &Vec<VectorElementType>,
+        vector: &[VectorElementType],
     ) -> OperationResult<bool>;
 
     fn delete_point(

commit 0e1a6e17507d56e7f6a7f764e7fa56a494753d4d
Author: Konstantin <kgrech@users.noreply.github.com>
Date:   Fri Jul 2 16:51:54 2021 +0100

    [Clippy] Fix a range of warnings (#52)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index a85587f13..597fb48d9 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -42,7 +42,7 @@ impl<E> From<AtomicIoError<E>> for OperationError {
         match err {
             AtomicIoError::Internal(io_err) => OperationError::from(io_err),
             AtomicIoError::User(_user_err) => OperationError::ServiceError {
-                description: format!("Unknown atomic write error"),
+                description: "Unknown atomic write error".to_owned(),
             },
         }
     }

commit 93e0fb5c2c8f85f232bef82f48ab2b80c43f76cc
Author: Konstantin <kgrech@users.noreply.github.com>
Date:   Sat Jul 3 12:12:21 2021 +0100

    [CLIPPY] Fix the last portion of rules and enable CI check (#53)
    
    * [CLIPPY] Fixed the warning for references of the user defined types
    
    * [CLIPPY] Fix module naming issue
    
    * [CLIPPY] Fix the last set of warnings and enable clippy check during CI
    
    * Moved cargo fmt and cargo clippy into it's own action

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 597fb48d9..3d687cc48 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use crate::types::{
-    Filter, PayloadKeyType, PayloadType, PointIdType, ScoredPoint, SearchParams, SegmentConfig,
-    SegmentInfo, SegmentType, SeqNumberType, TheMap, VectorElementType,
+    Filter, PayloadKeyType, PayloadKeyTypeRef, PayloadType, PointIdType, ScoredPoint, SearchParams,
+    SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, TheMap, VectorElementType,
 };
 use atomicwrites::Error as AtomicIoError;
 use rocksdb::Error;
@@ -120,7 +120,7 @@ pub trait SegmentEntry {
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
-        key: &PayloadKeyType,
+        key: PayloadKeyTypeRef,
         payload: PayloadType,
     ) -> OperationResult<bool>;
 
@@ -128,7 +128,7 @@ pub trait SegmentEntry {
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
-        key: &PayloadKeyType,
+        key: PayloadKeyTypeRef,
     ) -> OperationResult<bool>;
 
     fn clear_payload(
@@ -186,14 +186,14 @@ pub trait SegmentEntry {
     fn delete_field_index(
         &mut self,
         op_num: SeqNumberType,
-        key: &PayloadKeyType,
+        key: PayloadKeyTypeRef,
     ) -> OperationResult<bool>;
 
     /// Create index for a payload field, if not exists
     fn create_field_index(
         &mut self,
         op_num: SeqNumberType,
-        key: &PayloadKeyType,
+        key: PayloadKeyTypeRef,
     ) -> OperationResult<bool>;
 
     /// Get indexed fields

commit f55e5aa7b75593a3ca4fa82a42b29d765b69bc2b
Author: HaiCheViet <cheviethai123@gmail.com>
Date:   Tue Oct 12 16:07:36 2021 +0700

    Features/filter payload (#104)
    
    * update more test
    
    * update fmt
    
    * reduce non usecode and update docker version
    
    * update commend code
    
    * update name filter
    
    * renames and minor fixes
    
    * fix linter
    
    Co-authored-by: hai che <haiche@jobhop.com>
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    Co-authored-by: Andrey Vasnetsov <vasnetsov93@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 3d687cc48..6adb43a18 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use crate::types::{
     Filter, PayloadKeyType, PayloadKeyTypeRef, PayloadType, PointIdType, ScoredPoint, SearchParams,
-    SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, TheMap, VectorElementType,
+    SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, TheMap, VectorElementType, WithPayload,
 };
 use atomicwrites::Error as AtomicIoError;
 use rocksdb::Error;
@@ -84,6 +84,7 @@ pub trait SegmentEntry {
     fn search(
         &self,
         vector: &[VectorElementType],
+        with_payload: &WithPayload,
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,

commit bf3d8c25753188b4ca5e69a13c7f26e3c383f05b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Sun Oct 24 18:10:39 2021 +0200

    data consistency fixes and updates (#112)
    
    * update segment version after completed update only
    
    * more stable updates: check pre-existing points on update, fail recovery, WAL proper ack. check_unprocessed_points WIP
    
    * switch to async channel
    
    * perform update operations in a separate thread (#111)
    
    * perform update operations in a separate thread
    
    * ordered sending update signal
    
    * locate a segment merging versioning bug
    
    * rename id_mapper -> id_tracker
    
    * per-record versioning
    
    * clippy fixes
    
    * cargo fmt
    
    * rm limit of open files
    
    * fail recovery test
    
    * cargo fmt
    
    * wait for worker stops befor dropping the runtime

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 6adb43a18..73fdc692c 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -5,20 +5,10 @@ use crate::types::{
 use atomicwrites::Error as AtomicIoError;
 use rocksdb::Error;
 use std::io::Error as IoError;
-use std::path::Path;
 use std::result;
 use thiserror::Error;
 
-/// Trait for versionable & saveable objects.
-pub trait VersionedPersistable {
-    fn persist(&self, directory: &Path) -> SeqNumberType;
-    fn load(directory: &Path) -> Self;
-
-    /// Save latest persisted version in memory, so the object will not be saved too much times
-    fn ack_persistance(&mut self, version: SeqNumberType);
-}
-
-#[derive(Error, Debug)]
+#[derive(Error, Debug, Clone)]
 #[error("{0}")]
 pub enum OperationError {
     #[error("Vector inserting error: expected dim: {expected_dim}, got {received_dim}")]
@@ -37,6 +27,13 @@ pub enum OperationError {
     ServiceError { description: String },
 }
 
+#[derive(Debug, Clone)]
+pub struct SegmentFailedState {
+    pub version: SeqNumberType,
+    pub point_id: Option<PointIdType>,
+    pub error: OperationError,
+}
+
 impl<E> From<AtomicIoError<E>> for OperationError {
     fn from(err: AtomicIoError<E>) -> Self {
         match err {
@@ -74,6 +71,16 @@ impl From<serde_json::Error> for OperationError {
 
 pub type OperationResult<T> = result::Result<T, OperationError>;
 
+pub fn get_service_error<T>(err: &OperationResult<T>) -> Option<OperationError> {
+    match err {
+        Ok(_) => None,
+        Err(error) => match error {
+            OperationError::ServiceError { .. } => Some(error.clone()),
+            _ => None,
+        },
+    }
+}
+
 /// Define all operations which can be performed with Segment or Segment-like entity.
 /// Assume, that all operations are idempotent - which means that
 ///     no matter how much time they will consequently executed - storage state will be the same.
@@ -81,6 +88,9 @@ pub trait SegmentEntry {
     /// Get current update version of the segment
     fn version(&self) -> SeqNumberType;
 
+    /// Get version of specified point
+    fn point_version(&self, point_id: PointIdType) -> Option<SeqNumberType>;
+
     fn search(
         &self,
         vector: &[VectorElementType],
@@ -199,4 +209,7 @@ pub trait SegmentEntry {
 
     /// Get indexed fields
     fn get_indexed_fields(&self) -> Vec<PayloadKeyType>;
+
+    /// Checks if segment errored during last operations
+    fn check_error(&self) -> Option<SegmentFailedState>;
 }

commit 617b97d3f7faee4c44913c3adf68935f4e47c47b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Dec 9 11:06:25 2021 +0100

    add comments for segment entitites (#136)
    
    * add comments for segment entitites
    
    * fmt
    
    * cargo fmt

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 73fdc692c..9fa31da67 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -27,6 +27,7 @@ pub enum OperationError {
     ServiceError { description: String },
 }
 
+/// Contains information regarding last operation error, which should be fixed before next operation could be processed
 #[derive(Debug, Clone)]
 pub struct SegmentFailedState {
     pub version: SeqNumberType,

commit 1ad529c315f79470f14cee7a251880563787c067
Author: Daniil <daniil@moteefe.com>
Date:   Mon Jan 3 19:12:01 2022 +0300

    Allow to include vector into search result (#176)
    
    * feat(#50): include vector into search result
    
    allow to specify 'with_vector' parameter in search api to get search results vector data
    
    * test(#50): fix tests
    
    * chore(#50): apply cargo fmt
    
    * chore(#50): update api docs
    
    run tools/generate_openapi_models.sh
    
    Co-authored-by: Daniil Sunyaev <dasforrum@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 9fa31da67..bd06faf0c 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -96,6 +96,7 @@ pub trait SegmentEntry {
         &self,
         vector: &[VectorElementType],
         with_payload: &WithPayload,
+        with_vector: bool,
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,

commit 0f91c9a5e29ef9065c79a20e0ace25be898beff8
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Jan 18 15:06:42 2022 +0100

    [WIP] Force optimization stop #31 (#161)
    
    * implement checking stop-flag in the optimization routine
    
    * wip: optimization cancel test
    
    * force optimization stop during the construction of vector index
    
    * fix clippy

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index bd06faf0c..0495783cc 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -25,6 +25,8 @@ pub enum OperationError {
     },
     #[error("Service runtime error: {description}")]
     ServiceError { description: String },
+    #[error("Operation cancelled: {description}")]
+    Cancelled { description: String },
 }
 
 /// Contains information regarding last operation error, which should be fixed before next operation could be processed

commit 559e7a80556d46a471e46de5b34a54ee5342d132
Author: Tim Eggert <tim@elbart.com>
Date:   Tue Jan 25 16:22:18 2022 +0100

    Delete Points By Filter API #39 (#250)
    
    * Delete Points By Filter API #39
    
    * make delete_by_filter part of existing delete query + fix merge issues #39
    
    * apply fmt
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 0495783cc..5c4325a41 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -216,4 +216,11 @@ pub trait SegmentEntry {
 
     /// Checks if segment errored during last operations
     fn check_error(&self) -> Option<SegmentFailedState>;
+
+    /// Delete points by the given filter
+    fn delete_filtered<'a>(
+        &'a mut self,
+        op_num: SeqNumberType,
+        filter: &'a Filter,
+    ) -> OperationResult<usize>;
 }

commit 65787f7f556b309ffbfc733c0e3e01433e87e92b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jan 31 13:18:07 2022 +0100

    UUID as point id (#265)
    
    * wip: u64 -> u128 + serialization tests
    
    * breaking: use more flexible structure for saving point ids
    
    * replace u64 external id type with enum
    
    * update openapi definitions for uuid + fix retrieve point api + bash script tests

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 5c4325a41..e6555737d 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -164,7 +164,7 @@ pub trait SegmentEntry {
     /// Paginate over points which satisfies filtering condition starting with `offset` id including.
     fn read_filtered<'a>(
         &'a self,
-        offset: PointIdType,
+        offset: Option<PointIdType>,
         limit: usize,
         filter: Option<&'a Filter>,
     ) -> Vec<PointIdType>;

commit e45379e4384062e92ee1c9be82c250047464c9ef
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Feb 16 09:59:11 2022 +0100

    Better optimizer error reporting + small bug fixes (#316)
    
    * optimizer error reporting, decouple data removing, optimizator fix
    
    * fmt
    
    * fmt + clippy
    
    * update openapi

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index e6555737d..34eb2e119 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -29,6 +29,14 @@ pub enum OperationError {
     Cancelled { description: String },
 }
 
+impl OperationError {
+    pub fn service_error(description: &str) -> OperationError {
+        OperationError::ServiceError {
+            description: description.to_string(),
+        }
+    }
+}
+
 /// Contains information regarding last operation error, which should be fixed before next operation could be processed
 #[derive(Debug, Clone)]
 pub struct SegmentFailedState {
@@ -41,34 +49,28 @@ impl<E> From<AtomicIoError<E>> for OperationError {
     fn from(err: AtomicIoError<E>) -> Self {
         match err {
             AtomicIoError::Internal(io_err) => OperationError::from(io_err),
-            AtomicIoError::User(_user_err) => OperationError::ServiceError {
-                description: "Unknown atomic write error".to_owned(),
-            },
+            AtomicIoError::User(_user_err) => {
+                OperationError::service_error("Unknown atomic write error")
+            }
         }
     }
 }
 
 impl From<IoError> for OperationError {
     fn from(err: IoError) -> Self {
-        OperationError::ServiceError {
-            description: format!("{}", err),
-        }
+        OperationError::service_error(&format!("IO Error: {}", err))
     }
 }
 
 impl From<Error> for OperationError {
     fn from(err: Error) -> Self {
-        OperationError::ServiceError {
-            description: format!("persistence error: {}", err),
-        }
+        OperationError::service_error(&format!("persistence error: {}", err))
     }
 }
 
 impl From<serde_json::Error> for OperationError {
     fn from(err: serde_json::Error) -> Self {
-        OperationError::ServiceError {
-            description: format!("Json error: {}", err),
-        }
+        OperationError::service_error(&format!("Json error: {}", err))
     }
 }
 

commit f69a7b740fb57da8ed887f36afb173a3f3846c66
Author: Gabriel Velo <gabriel.velo@gmail.com>
Date:   Mon Mar 21 07:09:10 2022 -0300

    json as payload (#306)
    
    add json as payload
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 34eb2e119..d5e4ec5c9 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,9 +1,11 @@
 use crate::types::{
-    Filter, PayloadKeyType, PayloadKeyTypeRef, PayloadType, PointIdType, ScoredPoint, SearchParams,
-    SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, TheMap, VectorElementType, WithPayload,
+    Filter, Payload, PayloadKeyType, PayloadKeyTypeRef, PayloadSchemaType, PointIdType,
+    ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
+    VectorElementType, WithPayload,
 };
 use atomicwrites::Error as AtomicIoError;
 use rocksdb::Error;
+use std::collections::HashMap;
 use std::io::Error as IoError;
 use std::result;
 use thiserror::Error;
@@ -23,6 +25,10 @@ pub enum OperationError {
         field_name: PayloadKeyType,
         expected_type: String,
     },
+    #[error("Unable to infer type for the field '{field_name}'. Please specify `field_type`")]
+    TypeInferenceError { field_name: PayloadKeyType },
+    /// Service Error prevents further update of the collection until it is fixed.
+    /// Should only be used for hardware, data corruption, IO, or other unexpected internal errors.
     #[error("Service runtime error: {description}")]
     ServiceError { description: String },
     #[error("Operation cancelled: {description}")]
@@ -119,26 +125,18 @@ pub trait SegmentEntry {
         point_id: PointIdType,
     ) -> OperationResult<bool>;
 
-    fn set_full_payload(
-        &mut self,
-        op_num: SeqNumberType,
-        point_id: PointIdType,
-        full_payload: TheMap<PayloadKeyType, PayloadType>,
-    ) -> OperationResult<bool>;
-
-    fn set_full_payload_with_json(
+    fn set_payload(
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
-        full_payload: &str,
+        payload: &Payload,
     ) -> OperationResult<bool>;
 
-    fn set_payload(
+    fn set_full_payload(
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
-        key: PayloadKeyTypeRef,
-        payload: PayloadType,
+        full_payload: &Payload,
     ) -> OperationResult<bool>;
 
     fn delete_payload(
@@ -156,10 +154,7 @@ pub trait SegmentEntry {
 
     fn vector(&self, point_id: PointIdType) -> OperationResult<Vec<VectorElementType>>;
 
-    fn payload(
-        &self,
-        point_id: PointIdType,
-    ) -> OperationResult<TheMap<PayloadKeyType, PayloadType>>;
+    fn payload(&self, point_id: PointIdType) -> OperationResult<Payload>;
 
     fn iter_points(&self) -> Box<dyn Iterator<Item = PointIdType> + '_>;
 
@@ -211,10 +206,11 @@ pub trait SegmentEntry {
         &mut self,
         op_num: SeqNumberType,
         key: PayloadKeyTypeRef,
+        field_type: &Option<PayloadSchemaType>,
     ) -> OperationResult<bool>;
 
     /// Get indexed fields
-    fn get_indexed_fields(&self) -> Vec<PayloadKeyType>;
+    fn get_indexed_fields(&self) -> HashMap<PayloadKeyType, PayloadSchemaType>;
 
     /// Checks if segment errored during last operations
     fn check_error(&self) -> Option<SegmentFailedState>;

commit 2a81fc91421b7815854d86903c29f8f05b362d66
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Mar 23 14:21:04 2022 +0100

    Remove sled for alias mappings (#402)
    
    * improve alias tests
    
    * introduce new alias persistence and remove Sled
    
    * introduce FileStorageError
    
    * use new error in AliasMapping
    
    * aliases are kept in memory and saved to disk when modified
    
    * better naming
    
    * make alias renaming atomic
    
    * fmt
    
    * use correct alias and docs
    
    * code review: cleaner error conversion

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index d5e4ec5c9..a5cdb5f34 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,3 +1,4 @@
+use crate::common::file_operations::FileStorageError;
 use crate::types::{
     Filter, Payload, PayloadKeyType, PayloadKeyTypeRef, PayloadSchemaType, PointIdType,
     ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
@@ -51,6 +52,22 @@ pub struct SegmentFailedState {
     pub error: OperationError,
 }
 
+impl From<FileStorageError> for OperationError {
+    fn from(err: FileStorageError) -> Self {
+        match err {
+            FileStorageError::IoError { description } => {
+                OperationError::service_error(&format!("IO Error: {}", description))
+            }
+            FileStorageError::UserAtomicIoError => {
+                OperationError::service_error("Unknown atomic write error")
+            }
+            FileStorageError::GenericError { description } => {
+                OperationError::service_error(&description)
+            }
+        }
+    }
+}
+
 impl<E> From<AtomicIoError<E>> for OperationError {
     fn from(err: AtomicIoError<E>) -> Self {
         match err {

commit 1b458780eb196ebbbd7fb1f6c5d85ce3b15adb64
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Jun 1 17:23:34 2022 +0200

    On disk payload storage (#634)
    
    * implement on-disk payload storage
    
    * fmt + clippy
    
    * config param for on-disk payload storage
    
    * upd openapi definitions
    
    * add integration test with on-disk payload
    
    * fix clippy
    
    * review fixes
    
    * fmt

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index a5cdb5f34..ffc217f0e 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -68,6 +68,12 @@ impl From<FileStorageError> for OperationError {
     }
 }
 
+impl From<serde_cbor::Error> for OperationError {
+    fn from(err: serde_cbor::Error) -> Self {
+        OperationError::service_error(&format!("Failed to parse data: {}", err))
+    }
+}
+
 impl<E> From<AtomicIoError<E>> for OperationError {
     fn from(err: AtomicIoError<E>) -> Self {
         match err {

commit 2601c017de71bbb46bc61df256ea8263a8fe23b9
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Jun 1 18:09:38 2022 +0200

    Smarter defaults (#637)
    
    * auto segments number
    
    * auto segments number
    
    * replace vector number limits with vector size limits
    
    * fmt

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index ffc217f0e..2dedecb19 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -195,6 +195,8 @@ pub trait SegmentEntry {
     /// Return number of vectors in this segment
     fn vectors_count(&self) -> usize;
 
+    fn vector_dim(&self) -> usize;
+
     /// Number of vectors, marked as deleted
     fn deleted_count(&self) -> usize;
 

commit 40245c5e306c380a1e3ba5b69d61f1fca7229bea
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Jun 16 12:38:43 2022 +0200

    Cifs dir delete (#705)
    
    * consume objects before removing the data
    
    * fmt
    
    * rm debug code

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 2dedecb19..96a66efb2 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -8,6 +8,7 @@ use atomicwrites::Error as AtomicIoError;
 use rocksdb::Error;
 use std::collections::HashMap;
 use std::io::Error as IoError;
+use std::path::PathBuf;
 use std::result;
 use thiserror::Error;
 
@@ -217,7 +218,10 @@ pub trait SegmentEntry {
     fn flush(&self) -> OperationResult<SeqNumberType>;
 
     /// Removes all persisted data and forces to destroy segment
-    fn drop_data(&mut self) -> OperationResult<()>;
+    fn drop_data(self) -> OperationResult<()>;
+
+    /// Path to data, owned by segment
+    fn data_path(&self) -> PathBuf;
 
     /// Delete field index, if exists
     fn delete_field_index(

commit 850e937c2a883e87622b43b3603be9ee1aaf02af
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jun 27 15:17:09 2022 +0200

    Storage points tracking refactoring (#750)
    
    * segment refactoring
    
    * rm points iterator
    
    * fmt

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 96a66efb2..52607633d 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -194,7 +194,7 @@ pub trait SegmentEntry {
     fn has_point(&self, point_id: PointIdType) -> bool;
 
     /// Return number of vectors in this segment
-    fn vectors_count(&self) -> usize;
+    fn points_count(&self) -> usize;
 
     fn vector_dim(&self) -> usize;
 

commit db9e5a3abb17b133130f73cf6c30a64b58fa0e21
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Jun 30 13:50:15 2022 +0200

    SegmentHolder snapshot all segments (#759)
    
    * SegmentHolder snapshot all segments
    
    * snapshot proxy segment
    
    * release segment resources
    
    * use write_version in points deletion

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 52607633d..baa027fe1 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -8,7 +8,7 @@ use atomicwrites::Error as AtomicIoError;
 use rocksdb::Error;
 use std::collections::HashMap;
 use std::io::Error as IoError;
-use std::path::PathBuf;
+use std::path::{Path, PathBuf};
 use std::result;
 use thiserror::Error;
 
@@ -104,6 +104,12 @@ impl From<serde_json::Error> for OperationError {
     }
 }
 
+impl From<fs_extra::error::Error> for OperationError {
+    fn from(err: fs_extra::error::Error) -> Self {
+        OperationError::service_error(&format!("File system error: {}", err))
+    }
+}
+
 pub type OperationResult<T> = result::Result<T, OperationError>;
 
 pub fn get_service_error<T>(err: &OperationResult<T>) -> Option<OperationError> {
@@ -250,4 +256,14 @@ pub trait SegmentEntry {
         op_num: SeqNumberType,
         filter: &'a Filter,
     ) -> OperationResult<usize>;
+
+    /// Take a snapshot of the segment.
+    ///
+    /// Creates a tar archive of the segment directory into `snapshot_dir_path`.
+    fn take_snapshot(&self, snapshot_dir_path: &Path) -> OperationResult<()>;
+
+    /// Copy the segment directory structure into `target_dir_path`
+    ///
+    /// Return the `Path` of the copy
+    fn copy_segment_directory(&self, target_dir_path: &Path) -> OperationResult<PathBuf>;
 }

commit e983b07a1521cd47771b63006defe54f74d181ce
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Sun Jul 3 01:14:05 2022 +0200

    Parallel hnsw building (#773)
    
    * parallel hnsw building
    
    * improve hnsw payload blocks condition
    
    * update indexing optimizer condition
    
    * fmt

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index baa027fe1..0b460c6c8 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -5,6 +5,7 @@ use crate::types::{
     VectorElementType, WithPayload,
 };
 use atomicwrites::Error as AtomicIoError;
+use rayon::ThreadPoolBuildError;
 use rocksdb::Error;
 use std::collections::HashMap;
 use std::io::Error as IoError;
@@ -53,6 +54,14 @@ pub struct SegmentFailedState {
     pub error: OperationError,
 }
 
+impl From<ThreadPoolBuildError> for OperationError {
+    fn from(error: ThreadPoolBuildError) -> Self {
+        OperationError::ServiceError {
+            description: format!("{}", error),
+        }
+    }
+}
+
 impl From<FileStorageError> for OperationError {
     fn from(err: FileStorageError) -> Self {
         match err {

commit 098bc4c751909647dc3887e88e1f44b91d52f32b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Jul 5 09:33:38 2022 +0200

    Count api (#777)
    
    * count api
    
    * test for approx counting
    
    * fmt + clippy
    
    * unit test
    
    * add warning

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 0b460c6c8..86c98a421 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,4 +1,5 @@
 use crate::common::file_operations::FileStorageError;
+use crate::index::field_index::CardinalityEstimation;
 use crate::types::{
     Filter, Payload, PayloadKeyType, PayloadKeyTypeRef, PayloadSchemaType, PointIdType,
     ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
@@ -211,6 +212,9 @@ pub trait SegmentEntry {
     /// Return number of vectors in this segment
     fn points_count(&self) -> usize;
 
+    /// Estimate points count in this segment for given filter.
+    fn estimate_points_count<'a>(&'a self, filter: Option<&'a Filter>) -> CardinalityEstimation;
+
     fn vector_dim(&self) -> usize;
 
     /// Number of vectors, marked as deleted

commit 026bd040b001f1c66e16fc911322f1f182d1cf0f
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Fri Jul 15 15:42:25 2022 +0300

    Add import formatting rules (#820)
    
    * Add import formatting rules
    
    * Review fix: update rusty hook

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 86c98a421..2f9b852dd 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,3 +1,13 @@
+use std::collections::HashMap;
+use std::io::Error as IoError;
+use std::path::{Path, PathBuf};
+use std::result;
+
+use atomicwrites::Error as AtomicIoError;
+use rayon::ThreadPoolBuildError;
+use rocksdb::Error;
+use thiserror::Error;
+
 use crate::common::file_operations::FileStorageError;
 use crate::index::field_index::CardinalityEstimation;
 use crate::types::{
@@ -5,14 +15,6 @@ use crate::types::{
     ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
     VectorElementType, WithPayload,
 };
-use atomicwrites::Error as AtomicIoError;
-use rayon::ThreadPoolBuildError;
-use rocksdb::Error;
-use std::collections::HashMap;
-use std::io::Error as IoError;
-use std::path::{Path, PathBuf};
-use std::result;
-use thiserror::Error;
 
 #[derive(Error, Debug, Clone)]
 #[error("{0}")]

commit 42e930ab8f2fbda080511d5f4fc1092ee70e8c88
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Fri Jul 22 19:27:07 2022 +0400

    Segment telemetry (#814)
    
    * segment telemetry
    
    * anonymize trait
    
    * fix build
    
    * are you happy fmt
    
    * anonimyze implementations
    
    * sliding window avg (#826)
    
    * Actix web telemetry (#828)
    
    * actix web telemetry
    
    * small as move
    
    * use tokio mutex instead of std
    
    * add comments
    
    * are you happy fmt
    
    * use u16 as http status code
    
    * telemetry structs rename
    
    * fix build
    
    * using parking lot mutex
    
    * telemetry web api (#842)
    
    * telemetry web api
    
    * telemetry openapi (#843)
    
    * use async mutex for telemetry collector
    
    * use tokio mutex for telemetry collector
    
    * are you happy fmt

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 2f9b852dd..c5cf4db83 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -10,6 +10,7 @@ use thiserror::Error;
 
 use crate::common::file_operations::FileStorageError;
 use crate::index::field_index::CardinalityEstimation;
+use crate::telemetry::SegmentTelemetry;
 use crate::types::{
     Filter, Payload, PayloadKeyType, PayloadKeyTypeRef, PayloadSchemaType, PointIdType,
     ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
@@ -281,4 +282,7 @@ pub trait SegmentEntry {
     ///
     /// Return the `Path` of the copy
     fn copy_segment_directory(&self, target_dir_path: &Path) -> OperationResult<PathBuf>;
+
+    // Get collected telemetry data of segment
+    fn get_telemetry_data(&self) -> SegmentTelemetry;
 }

commit f357bd5d9bc8cdc05915111419894d4f25512d83
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Mon Aug 15 13:47:52 2022 +0400

    Allow to flush segment in separate thread (#927)
    
    * allow to flush segment in separate thread
    
    * flush as separate function (#928)
    
    * flush as separate function
    
    * review suggestion
    
    * reduce locks during vector scoring
    
    * fmt
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    * don't run background flush twice
    
    * Update lib/segment/src/segment.rs
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    * increase flush interval
    
    * Update lib/segment/src/segment.rs
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    
    * are you happy fmt
    
    * test background flush
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index c5cf4db83..7d187e9ba 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -236,8 +236,10 @@ pub trait SegmentEntry {
     fn is_appendable(&self) -> bool;
 
     /// Flushes current segment state into a persistent storage, if possible
+    /// if sync == true, block current thread while flushing
+    ///
     /// Returns maximum version number which is guaranteed to be persisted.
-    fn flush(&self) -> OperationResult<SeqNumberType>;
+    fn flush(&self, sync: bool) -> OperationResult<SeqNumberType>;
 
     /// Removes all persisted data and forces to destroy segment
     fn drop_data(self) -> OperationResult<()>;

commit a2acca0345057dfb7fd8f218801a1c84cd77616b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Aug 18 14:48:17 2022 +0200

    Segment batch search (#813)
    
    * batch search benchmark
    
    * collect filter iterator in indexed search
    
    * fmt
    
    * fix
    
    * fix
    
    * fmt
    
    * use new tempfile create
    
    * auto batching
    
    * Clippy fixes
    
    * REST, gRPC and internal APIs
    
    * fix bugs & less duplication
    
    * two steps payload retrieval mechanism & fix duplication
    
    * add proxy_segment implementation & tests
    
    * add gRPC docs
    
    * remove unused code (#950)
    
    * only filter ids within a batch
    
    * add more equivalence tests
    
    * add integration test search vs batch
    
    * assert more search options in tests
    
    * cleanup assertions
    
    * fix offset panic
    
    * rename search batch API
    
    * openapi spec
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 7d187e9ba..2ed814456 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -155,6 +155,16 @@ pub trait SegmentEntry {
         params: Option<&SearchParams>,
     ) -> OperationResult<Vec<ScoredPoint>>;
 
+    fn search_batch(
+        &self,
+        vectors: &[&[VectorElementType]],
+        with_payload: &WithPayload,
+        with_vector: bool,
+        filter: Option<&Filter>,
+        top: usize,
+        params: Option<&SearchParams>,
+    ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
+
     fn upsert_point(
         &mut self,
         op_num: SeqNumberType,

commit f9fb0777a0fa67f3b297140493a3c71a4ef42064
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Mon Aug 22 10:41:08 2022 +0300

    Wrap rocksdb column usages (#951)
    
    * wrap rocksdb column usages
    
    * remove obsolete comments
    
    * are you happy clippy

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 2ed814456..80158d02a 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -5,7 +5,6 @@ use std::result;
 
 use atomicwrites::Error as AtomicIoError;
 use rayon::ThreadPoolBuildError;
-use rocksdb::Error;
 use thiserror::Error;
 
 use crate::common::file_operations::FileStorageError;
@@ -105,12 +104,6 @@ impl From<IoError> for OperationError {
     }
 }
 
-impl From<Error> for OperationError {
-    fn from(err: Error) -> Self {
-        OperationError::service_error(&format!("persistence error: {}", err))
-    }
-}
-
 impl From<serde_json::Error> for OperationError {
     fn from(err: serde_json::Error) -> Self {
         OperationError::service_error(&format!("Json error: {}", err))

commit be38254ee8f29902f66fe4bda13be13cf6bc3cef
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Sep 1 12:36:28 2022 +0200

    small refactoring (#746)
    
    * small refactoring
    
    * fix tests

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 80158d02a..24b7a3069 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -158,7 +158,7 @@ pub trait SegmentEntry {
         params: Option<&SearchParams>,
     ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
 
-    fn upsert_point(
+    fn upsert_vector(
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,

commit b9eee55a9fb6d53572622f62756a80e62484009e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Sep 1 12:50:12 2022 +0200

    Full text search (#963)
    
    * allow additional params for payload field index
    
    * fmt
    
    * wip: full text index building
    
    * fmt
    
    * text search request
    
    * text search request
    
    * full text index persitance and loading
    
    * fmt
    
    * enable fts index in mapping
    
    * clippy
    
    * fix tests + add integration test
    
    * review fixes: extend payload index test
    
    * revert incedental change

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 24b7a3069..61208ab38 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -11,7 +11,7 @@ use crate::common::file_operations::FileStorageError;
 use crate::index::field_index::CardinalityEstimation;
 use crate::telemetry::SegmentTelemetry;
 use crate::types::{
-    Filter, Payload, PayloadKeyType, PayloadKeyTypeRef, PayloadSchemaType, PointIdType,
+    Filter, Payload, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PointIdType,
     ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
     VectorElementType, WithPayload,
 };
@@ -262,11 +262,11 @@ pub trait SegmentEntry {
         &mut self,
         op_num: SeqNumberType,
         key: PayloadKeyTypeRef,
-        field_type: &Option<PayloadSchemaType>,
+        field_schema: Option<&PayloadFieldSchema>,
     ) -> OperationResult<bool>;
 
     /// Get indexed fields
-    fn get_indexed_fields(&self) -> HashMap<PayloadKeyType, PayloadSchemaType>;
+    fn get_indexed_fields(&self) -> HashMap<PayloadKeyType, PayloadFieldSchema>;
 
     /// Checks if segment errored during last operations
     fn check_error(&self) -> Option<SegmentFailedState>;

commit 24ac939b4a7a518cfdb209f32cff46e0c4c9f491
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Sep 5 15:09:39 2022 +0200

    Sync Points API (#985)
    
    * shard sync operation
    
    * fnt
    
    * tests
    
    * fix test
    
    * Update lib/collection/src/collection_manager/segments_updater.rs
    
    Co-authored-by: Egor Ivkov <e.o.ivkov@gmail.com>
    
    * Update lib/collection/src/collection_manager/segments_updater.rs
    
    Co-authored-by: Egor Ivkov <e.o.ivkov@gmail.com>
    
    * match payload after vector only
    
    * Update lib/collection/src/collection_manager/segments_updater.rs
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    
    Co-authored-by: Egor Ivkov <e.o.ivkov@gmail.com>
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 61208ab38..29082b316 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -212,6 +212,8 @@ pub trait SegmentEntry {
         filter: Option<&'a Filter>,
     ) -> Vec<PointIdType>;
 
+    fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;
+
     /// Check if there is point with `point_id` in this segment.
     fn has_point(&self, point_id: PointIdType) -> bool;
 

commit f6b21861939744e054a861d9771608b7e6b614e7
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Sun Sep 11 22:59:23 2022 +0400

    [WIP] Many named vectors per point (#958)
    
    * many named vectors per point (segment-level)
    
    * operation result for dim function
    
    * beautifulized vector name
    
    * fix naming bug
    
    * segment version migration
    
    * fmt
    
    * add segment tests
    
    * are you happy clippy
    
    * fix build
    
    * [WIP] many named vectors per point (collection-level) (#975)
    
    * config and search
    
    * fix placeholders for proxy segment move
    
    * remove VectorType from collection
    
    * are you happy fmt
    
    * vectors in grps messages
    
    * create collections with vectors
    
    * segment holder fixes
    
    * are you happy fmt
    
    * remove default vector name placeholders
    
    * are you happy fmt
    
    * are you happy clippy
    
    * fix build
    
    * fix web api
    
    * are you happy clippy
    
    * are you happy fmt
    
    * record vector&vectors
    
    * openapi update
    
    * fix openapi integration tests
    
    * segment builder fix todo
    
    * vector names for update from segment
    
    * remove unwrap
    
    * backward compatibility
    
    * upd openapi
    
    * backward compatible PointStruct
    
    * upd openapi
    
    * fix record back-comp
    
    * fmt
    
    * vector configuration backward compatibility
    
    * fix vetor storage size estimation
    
    * fmt
    
    * multi-vec segment test + index test
    
    * fmt
    
    * api integration tests
    
    * [WIP] Named vectors struct (#1002)
    
    * move to separate file
    
    * named vectors as struct
    
    * use cow
    
    * fix build
    
    * keys iterator
    
    * avoid copy in PointStruct -> get_vectors
    
    * avoid another copy
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 29082b316..31f5acc97 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -8,12 +8,14 @@ use rayon::ThreadPoolBuildError;
 use thiserror::Error;
 
 use crate::common::file_operations::FileStorageError;
+use crate::data_types::named_vectors::NamedVectors;
+use crate::data_types::vectors::VectorElementType;
 use crate::index::field_index::CardinalityEstimation;
 use crate::telemetry::SegmentTelemetry;
 use crate::types::{
     Filter, Payload, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PointIdType,
-    ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
-    VectorElementType, WithPayload,
+    ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, WithPayload,
+    WithVector,
 };
 
 #[derive(Error, Debug, Clone)]
@@ -24,6 +26,10 @@ pub enum OperationError {
         expected_dim: usize,
         received_dim: usize,
     },
+    #[error("Not existing vector name error: {received_name}")]
+    VectorNameNotExists { received_name: String },
+    #[error("Missed vector name error: {received_name}")]
+    MissedVectorName { received_name: String },
     #[error("No point with id {missed_point_id} found")]
     PointIdError { missed_point_id: PointIdType },
     #[error("Payload type does not match with previously given for field {field_name}. Expected: {expected_type}")]
@@ -57,6 +63,14 @@ pub struct SegmentFailedState {
     pub error: OperationError,
 }
 
+impl From<semver::Error> for OperationError {
+    fn from(error: semver::Error) -> Self {
+        OperationError::ServiceError {
+            description: error.to_string(),
+        }
+    }
+}
+
 impl From<ThreadPoolBuildError> for OperationError {
     fn from(error: ThreadPoolBuildError) -> Self {
         OperationError::ServiceError {
@@ -138,21 +152,25 @@ pub trait SegmentEntry {
     /// Get version of specified point
     fn point_version(&self, point_id: PointIdType) -> Option<SeqNumberType>;
 
+    #[allow(clippy::too_many_arguments)]
     fn search(
         &self,
+        vector_name: &str,
         vector: &[VectorElementType],
         with_payload: &WithPayload,
-        with_vector: bool,
+        with_vector: &WithVector,
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,
     ) -> OperationResult<Vec<ScoredPoint>>;
 
+    #[allow(clippy::too_many_arguments)]
     fn search_batch(
         &self,
+        vector_name: &str,
         vectors: &[&[VectorElementType]],
         with_payload: &WithPayload,
-        with_vector: bool,
+        with_vector: &WithVector,
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,
@@ -162,7 +180,7 @@ pub trait SegmentEntry {
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
-        vector: &[VectorElementType],
+        vectors: &NamedVectors,
     ) -> OperationResult<bool>;
 
     fn delete_point(
@@ -198,7 +216,13 @@ pub trait SegmentEntry {
         point_id: PointIdType,
     ) -> OperationResult<bool>;
 
-    fn vector(&self, point_id: PointIdType) -> OperationResult<Vec<VectorElementType>>;
+    fn vector(
+        &self,
+        vector_name: &str,
+        point_id: PointIdType,
+    ) -> OperationResult<Vec<VectorElementType>>;
+
+    fn all_vectors(&self, point_id: PointIdType) -> OperationResult<NamedVectors>;
 
     fn payload(&self, point_id: PointIdType) -> OperationResult<Payload>;
 
@@ -223,7 +247,9 @@ pub trait SegmentEntry {
     /// Estimate points count in this segment for given filter.
     fn estimate_points_count<'a>(&'a self, filter: Option<&'a Filter>) -> CardinalityEstimation;
 
-    fn vector_dim(&self) -> usize;
+    fn vector_dim(&self, vector_name: &str) -> OperationResult<usize>;
+
+    fn vector_dims(&self) -> HashMap<String, usize>;
 
     /// Number of vectors, marked as deleted
     fn deleted_count(&self) -> usize;

commit ba26e2f85e36fc1f4258de9351ad4d90082056c0
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Sep 12 17:55:56 2022 +0200

    Faster filtered scroll (#1003)
    
    * faster filtered scroll for low cardinality filters
    
    * add test
    
    * scroll strategy heuristics

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 31f5acc97..f7247cb2e 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -232,7 +232,7 @@ pub trait SegmentEntry {
     fn read_filtered<'a>(
         &'a self,
         offset: Option<PointIdType>,
-        limit: usize,
+        limit: Option<usize>,
         filter: Option<&'a Filter>,
     ) -> Vec<PointIdType>;
 

commit 9324be1d6038b4ba66ca776eb7e753e69fe5d624
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Oct 17 20:12:10 2022 +0200

    [Replication] Add replicas (#1085)
    
    * Add replicas to ReplicaSet
    
    * unproxify shard & miscs
    
    * no exlusive write locking while adding replicas
    
    * on_optimizer_config_update on Shard with async. recursion
    
    * no exlusive write locking while removing replicas
    
    * shortcut replica set propagation #1101
    
    * remove unused field
    
    * make RequestShardTransfer callback sync.
    
    * promote local & remote to replica state
    
    * fixes for replica sync api (#1123)
    
    * code review
    
    * fix replica set update - fail only if all failed
    
    * Add replica redesign (#1131)
    
    * refactor shard/mod.rs
    
    * wip
    
    * fmt
    
    * it compiles
    
    * temporary disable replica placemeant change on replication factor
    
    * fmt
    
    * finish todos
    
    * small refactoring
    
    * remove change::add
    
    * replica-set -> shard-replica-set
    
    * fmt
    
    * upd openapi
    
    * fix finish transfer logic
    
    * fix existing integration tests
    
    * shard transfer validation
    
    * fmt
    
    * review fixes
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index f7247cb2e..bdd358d56 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -236,6 +236,7 @@ pub trait SegmentEntry {
         filter: Option<&'a Filter>,
     ) -> Vec<PointIdType>;
 
+    /// Read points in [from; to) range
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;
 
     /// Check if there is point with `point_id` in this segment.

commit 2d02f209ae9bdbb5140a361c06e469770ab05d73
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Dec 6 12:31:24 2022 +0100

    Missed points on update fix (#1255)
    
    * add context to point-not-found error
    
    * fmt
    
    * add backtrace
    
    * use upgradable lock
    
    * unique points in insert operation
    
    * remove debug code

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index bdd358d56..e071a6af6 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -30,7 +30,7 @@ pub enum OperationError {
     VectorNameNotExists { received_name: String },
     #[error("Missed vector name error: {received_name}")]
     MissedVectorName { received_name: String },
-    #[error("No point with id {missed_point_id} found")]
+    #[error("No point with id {missed_point_id}")]
     PointIdError { missed_point_id: PointIdType },
     #[error("Payload type does not match with previously given for field {field_name}. Expected: {expected_type}")]
     TypeError {

commit 6a0d90775574d00afc94e8aa567b596fd4e4a15f
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Dec 6 12:31:38 2022 +0100

    include backtrace for service errors (#1256)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index e071a6af6..56d37890f 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,3 +1,4 @@
+use std::backtrace::Backtrace;
 use std::collections::HashMap;
 use std::io::Error as IoError;
 use std::path::{Path, PathBuf};
@@ -42,7 +43,10 @@ pub enum OperationError {
     /// Service Error prevents further update of the collection until it is fixed.
     /// Should only be used for hardware, data corruption, IO, or other unexpected internal errors.
     #[error("Service runtime error: {description}")]
-    ServiceError { description: String },
+    ServiceError {
+        description: String,
+        backtrace: Option<String>,
+    },
     #[error("Operation cancelled: {description}")]
     Cancelled { description: String },
 }
@@ -51,6 +55,7 @@ impl OperationError {
     pub fn service_error(description: &str) -> OperationError {
         OperationError::ServiceError {
             description: description.to_string(),
+            backtrace: Some(Backtrace::force_capture().to_string()),
         }
     }
 }
@@ -67,6 +72,7 @@ impl From<semver::Error> for OperationError {
     fn from(error: semver::Error) -> Self {
         OperationError::ServiceError {
             description: error.to_string(),
+            backtrace: Some(Backtrace::force_capture().to_string()),
         }
     }
 }
@@ -75,6 +81,7 @@ impl From<ThreadPoolBuildError> for OperationError {
     fn from(error: ThreadPoolBuildError) -> Self {
         OperationError::ServiceError {
             description: format!("{}", error),
+            backtrace: Some(Backtrace::force_capture().to_string()),
         }
     }
 }

commit 8e8ed800f4cb4995d3449a6c1de0f41960042c8b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Dec 14 10:11:46 2022 +0100

    Shard build refactoring (#1280)
    
    * refactor some code of shard creation and optimizers
    
    * Shard build refactoring debug (#1279)
    
    * add debig code
    
    * debug code
    
    * debug code
    
    * debug code
    
    * debug code
    
    * debug code
    
    * debug code
    
    * debug code
    
    * debug code
    
    * debug code
    
    * debug code
    
    * refactor stop-checking during the optimization
    
    * remove debug logs
    
    * improve delete-renaming schema
    
    * fmt
    
    * move collection file removing to the async task
    
    * rename check_optimization_stopped into more general check_process_stopped

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 56d37890f..fa8f62fd2 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -3,6 +3,7 @@ use std::collections::HashMap;
 use std::io::Error as IoError;
 use std::path::{Path, PathBuf};
 use std::result;
+use std::sync::atomic::{AtomicBool, Ordering};
 
 use atomicwrites::Error as AtomicIoError;
 use rayon::ThreadPoolBuildError;
@@ -60,6 +61,15 @@ impl OperationError {
     }
 }
 
+pub fn check_process_stopped(stopped: &AtomicBool) -> OperationResult<()> {
+    if stopped.load(Ordering::Relaxed) {
+        return Err(OperationError::Cancelled {
+            description: "process cancelled by service".to_string(),
+        });
+    }
+    Ok(())
+}
+
 /// Contains information regarding last operation error, which should be fixed before next operation could be processed
 #[derive(Debug, Clone)]
 pub struct SegmentFailedState {

commit 6eca194f71bc20ca3e945560d47414eb10c14874
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Fri Jan 13 11:44:42 2023 +0100

    Fix segment snapshotting (#1321) (#1334)
    
    * WIP: Fix `Segment::take_snapshot`
    
    TODO:
    - This commit, probably, breaks snapshotting of segments with memmapped vector storage
    - `ProxySegment::take_snapshot` seems to potentially similar bug
    
    * WIP: Fix `Segment::take_snapshot`
    
    - Fix snapshotting of `StructPayloadIndex`
    - Fix snapshotting of segments with memmapped vector storage
    - Temporarily break `ProxySegment::take_snapshot`
    
    * Fix `ProxySegment::take_snapshot`
    
    * Remove `copy_segment_directory` test
    
    * nitpicking
    
    * clippy fixes
    
    * use OperationError::service_error
    
    * Cleanup `TinyMap` trait bounds and derive `Debug`
    
    * Fix `test_snapshot` test
    
    - Derive `Debug` for `NamedVectors`
    
    * Move utility functions from `segment.rs` to `utils` module
    
    * Contextualize `segment::utils::fs::move_all` a bit more carefully
    
    * Fix a typo
    
    * add backward compatibility with old snapshot formats
    
    * fmt
    
    * add snapshot for compatibility test
    
    * git lfs is a piece of shit
    
    * Nitpicking
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index fa8f62fd2..c28b0c34c 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -53,9 +53,9 @@ pub enum OperationError {
 }
 
 impl OperationError {
-    pub fn service_error(description: &str) -> OperationError {
+    pub fn service_error(description: impl Into<String>) -> OperationError {
         OperationError::ServiceError {
-            description: description.to_string(),
+            description: description.into(),
             backtrace: Some(Backtrace::force_capture().to_string()),
         }
     }
@@ -100,13 +100,13 @@ impl From<FileStorageError> for OperationError {
     fn from(err: FileStorageError) -> Self {
         match err {
             FileStorageError::IoError { description } => {
-                OperationError::service_error(&format!("IO Error: {}", description))
+                OperationError::service_error(format!("IO Error: {}", description))
             }
             FileStorageError::UserAtomicIoError => {
                 OperationError::service_error("Unknown atomic write error")
             }
             FileStorageError::GenericError { description } => {
-                OperationError::service_error(&description)
+                OperationError::service_error(description)
             }
         }
     }
@@ -114,7 +114,7 @@ impl From<FileStorageError> for OperationError {
 
 impl From<serde_cbor::Error> for OperationError {
     fn from(err: serde_cbor::Error) -> Self {
-        OperationError::service_error(&format!("Failed to parse data: {}", err))
+        OperationError::service_error(format!("Failed to parse data: {}", err))
     }
 }
 
@@ -131,19 +131,19 @@ impl<E> From<AtomicIoError<E>> for OperationError {
 
 impl From<IoError> for OperationError {
     fn from(err: IoError) -> Self {
-        OperationError::service_error(&format!("IO Error: {}", err))
+        OperationError::service_error(format!("IO Error: {}", err))
     }
 }
 
 impl From<serde_json::Error> for OperationError {
     fn from(err: serde_json::Error) -> Self {
-        OperationError::service_error(&format!("Json error: {}", err))
+        OperationError::service_error(format!("Json error: {}", err))
     }
 }
 
 impl From<fs_extra::error::Error> for OperationError {
     fn from(err: fs_extra::error::Error) -> Self {
-        OperationError::service_error(&format!("File system error: {}", err))
+        OperationError::service_error(format!("File system error: {}", err))
     }
 }
 
@@ -327,12 +327,7 @@ pub trait SegmentEntry {
     /// Take a snapshot of the segment.
     ///
     /// Creates a tar archive of the segment directory into `snapshot_dir_path`.
-    fn take_snapshot(&self, snapshot_dir_path: &Path) -> OperationResult<()>;
-
-    /// Copy the segment directory structure into `target_dir_path`
-    ///
-    /// Return the `Path` of the copy
-    fn copy_segment_directory(&self, target_dir_path: &Path) -> OperationResult<PathBuf>;
+    fn take_snapshot(&self, snapshot_dir_path: &Path) -> OperationResult<PathBuf>;
 
     // Get collected telemetry data of segment
     fn get_telemetry_data(&self) -> SegmentTelemetry;

commit 66aa2c99cedbdc31648feb0b28cb469d7021bef4
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Jan 26 17:48:52 2023 +0100

    Clippy rust 1.67 (#1406)
    
    * inline format! args
    
    * inline format! args
    
    * explicit lifetime could be elided
    
    * fmt

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index c28b0c34c..ee061b65d 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -90,7 +90,7 @@ impl From<semver::Error> for OperationError {
 impl From<ThreadPoolBuildError> for OperationError {
     fn from(error: ThreadPoolBuildError) -> Self {
         OperationError::ServiceError {
-            description: format!("{}", error),
+            description: format!("{error}"),
             backtrace: Some(Backtrace::force_capture().to_string()),
         }
     }
@@ -100,7 +100,7 @@ impl From<FileStorageError> for OperationError {
     fn from(err: FileStorageError) -> Self {
         match err {
             FileStorageError::IoError { description } => {
-                OperationError::service_error(format!("IO Error: {}", description))
+                OperationError::service_error(format!("IO Error: {description}"))
             }
             FileStorageError::UserAtomicIoError => {
                 OperationError::service_error("Unknown atomic write error")
@@ -114,7 +114,7 @@ impl From<FileStorageError> for OperationError {
 
 impl From<serde_cbor::Error> for OperationError {
     fn from(err: serde_cbor::Error) -> Self {
-        OperationError::service_error(format!("Failed to parse data: {}", err))
+        OperationError::service_error(format!("Failed to parse data: {err}"))
     }
 }
 
@@ -131,19 +131,19 @@ impl<E> From<AtomicIoError<E>> for OperationError {
 
 impl From<IoError> for OperationError {
     fn from(err: IoError) -> Self {
-        OperationError::service_error(format!("IO Error: {}", err))
+        OperationError::service_error(format!("IO Error: {err}"))
     }
 }
 
 impl From<serde_json::Error> for OperationError {
     fn from(err: serde_json::Error) -> Self {
-        OperationError::service_error(format!("Json error: {}", err))
+        OperationError::service_error(format!("Json error: {err}"))
     }
 }
 
 impl From<fs_extra::error::Error> for OperationError {
     fn from(err: fs_extra::error::Error) -> Self {
-        OperationError::service_error(format!("File system error: {}", err))
+        OperationError::service_error(format!("File system error: {err}"))
     }
 }
 

commit 511704d88d8f915eb142e5873edbf20d249c3132
Author: Tim Vise <tim+github@visee.me>
Date:   Thu Apr 20 12:06:29 2023 +0200

    Add support for deleted vectors in segments (#1724)
    
    * Use resize rather than while-push loop
    
    * Add deleted flags to simple vector storage
    
    * Add deleted flag to memmap vector storage
    
    * Map BitSlice on mmap file for deleted flags
    
    * Use vector specific deletion BitSlice in RawScorer
    
    * Use BitSlice for deleted points, fix check point logic, clarify names
    
    * Extract div_ceil function to shared module
    
    * We can use unchecked set and replace because we just checked the length
    
    * Add deleted count function to vector storage
    
    * Add vector storage point deletion tests
    
    * Keep deleted state in simple vector storage with update_from, add test
    
    * Keep deleted state in memmap vector storage with update_from, add test
    
    * Simplify div_ceil
    
    * Improve deletion handling in update_from in mmap vector storage
    
    * Improve performance, use trickery to get BitSlice view over deleted mmap
    
    * Use BitSlice where possible, construct BitVec more efficiently
    
    * Incorporate vector specific delete flags in quantized raw scorer
    
    * Don't pin MmapMut, it is not required
    
    * With quantization, keep mmap deleted flags in RAM for better performance
    
    * Advice the kernel to prepare deleted flags mmap for faster future access
    
    * Simplify deleted bitslice access, add bound check, remove unused function
    
    * Fix compilation on Windows
    
    * Cleanup
    
    * Rename delete functions to delete_{point,vec} to prevent confusion
    
    * Use then_some rather than match a boolean
    
    * Lock deleted flags in memory only when quantization is available
    
    * Add docs and stabilize issue link to dev_ceil
    
    * Flush deleted mmap when closing segment
    
    This requires us to to wrap the memory map struct in an Arc and Mutex.
    Though this may look inefficient, it doesn't have a negative side effect
    on deleted flag performance, because the flags are accessed through a
    BitSlice that is separate and doesn't use locking.
    
    * Rename some point functions to vec because that makes more sense
    
    * Simplify delete flag fetching option, use deref func instead of asterisk
    
    * Do not calculate slice size manually, use size_of_val
    
    * remove test raw scorer
    
    * use deref in check
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index ee061b65d..8320e63bf 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -270,7 +270,7 @@ pub trait SegmentEntry {
     fn vector_dims(&self) -> HashMap<String, usize>;
 
     /// Number of vectors, marked as deleted
-    fn deleted_count(&self) -> usize;
+    fn deleted_point_count(&self) -> usize;
 
     /// Get segment type
     fn segment_type(&self) -> SegmentType;

commit ecfeefdaa8d1a74358960842a99b96dee8147dd3
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Mon Apr 24 13:02:29 2023 +0200

    Improve handling of out-of-disk-space errors during Qdrant startup (#1755)
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 8320e63bf..9f2b568c0 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -98,17 +98,7 @@ impl From<ThreadPoolBuildError> for OperationError {
 
 impl From<FileStorageError> for OperationError {
     fn from(err: FileStorageError) -> Self {
-        match err {
-            FileStorageError::IoError { description } => {
-                OperationError::service_error(format!("IO Error: {description}"))
-            }
-            FileStorageError::UserAtomicIoError => {
-                OperationError::service_error("Unknown atomic write error")
-            }
-            FileStorageError::GenericError { description } => {
-                OperationError::service_error(description)
-            }
-        }
+        Self::service_error(err.to_string())
     }
 }
 

commit 7edf599d73cd65b47476be72009684451b7533a9
Author: Tim Vise <tim+github@visee.me>
Date:   Tue Apr 25 14:31:04 2023 +0200

    Make query planner aware of deleted points and vectors (#1757)
    
    * Exclude deleted vectors from HNSW graph building stage
    
    * When estimating query cardinality, use available points as baseline
    
    We should not use the total number of points in a segment, because a
    portion of it may be soft deleted. Instead, we use the available
    (non-deleted) points as baseline.
    
    * Add plain search check to unfiltered HNSW search due to deleted points
    
    * Cardinality sampling on available points, ignore deleted named vectors
    
    * Estimate available vectors in query planner, now consider deleted points
    
    In the query planner, we want to know the number of available points as
    accurately as possible. This isn't possible because we only know the
    number of deletions and vectors can be deleted in two places: as point
    or as vector. These deletions may overlap. This now estimates the number
    of deleted vectors based on the segment state. It assumes that point and
    vector deletions have an overlap of 20%. This is an arbitrary
    percentage, but reflects an almost-worst scenario.
    
    This improves because the number of deleted points wasn't considered at
    all before.
    
    * Remove unused function from trait
    
    * Fix bench compilation error
    
    * Fix typo in docs
    
    * Base whether to do plain search in HNSW upon full scan threshold
    
    * Remove index threshold from HNSW config, only use full scan threshold
    
    * Simplify timer aggregator assignment in HNSW search
    
    * Remove vector storage type from cardinality function parameters
    
    * Propagate point deletes to all its vectors
    
    * Check for deleted vectors first, this makes early return possible
    
    Since point deletes are now propagated to vectors, deleted points are
    included in vector deletions. Because of that we can check if the vector
    is deleted first so we can return early and skip the point deletion
    check.
    
    For integrity we also check if the point is deleted, if the vector was
    not. That is because it may happen that point deletions are not properly
    propagated to vectors.
    
    * Don't use arbitrary vector count estimation, use vector count directly
    
    Before we had to estimate the number of vectors (for a named vector)
    because vectors could be deleted as point or vector. Point deletes are
    now propagated to vector deletes, that means we can simply use the
    deleted vector count which is now much more accurate.
    
    * When sampling IDs, check deleted vecs before deleted points
    
    * On segment consistency check, delete vectors for deleted points
    
    * Fix vector delete state not being kept when updating storage from other
    
    * Fix segment builder skipping deleted vectors breaking offsets
    
    * update segment to handle optional vectors + add test (#1781)
    
    * update segment to handle optional vectors + add test
    
    * Only update stored record when deleting if it wasn't deleted already
    
    * Reformat comment
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>
    
    * Fix missed vector name test, these are now marked as deleted
    
    * upd test
    
    * upd test
    
    * Update consensus test
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 9f2b568c0..aa6def22f 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -196,6 +196,13 @@ pub trait SegmentEntry {
         point_id: PointIdType,
     ) -> OperationResult<bool>;
 
+    fn delete_vector(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+        vector_name: &str,
+    ) -> OperationResult<bool>;
+
     fn set_payload(
         &mut self,
         op_num: SeqNumberType,
@@ -227,7 +234,7 @@ pub trait SegmentEntry {
         &self,
         vector_name: &str,
         point_id: PointIdType,
-    ) -> OperationResult<Vec<VectorElementType>>;
+    ) -> OperationResult<Option<Vec<VectorElementType>>>;
 
     fn all_vectors(&self, point_id: PointIdType) -> OperationResult<NamedVectors>;
 
@@ -250,6 +257,8 @@ pub trait SegmentEntry {
     fn has_point(&self, point_id: PointIdType) -> bool;
 
     /// Return number of vectors in this segment
+    ///
+    /// - Includes soft deleted points
     fn points_count(&self) -> usize;
 
     /// Estimate points count in this segment for given filter.

commit 1c85c9b2359c81897da57ea7dd5e9f0bdbf67791
Author: Tim Vise <tim+github@visee.me>
Date:   Fri Apr 28 10:36:58 2023 +0200

    Add optimizer for many deleted points, make aware of deleted points and vectors (#1758)
    
    * Minor collection optimizer cleanup
    
    * Make optimizers better aware of available vs soft deleted points
    
    * Fix incorrect deleted state on proxy segment for double delete
    
    * Rename upsert_vector to upsert_point, because we work with points
    
    * Refactor point methods for more clear and consistent naming
    
    * Replace internal_size in IdTracker with total_point_count
    
    * Keep track of vector deletion count on storage creation
    
    * Add sparse index optimizer, to optimize indexes with high deletion count
    
    * Add minimum vector count threshold to sparse index optimizer
    
    * Add sparse index optimizer test
    
    * Use consistent naming, write vector in full everywhere
    
    * Simplify vacuum optimizer a bit
    
    * Merge sparse index optimizer into vacuum optimizer
    
    * Improve update_from in segment builder by returning early
    
    * More accurately count vectors in segment optimizer
    
    * Remove random from vacuum optimizer tests to make them more reliable
    
    * Don't expose the total points in segment info, use available points
    
    * Process review feedback
    
    * Compare available vectors against indexed ones in vacuum optimizer
    
    This is much better than using the number of soft-deleted vectors when
    the segment was created for calculations. Not to mention that value had
    other problems as well.
    
    * Remove create_deleted_vector_count field, update vacuum test parameters
    
    * Potentially solve out of bound panic when building index
    
    * Review fixes:
    
    - Propagate deleted flags into payload hnsw building
    - Use `total` number of points for building HNSW instead of number of
      available points
    - minor refactoring of `hnsw_config` copy -> clone
    - Better detection of `indexed_points` in HNSW
    
    * fix assert condition
    
    * Optional named vectors optimizer reveiw 2 (#1794)
    
    * review with Ivan
    
    * fmt
    
    * remove available_vector_count from segment entry
    
    * remove total_point_count from segment entry
    
    ---------
    
    Co-authored-by: Ivan Pleshkov <pleshkov.ivan@gmail.com>
    
    * rollback changes in deleted count in proxy segment
    
    * improve vector threshold detection logic in optimized_segment_builder
    
    * style changes
    
    * fix propagate deleted points to vectors
    
    * Fix typo in method name
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    Co-authored-by: Ivan Pleshkov <pleshkov.ivan@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index aa6def22f..592fc9487 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -150,8 +150,9 @@ pub fn get_service_error<T>(err: &OperationResult<T>) -> Option<OperationError>
 }
 
 /// Define all operations which can be performed with Segment or Segment-like entity.
-/// Assume, that all operations are idempotent - which means that
-///     no matter how much time they will consequently executed - storage state will be the same.
+///
+/// Assume all operations are idempotent - which means that no matter how many times an operation
+/// is executed - the storage state will be the same.
 pub trait SegmentEntry {
     /// Get current update version of the segment
     fn version(&self) -> SeqNumberType;
@@ -183,7 +184,7 @@ pub trait SegmentEntry {
         params: Option<&SearchParams>,
     ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
 
-    fn upsert_vector(
+    fn upsert_point(
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
@@ -256,19 +257,19 @@ pub trait SegmentEntry {
     /// Check if there is point with `point_id` in this segment.
     fn has_point(&self, point_id: PointIdType) -> bool;
 
-    /// Return number of vectors in this segment
-    ///
-    /// - Includes soft deleted points
-    fn points_count(&self) -> usize;
-
-    /// Estimate points count in this segment for given filter.
-    fn estimate_points_count<'a>(&'a self, filter: Option<&'a Filter>) -> CardinalityEstimation;
+    /// Estimate available point count in this segment for given filter.
+    fn estimate_point_count<'a>(&'a self, filter: Option<&'a Filter>) -> CardinalityEstimation;
 
     fn vector_dim(&self, vector_name: &str) -> OperationResult<usize>;
 
     fn vector_dims(&self) -> HashMap<String, usize>;
 
-    /// Number of vectors, marked as deleted
+    /// Number of available points
+    ///
+    /// - excludes soft deleted points
+    fn available_point_count(&self) -> usize;
+
+    /// Number of deleted points
     fn deleted_point_count(&self) -> usize;
 
     /// Get segment type

commit 93d784f269eb54eeec7e1c68e925119241eeeebb
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Tue May 2 20:54:13 2023 +0200

    Improve handling out-of-RAM errors during Qdrant startup (#1777)
    
    * WIP: Start working on out-of-RAM errors handling [skip ci]
    
    * Implement basic handling of out-of-RAM errors during Qdrant startup
    
    * Try to fix CI fail by allowing both V1 and V2 cgroups
    
    * Try to fix CI fail by improving cgroups handling
    
    * Fix cgroups path detection/handling (+ some minor stylistic changes)
    
    * fixup! Fix cgroups path detection/handling (+ some minor stylistic changes)
    
    * Add test
    
    * Enable low RAM test
    
    * fixup! Add test
    
    * free memory checks
    
    * rm unused function
    
    * Oom fallback script (#1809)
    
    * add recover mode in qdrant + script for handelling OOM
    
    * fix clippy
    
    * reformat entrypoint.sh
    
    * fix test
    
    * add logging to test
    
    * fix test
    
    * fix test
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 592fc9487..8e17f2a7a 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,6 +1,6 @@
 use std::backtrace::Backtrace;
-use std::collections::HashMap;
-use std::io::Error as IoError;
+use std::collections::{HashMap, TryReserveError};
+use std::io::{Error as IoError, ErrorKind};
 use std::path::{Path, PathBuf};
 use std::result;
 use std::sync::atomic::{AtomicBool, Ordering};
@@ -19,6 +19,7 @@ use crate::types::{
     ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, WithPayload,
     WithVector,
 };
+use crate::utils::mem::Mem;
 
 #[derive(Error, Debug, Clone)]
 #[error("{0}")]
@@ -48,6 +49,8 @@ pub enum OperationError {
         description: String,
         backtrace: Option<String>,
     },
+    #[error("Out of memory, free: {free}, {description}")]
+    OutOfMemory { description: String, free: u64 },
     #[error("Operation cancelled: {description}")]
     Cancelled { description: String },
 }
@@ -121,7 +124,16 @@ impl<E> From<AtomicIoError<E>> for OperationError {
 
 impl From<IoError> for OperationError {
     fn from(err: IoError) -> Self {
-        OperationError::service_error(format!("IO Error: {err}"))
+        match err.kind() {
+            ErrorKind::OutOfMemory => {
+                let free_memory = Mem::new().available_memory_bytes();
+                OperationError::OutOfMemory {
+                    description: format!("IO Error: {err}"),
+                    free: free_memory,
+                }
+            }
+            _ => OperationError::service_error(format!("IO Error: {err}")),
+        }
     }
 }
 
@@ -137,6 +149,16 @@ impl From<fs_extra::error::Error> for OperationError {
     }
 }
 
+impl From<TryReserveError> for OperationError {
+    fn from(err: TryReserveError) -> Self {
+        let free_memory = Mem::new().available_memory_bytes();
+        OperationError::OutOfMemory {
+            description: format!("Failed to reserve memory: {err}"),
+            free: free_memory,
+        }
+    }
+}
+
 pub type OperationResult<T> = result::Result<T, OperationError>;
 
 pub fn get_service_error<T>(err: &OperationResult<T>) -> Option<OperationError> {

commit 5805811ad4b6d41aaa3033c4df36a4fe8536e958
Author: Tim Vise <tim+github@visee.me>
Date:   Fri May 5 15:18:19 2023 +0200

    Add gRPC interface to update/delete optional named vectors (#1816)
    
    * Add segment entry function to update named vectors
    
    * Use already available function to update existing vectors
    
    We already had a segment function to update existing named vectors. This
    change ensure we use that instead of separating it separately. As a
    bonus, this adds support for setting multiple named vectors at once.
    
    * Update set vectors ourselves, don't drop omitted vectors
    
    * Refactor vector updating functions, separate update and replace
    
    * Add basic vector ops, add update/delete functionality to segment updater
    
    * Add internal and public gRPC types and actions for vectors
    
    * Add gRPC API actions
    
    * Reformat
    
    * Add VectorOperations to vector ops, add basic validation
    
    * Validate gRPC vector types
    
    * Validate vector operation structs
    
    * Construct PointIdsList through From trait
    
    * Update gRPC docs
    
    * Use VectorsSelector for vector deletions in gRPC
    
    * Add support for updating multiple points/vectors in update vectors API
    
    * Update gRPC docs
    
    * Fix incorrect gRPC type numbering
    
    * Return point ID error from vector update/delete functions if not found
    
    * Fix disbalanced vectors test

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 8e17f2a7a..bca59d6a8 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -219,6 +219,13 @@ pub trait SegmentEntry {
         point_id: PointIdType,
     ) -> OperationResult<bool>;
 
+    fn update_vectors(
+        &mut self,
+        op_num: SeqNumberType,
+        point_id: PointIdType,
+        vectors: NamedVectors,
+    ) -> OperationResult<bool>;
+
     fn delete_vector(
         &mut self,
         op_num: SeqNumberType,

commit 45ae3e048b15f10e71b5825a9fc00ee7b7676390
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue May 9 18:01:01 2023 +0200

    Dynamic mmap vector storage (#1838)
    
    * wip: chunked mmap
    
    * Fix typo
    
    * insert and get methods
    
    * dynamic bitvec
    
    * clippy
    
    * wip: vector storage
    
    * wip: fmt
    
    * wip: mmap chunks
    
    * wip: mmap problems
    
    * Share transmuted mutable reference over mmap
    
    * option to enable appendable mmap vectors
    
    * fmt
    
    * rename storage status file
    
    * update tests
    
    * fix get deleted value range
    
    * add recovery to vector storage tests
    
    * add flush to tests
    
    * fix transmute from immutable to mutable
    
    * make transmuted pointer private
    
    * remove unused unsafe functions
    
    * force WAL flush if wait=true
    
    * move wal flush into updater thread
    
    * remove flush from update api
    
    * Minimize pub visibility for specialized/dangerous functions
    
    * Allocate vector with predefined capacity
    
    * Inline format parameters
    
    * Assert we have multiple chunks while testing, test is useless otherwise
    
    * Remove unnecessary scope
    
    * Remove unnecessary dereference
    
    * Random bool has 0.5 as standard distribution, use iter::repeat_with
    
    * Replace RemovableMmap::new with Default derive
    
    * Rename len to num_flags
    
    * Use Option replace as it is convention alongside take
    
    * Add FileId enum to replace error prone manual ID rotating
    
    * Use debug_assert_eq where applicable
    
    * Refactor drop and set to replace
    
    * Change default chunk size for chunked mmap vectors to 32MB
    
    This change is made as per GitHub review, because allocating a few
    storages with 128MB would take a significant amount of time and storage.
    
    See: https://github.com/qdrant/qdrant/pull/1838#discussion_r1187215475
    
    * Replace for-loops with iterators
    
    * Draft: add typed mmap to improve code safety (#1860)
    
    * Add typed mmap
    
    * Replace some crude mmap usages with typed mmap
    
    * Use typed mmap for deleted flags
    
    * Simplify dynamic mmap flags a lot with new typed mmap, remove flags option
    
    * Reformat
    
    * Remove old mmap functions that are now unused
    
    * Reimplement mmap locking for mmap_vectors
    
    * Add MmapBitSlice tests
    
    * Replace MmapChunk with new typed mmap
    
    * Update docs
    
    * Clean-up
    
    * Disable alignment assertions on Windows for now
    
    * Rename mmap lock to mlock to prevent confusion with lockable types
    
    * one more small test
    
    * Some review fixes
    
    * Add aliasing note
    
    * Add basic error handling in typed mmap constructors
    
    * Use typed mmap error handling throughout project
    
    * Move mmap type module to common
    
    * Fix transmute functions being unsound
    
    See https://github.com/qdrant/qdrant/pull/1860#discussion_r1188593854
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>
    Co-authored-by: Tim Vise <tim+github@visee.me>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index bca59d6a8..613534663 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -10,6 +10,7 @@ use rayon::ThreadPoolBuildError;
 use thiserror::Error;
 
 use crate::common::file_operations::FileStorageError;
+use crate::common::mmap_type::Error as MmapError;
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::vectors::VectorElementType;
 use crate::index::field_index::CardinalityEstimation;
@@ -105,6 +106,12 @@ impl From<FileStorageError> for OperationError {
     }
 }
 
+impl From<MmapError> for OperationError {
+    fn from(err: MmapError) -> Self {
+        Self::service_error(err.to_string())
+    }
+}
+
 impl From<serde_cbor::Error> for OperationError {
     fn from(err: serde_cbor::Error) -> Self {
         OperationError::service_error(format!("Failed to parse data: {err}"))

commit 75cb07c7e490f7654fe5908a9c8862e0912e0c99
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Wed May 10 20:20:52 2023 +0400

    Product quantization (#1615)
    
    * product quantization
    
    * update quantization version
    
    * refactor
    
    * change api
    
    * PQ -> product rename
    
    * fix grpc comment
    
    * fix tests
    
    * are you happy clippy
    
    * quantization version up
    
    * update quantization
    
    * provide max threads for kmeans
    
    * fix test build
    
    * pq unit tests
    
    * update quantization lib
    
    * update quantization version
    
    * update deleted flags for quantized raw scorer
    
    * fix build
    
    * are you happy fmt
    
    * update grpc docs
    
    * update openapi
    
    * restore storage_builder.try_reserve_exact
    
    * Update lib/segment/src/segment_constructor/segment_builder.rs
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * Update lib/segment/src/vector_storage/quantized/quantized_raw_scorer.rs
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * change pub to pub(super)
    
    * Update lib/segment/src/vector_storage/quantized/quantized_vectors.rs
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * rename to config_exists
    
    * Product quantization compression api (#1834)
    
    * product quantization compression api
    
    * update openapi and grpc docs
    
    * Update lib/api/src/grpc/proto/collections.proto
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * fix test build
    
    * are you happy fmt
    
    * update grpc docs
    
    ---------
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * product quantization with stopper (#1874)
    
    * product quantization with stopper
    
    * quantization version up
    
    * fix build
    
    * small comment fix
    
    ---------
    
    Co-authored-by: Tim Vise <tim+github@visee.me>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 613534663..e2f4da3fc 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -156,6 +156,12 @@ impl From<fs_extra::error::Error> for OperationError {
     }
 }
 
+impl From<quantization::EncodingError> for OperationError {
+    fn from(err: quantization::EncodingError) -> Self {
+        OperationError::service_error(format!("Quantization encoding error: {err}"))
+    }
+}
+
 impl From<TryReserveError> for OperationError {
     fn from(err: TryReserveError) -> Self {
         let free_memory = Mem::new().available_memory_bytes();

commit eae93b27767a784e1b07179ccdc9948e2caf9c80
Author: Damien Castelltort <dcastelltort@gmail.com>
Date:   Wed Jun 21 22:53:19 2023 +0200

    Configurable location of temporary snapshot files (#1960)
    
    * Issue 1905: Configurable location for the tmp snapshot files
    
    * Apply suggestions from code review
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * fix code review suggestions
    
    * clippy fix
    
    * Propagate temp path, use configured dir for snapshot creation
    
    * Use real temp dir in snapshot tests
    
    * Mention default temporary snapshot file path in configuration
    
    * Use temp everywhere rather than a mix of temp and tmp
    
    * Use consistent naming for temporary snapshot directories
    
    * Extract logic for temporary storage path into toc method
    
    * Resolve clippy warnings
    
    * Apply suggestions from code review
    
    Co-authored-by: Roman Titov <ffuugoo@users.noreply.github.com>
    
    ---------
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    Co-authored-by: timvisee <tim@visee.me>
    Co-authored-by: Roman Titov <ffuugoo@users.noreply.github.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index e2f4da3fc..e331dc3fe 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -369,7 +369,9 @@ pub trait SegmentEntry {
     /// Take a snapshot of the segment.
     ///
     /// Creates a tar archive of the segment directory into `snapshot_dir_path`.
-    fn take_snapshot(&self, snapshot_dir_path: &Path) -> OperationResult<PathBuf>;
+    /// Uses `temp_path` to prepare files to archive.
+    fn take_snapshot(&self, temp_path: &Path, snapshot_dir_path: &Path)
+        -> OperationResult<PathBuf>;
 
     // Get collected telemetry data of segment
     fn get_telemetry_data(&self) -> SegmentTelemetry;

commit 0fb05b38eae96948473871920a48e8500a20fe52
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jul 3 12:38:18 2023 +0200

    handle inconsistent vector storage in sync operation (#2185)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index e331dc3fe..9e68a46b4 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -50,6 +50,8 @@ pub enum OperationError {
         description: String,
         backtrace: Option<String>,
     },
+    #[error("Inconsistent storage: {description}")]
+    InconsistentStorage { description: String },
     #[error("Out of memory, free: {free}, {description}")]
     OutOfMemory { description: String, free: u64 },
     #[error("Operation cancelled: {description}")]

commit 396714f7faa04ac6a64d63c784adfda25d468737
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Wed Jul 5 00:30:15 2023 +0200

    Add missed vector preprocess (#2203)
    
    * test missed preprocess after segment update
    
    * missed preprocess
    
    * remove preprocess_named_vectors fn
    
    * are you happy clippy
    
    * fix integration tests
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 9e68a46b4..124f47977 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -225,7 +225,7 @@ pub trait SegmentEntry {
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
-        vectors: &NamedVectors,
+        vectors: NamedVectors,
     ) -> OperationResult<bool>;
 
     fn delete_point(

commit c07c840b27179d005b1929ef316a9da091cead0e
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Mon Jul 24 12:20:02 2023 +0200

    Dedup without large hashmap (#2292)
    
    * dedup without large hashmap
    
    * are you happy fmt
    
    * add comment with iterator ordering
    
    * Update lib/collection/src/collection_manager/holders/segment_holder.rs
    
    Co-authored-by: Roman Titov <ffuugoo@users.noreply.github.com>
    
    * remove unnecessary continue
    
    * review remarks
    
    ---------
    
    Co-authored-by: Roman Titov <ffuugoo@users.noreply.github.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 124f47977..9055ebc1a 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -285,6 +285,7 @@ pub trait SegmentEntry {
 
     fn payload(&self, point_id: PointIdType) -> OperationResult<Payload>;
 
+    /// Iterator over all points in segment in ascending order.
     fn iter_points(&self) -> Box<dyn Iterator<Item = PointIdType> + '_>;
 
     /// Paginate over points which satisfies filtering condition starting with `offset` id including.

commit 76f7d2fc68b124d3fe788900fd022b8daee0c60e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jul 24 12:45:33 2023 +0200

    Search timeout (#2293)
    
    * pass atomic bool from local shard to raw scorer
    
    * pass atomic bool from local shard to raw scorer
    
    * is_stopped in async scorer
    
    * fmt
    
    * is_stopped in quantized scorer
    
    * terminating scorer if stopped
    
    * enable timeout in local_shard
    
    * allow timeout configuration
    
    * use tokio spawn to ensure timeout handling if request is dropped
    
    * Revert "use tokio spawn to ensure timeout handling if request is dropped"
    
    This reverts commit 1068cf48d481b8856da41869b71b1f9a361f7e2d.
    
    * use stopping guard instead of task
    
    * report error if search request is stopped
    
    * fmt
    
    * refactor transient error handelling

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 9055ebc1a..70dc6de7a 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -207,6 +207,7 @@ pub trait SegmentEntry {
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,
+        is_stopped: &AtomicBool,
     ) -> OperationResult<Vec<ScoredPoint>>;
 
     #[allow(clippy::too_many_arguments)]
@@ -219,6 +220,7 @@ pub trait SegmentEntry {
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,
+        is_stopped: &AtomicBool,
     ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
 
     fn upsert_point(

commit 2df2334c4c7bc62a04e5b8177adc4d76b74ec74d
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Fri Aug 11 18:53:35 2023 +0200

    cancel quantization without panic (#2422)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 70dc6de7a..512dfad08 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -22,6 +22,8 @@ use crate::types::{
 };
 use crate::utils::mem::Mem;
 
+pub const PROCESS_CANCELLED_BY_SERVICE_MESSAGE: &str = "process cancelled by service";
+
 #[derive(Error, Debug, Clone)]
 #[error("{0}")]
 pub enum OperationError {
@@ -70,7 +72,7 @@ impl OperationError {
 pub fn check_process_stopped(stopped: &AtomicBool) -> OperationResult<()> {
     if stopped.load(Ordering::Relaxed) {
         return Err(OperationError::Cancelled {
-            description: "process cancelled by service".to_string(),
+            description: PROCESS_CANCELLED_BY_SERVICE_MESSAGE.to_string(),
         });
     }
     Ok(())
@@ -160,7 +162,16 @@ impl From<fs_extra::error::Error> for OperationError {
 
 impl From<quantization::EncodingError> for OperationError {
     fn from(err: quantization::EncodingError) -> Self {
-        OperationError::service_error(format!("Quantization encoding error: {err}"))
+        match err {
+            quantization::EncodingError::IOError(err)
+            | quantization::EncodingError::EncodingError(err)
+            | quantization::EncodingError::ArgumentsError(err) => {
+                OperationError::service_error(format!("Quantization encoding error: {err}"))
+            }
+            quantization::EncodingError::Stopped => OperationError::Cancelled {
+                description: PROCESS_CANCELLED_BY_SERVICE_MESSAGE.to_string(),
+            },
+        }
     }
 }
 

commit ecaff1023de967e0f2e3ea0facf98b80268ff87d
Author: Di Zhao <di.zhao@gmail.com>
Date:   Wed Aug 16 01:56:44 2023 -0700

    Add `indexed_only` to speed up search (#2431)
    
    * add ignore_plain_index to speed up search
    
    * remove unnecessary & for vectors_batch
    
    * format
    
    * add special handle for proxy segments where the wrapped segment is plain
    indexed
    
    * review refactoring
    
    * rollback changes in google.protobuf.rs
    
    ---------
    
    Co-authored-by: Di Zhao <diz@twitter.com>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 512dfad08..2f5e6443c 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -337,7 +337,7 @@ pub trait SegmentEntry {
     fn info(&self) -> SegmentInfo;
 
     /// Get segment configuration
-    fn config(&self) -> SegmentConfig;
+    fn config(&self) -> &SegmentConfig;
 
     /// Get current stats of the segment
     fn is_appendable(&self) -> bool;

commit c8bdec7b0616c47e1c3057b3f8ef8435833dc74f
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Tue Sep 5 09:26:24 2023 -0300

    Refactor batch search to allow different scorers (#2529)
    
    * add enum for vector query on segment search
    
    * rename newly introduced types
    
    * fix: handle QueryVector on async scorer
    
    * handle QueryVector in QuantizedVectors impl
    
    * fix async scorer test after refactor
    
    * rebase + refactor on queue_proxy_shard.rs
    
    * constrain refactor propagation to segment_searcher
    
    * fmt
    
    * fix after rebase

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 2f5e6443c..0dee55419 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -12,7 +12,7 @@ use thiserror::Error;
 use crate::common::file_operations::FileStorageError;
 use crate::common::mmap_type::Error as MmapError;
 use crate::data_types::named_vectors::NamedVectors;
-use crate::data_types::vectors::VectorElementType;
+use crate::data_types::vectors::{QueryVector, VectorElementType};
 use crate::index::field_index::CardinalityEstimation;
 use crate::telemetry::SegmentTelemetry;
 use crate::types::{
@@ -212,7 +212,7 @@ pub trait SegmentEntry {
     fn search(
         &self,
         vector_name: &str,
-        vector: &[VectorElementType],
+        vector: &QueryVector,
         with_payload: &WithPayload,
         with_vector: &WithVector,
         filter: Option<&Filter>,
@@ -225,7 +225,7 @@ pub trait SegmentEntry {
     fn search_batch(
         &self,
         vector_name: &str,
-        vectors: &[&[VectorElementType]],
+        vectors: &[&QueryVector],
         with_payload: &WithPayload,
         with_vector: &WithVector,
         filter: Option<&Filter>,

commit 67c2a414d67318ff0528e3374e41f96b7d6874fb
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Thu Sep 14 12:37:14 2023 -0300

    Recommendation scorer internals (#2538)
    
    * use enum_dispatch on vector_index_base.rs
    
    * add reco_query_scorer.rs
    
    * smol refactor on reco_query_scorer
    
    * add PositiveNegative variant
    
    * recommend query scorer internals
    
    - missing tests
    
    * add test for RecoQuery
    
    * Revert "use enum_dispatch on vector_index_base.rs"
    
    This reverts commit 016e831d00d67ef01e64b4f7a76854e555cd9697.
    
    * remove enum_dispatch usage
    
    * disable score_internal implementation for QuantizedRecoQueryScorer
    
    * refactor test
    
    * refactor with latest preprocess changes
    
    * add reco scorer for async scorer
    
    * add iter_all() helper for RecoQuery
    
    * rename PositiveNegative -> Recommend,
    change variable names,
    refactor quantized query scorer
    
    * refactor new raw scorer
    
    * add tests for comparison raw against async and u8 quant
    
    * smol test improvements
    
    * fix error after rebase
    
    * fmt
    
    * finish score equivalency test, remove dbgs
    
    * make scorer builder for quantized storage
    
    * move query preprocessing to `new()` of quantized query scorers
    
    * self review
    
    * review suggestions
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 0dee55419..7f761ea27 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -212,7 +212,7 @@ pub trait SegmentEntry {
     fn search(
         &self,
         vector_name: &str,
-        vector: &QueryVector,
+        query_vector: &QueryVector,
         with_payload: &WithPayload,
         with_vector: &WithVector,
         filter: Option<&Filter>,
@@ -225,7 +225,7 @@ pub trait SegmentEntry {
     fn search_batch(
         &self,
         vector_name: &str,
-        vectors: &[&QueryVector],
+        query_vectors: &[&QueryVector],
         with_payload: &WithPayload,
         with_vector: &WithVector,
         filter: Option<&Filter>,

commit b35177d16c36cebe097299bf363f3dcee38531e8
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Sep 21 09:13:19 2023 +0200

    introduce IO common module (#2704)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 7f761ea27..772607f8b 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -6,10 +6,10 @@ use std::result;
 use std::sync::atomic::{AtomicBool, Ordering};
 
 use atomicwrites::Error as AtomicIoError;
+use io::file_operations::FileStorageError;
 use rayon::ThreadPoolBuildError;
 use thiserror::Error;
 
-use crate::common::file_operations::FileStorageError;
 use crate::common::mmap_type::Error as MmapError;
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::vectors::{QueryVector, VectorElementType};

commit 4f983e495db72336b2311dc2abe95a11eab8c620
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Fri Sep 29 16:23:24 2023 +0200

    Promote operation error to dedicated file (#2736)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 772607f8b..d4a0a4dee 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,16 +1,8 @@
-use std::backtrace::Backtrace;
-use std::collections::{HashMap, TryReserveError};
-use std::io::{Error as IoError, ErrorKind};
+use std::collections::HashMap;
 use std::path::{Path, PathBuf};
-use std::result;
-use std::sync::atomic::{AtomicBool, Ordering};
+use std::sync::atomic::AtomicBool;
 
-use atomicwrites::Error as AtomicIoError;
-use io::file_operations::FileStorageError;
-use rayon::ThreadPoolBuildError;
-use thiserror::Error;
-
-use crate::common::mmap_type::Error as MmapError;
+use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::vectors::{QueryVector, VectorElementType};
 use crate::index::field_index::CardinalityEstimation;
@@ -20,182 +12,6 @@ use crate::types::{
     ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, WithPayload,
     WithVector,
 };
-use crate::utils::mem::Mem;
-
-pub const PROCESS_CANCELLED_BY_SERVICE_MESSAGE: &str = "process cancelled by service";
-
-#[derive(Error, Debug, Clone)]
-#[error("{0}")]
-pub enum OperationError {
-    #[error("Vector inserting error: expected dim: {expected_dim}, got {received_dim}")]
-    WrongVector {
-        expected_dim: usize,
-        received_dim: usize,
-    },
-    #[error("Not existing vector name error: {received_name}")]
-    VectorNameNotExists { received_name: String },
-    #[error("Missed vector name error: {received_name}")]
-    MissedVectorName { received_name: String },
-    #[error("No point with id {missed_point_id}")]
-    PointIdError { missed_point_id: PointIdType },
-    #[error("Payload type does not match with previously given for field {field_name}. Expected: {expected_type}")]
-    TypeError {
-        field_name: PayloadKeyType,
-        expected_type: String,
-    },
-    #[error("Unable to infer type for the field '{field_name}'. Please specify `field_type`")]
-    TypeInferenceError { field_name: PayloadKeyType },
-    /// Service Error prevents further update of the collection until it is fixed.
-    /// Should only be used for hardware, data corruption, IO, or other unexpected internal errors.
-    #[error("Service runtime error: {description}")]
-    ServiceError {
-        description: String,
-        backtrace: Option<String>,
-    },
-    #[error("Inconsistent storage: {description}")]
-    InconsistentStorage { description: String },
-    #[error("Out of memory, free: {free}, {description}")]
-    OutOfMemory { description: String, free: u64 },
-    #[error("Operation cancelled: {description}")]
-    Cancelled { description: String },
-}
-
-impl OperationError {
-    pub fn service_error(description: impl Into<String>) -> OperationError {
-        OperationError::ServiceError {
-            description: description.into(),
-            backtrace: Some(Backtrace::force_capture().to_string()),
-        }
-    }
-}
-
-pub fn check_process_stopped(stopped: &AtomicBool) -> OperationResult<()> {
-    if stopped.load(Ordering::Relaxed) {
-        return Err(OperationError::Cancelled {
-            description: PROCESS_CANCELLED_BY_SERVICE_MESSAGE.to_string(),
-        });
-    }
-    Ok(())
-}
-
-/// Contains information regarding last operation error, which should be fixed before next operation could be processed
-#[derive(Debug, Clone)]
-pub struct SegmentFailedState {
-    pub version: SeqNumberType,
-    pub point_id: Option<PointIdType>,
-    pub error: OperationError,
-}
-
-impl From<semver::Error> for OperationError {
-    fn from(error: semver::Error) -> Self {
-        OperationError::ServiceError {
-            description: error.to_string(),
-            backtrace: Some(Backtrace::force_capture().to_string()),
-        }
-    }
-}
-
-impl From<ThreadPoolBuildError> for OperationError {
-    fn from(error: ThreadPoolBuildError) -> Self {
-        OperationError::ServiceError {
-            description: format!("{error}"),
-            backtrace: Some(Backtrace::force_capture().to_string()),
-        }
-    }
-}
-
-impl From<FileStorageError> for OperationError {
-    fn from(err: FileStorageError) -> Self {
-        Self::service_error(err.to_string())
-    }
-}
-
-impl From<MmapError> for OperationError {
-    fn from(err: MmapError) -> Self {
-        Self::service_error(err.to_string())
-    }
-}
-
-impl From<serde_cbor::Error> for OperationError {
-    fn from(err: serde_cbor::Error) -> Self {
-        OperationError::service_error(format!("Failed to parse data: {err}"))
-    }
-}
-
-impl<E> From<AtomicIoError<E>> for OperationError {
-    fn from(err: AtomicIoError<E>) -> Self {
-        match err {
-            AtomicIoError::Internal(io_err) => OperationError::from(io_err),
-            AtomicIoError::User(_user_err) => {
-                OperationError::service_error("Unknown atomic write error")
-            }
-        }
-    }
-}
-
-impl From<IoError> for OperationError {
-    fn from(err: IoError) -> Self {
-        match err.kind() {
-            ErrorKind::OutOfMemory => {
-                let free_memory = Mem::new().available_memory_bytes();
-                OperationError::OutOfMemory {
-                    description: format!("IO Error: {err}"),
-                    free: free_memory,
-                }
-            }
-            _ => OperationError::service_error(format!("IO Error: {err}")),
-        }
-    }
-}
-
-impl From<serde_json::Error> for OperationError {
-    fn from(err: serde_json::Error) -> Self {
-        OperationError::service_error(format!("Json error: {err}"))
-    }
-}
-
-impl From<fs_extra::error::Error> for OperationError {
-    fn from(err: fs_extra::error::Error) -> Self {
-        OperationError::service_error(format!("File system error: {err}"))
-    }
-}
-
-impl From<quantization::EncodingError> for OperationError {
-    fn from(err: quantization::EncodingError) -> Self {
-        match err {
-            quantization::EncodingError::IOError(err)
-            | quantization::EncodingError::EncodingError(err)
-            | quantization::EncodingError::ArgumentsError(err) => {
-                OperationError::service_error(format!("Quantization encoding error: {err}"))
-            }
-            quantization::EncodingError::Stopped => OperationError::Cancelled {
-                description: PROCESS_CANCELLED_BY_SERVICE_MESSAGE.to_string(),
-            },
-        }
-    }
-}
-
-impl From<TryReserveError> for OperationError {
-    fn from(err: TryReserveError) -> Self {
-        let free_memory = Mem::new().available_memory_bytes();
-        OperationError::OutOfMemory {
-            description: format!("Failed to reserve memory: {err}"),
-            free: free_memory,
-        }
-    }
-}
-
-pub type OperationResult<T> = result::Result<T, OperationError>;
-
-pub fn get_service_error<T>(err: &OperationResult<T>) -> Option<OperationError> {
-    match err {
-        Ok(_) => None,
-        Err(error) => match error {
-            OperationError::ServiceError { .. } => Some(error.clone()),
-            _ => None,
-        },
-    }
-}
 
 /// Define all operations which can be performed with Segment or Segment-like entity.
 ///

commit 13f15955fcc5920aab21c3e1d5a2a81794f3e299
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Tue Nov 21 09:18:15 2023 +0100

    Sparse vectors rest search and upsert (#3051)
    
    * sparse vector sparse search and upsert
    
    are you happy fmt
    
    fix build
    
    update openapi
    
    batch changes
    
    update openapi
    
    named sparse vector
    
    * review remarks
    
    * cowvalue to cowvector

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index d4a0a4dee..2526ddac2 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -4,7 +4,7 @@ use std::sync::atomic::AtomicBool;
 
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::named_vectors::NamedVectors;
-use crate::data_types::vectors::{QueryVector, VectorElementType};
+use crate::data_types::vectors::{QueryVector, Vector};
 use crate::index::field_index::CardinalityEstimation;
 use crate::telemetry::SegmentTelemetry;
 use crate::types::{
@@ -104,11 +104,7 @@ pub trait SegmentEntry {
         point_id: PointIdType,
     ) -> OperationResult<bool>;
 
-    fn vector(
-        &self,
-        vector_name: &str,
-        point_id: PointIdType,
-    ) -> OperationResult<Option<Vec<VectorElementType>>>;
+    fn vector(&self, vector_name: &str, point_id: PointIdType) -> OperationResult<Option<Vector>>;
 
     fn all_vectors(&self, point_id: PointIdType) -> OperationResult<NamedVectors>;
 

commit 320b7f2621f08d08fa6fbd1e8f82a277610af81c
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Sun Feb 4 14:46:22 2024 -0300

    `order_by` in scroll (#3493)
    
    * first PR implementation (#2865)
    
    - fetch offset id
    - restructure tests
    - only let order_by with numeric
    - introduce order_by interface
    
    cargo fmt
    
    update openapi
    
    calculate range to fetch using offset + limit, do some cleanup
    
    enable index validation, fix test
    
    Fix pagination
    
    add e2e tests
    
    make test a little more strict
    
    select numeric index on read_ordered_filtered
    
    add filtering test 
    
    fix filtering on order-by
    
    fix pip requirements
    
    add grpc interface, make read_ordered_filtered fallible
    
    fmt
    
    small optimization of `with_payload` and `with_vector`
    
    refactor common logic of point_ops and local_shard_operations
    
    Make filtering test harder and fix limit for worst case
    
    update openapi
    
    small clarity refactor
    
    avoid extra allocation when sorting with offset
    
    stream from numeric index btree instead of calculating range
    
    use payload to store order-by value, instead of modifying Record interface
    
    various fixes:
    - fix ordering at collection level, when merging shard results
    - fix offset at segment level, to take into account also value offset
    - make rust tests pass
    
    remove unused histogram changes
    
    fix error messages and make has_range_index exhaustive
    
    remove unused From impl
    
    Move OrderBy and Direction to segment::data_types::order_by
    
    Refactor normal scroll_by in local_shard_operations.rs
    
    More cleanup + rename OrderableRead to StreamWithValue
    
    empty commit
    
    optimization for merging results from shards and segments
    
    fix case of multi-valued fields
    
    fix IntegerIndexParams name after rebase
    
    precompute offset key
    
    use extracted `read_by_id_stream`
    
    Expose value_offset to user
    - rename offset -> value_offset
    - extract offset value fetching logic
    
    * remove offset functionality when using order_by
    
    * include order_by in ForwardProxyShard
    
    * extra nits
    
    * remove histogram changes
    
    * more nits
    
    * self review
    
    * resolve conflicts after rebase, not enable order-by with datetime index schema
    
    * make grpc start_from value extendable
    
    * gen grpc docs
    
    ---------
    
    Co-authored-by: kwkr <kawka.maciej.93@gmail.com>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 2526ddac2..96ca5b92d 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -2,8 +2,11 @@ use std::collections::HashMap;
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicBool;
 
+use ordered_float::OrderedFloat;
+
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::named_vectors::NamedVectors;
+use crate::data_types::order_by::OrderBy;
 use crate::data_types::vectors::{QueryVector, Vector};
 use crate::index::field_index::CardinalityEstimation;
 use crate::telemetry::SegmentTelemetry;
@@ -121,6 +124,17 @@ pub trait SegmentEntry {
         filter: Option<&'a Filter>,
     ) -> Vec<PointIdType>;
 
+    /// Return points which satisfies filtering condition ordered by the `order_by.key` field,
+    /// starting with `order_by.start_from` value including.
+    ///
+    /// Will fail if there is no index for the order_by key.
+    fn read_ordered_filtered<'a>(
+        &'a self,
+        limit: Option<usize>,
+        filter: Option<&'a Filter>,
+        order_by: &'a OrderBy,
+    ) -> OperationResult<Vec<(OrderedFloat<f64>, PointIdType)>>;
+
     /// Read points in [from; to) range
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;
 

commit ffa27c4fd2900458b6b07b06e799704cb11604ce
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Wed Feb 7 09:54:40 2024 -0300

    Order-by: Introduce `OrderingValue` for ordering also based on int values (#3533)
    
    * introduce `OrderingValue` for ordering also based on int values
    
    * use `num-cmp` for comparing ints and floats
    
    * Update comparison logic
    
    ---------
    
    Co-authored-by: Albert Safin <xzfcpw@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 96ca5b92d..68cce4f51 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -2,11 +2,9 @@ use std::collections::HashMap;
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicBool;
 
-use ordered_float::OrderedFloat;
-
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::named_vectors::NamedVectors;
-use crate::data_types::order_by::OrderBy;
+use crate::data_types::order_by::{OrderBy, OrderingValue};
 use crate::data_types::vectors::{QueryVector, Vector};
 use crate::index::field_index::CardinalityEstimation;
 use crate::telemetry::SegmentTelemetry;
@@ -133,7 +131,7 @@ pub trait SegmentEntry {
         limit: Option<usize>,
         filter: Option<&'a Filter>,
         order_by: &'a OrderBy,
-    ) -> OperationResult<Vec<(OrderedFloat<f64>, PointIdType)>>;
+    ) -> OperationResult<Vec<(OrderingValue, PointIdType)>>;
 
     /// Read points in [from; to) range
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;

commit 87b541bb41560adf4609190cc0a7c1ed1da6e2f3
Author: shylock <tcath2s@gmail.com>
Date:   Thu Feb 15 22:15:05 2024 +0800

    Feat/set payload by key (#3548)
    
    * Support set by key in low level.
    
    * Rename key field.
    
    * Format.
    
    * Pass key.
    
    * Format.
    
    * Test.
    
    * Clippy.
    
    * Fix ci lint.
    
    * Check grpc consistency.
    
    * Update openapi.
    
    * Fix empty key test case.
    
    * Support array index.
    
    * Format.
    
    * Add test for non exists key.
    
    * Clippy fix.
    
    * Add idempotence test.
    
    * Update index by updated payload.
    
    * Add ut for utils.
    
    * Add ut for 1 level key.
    
    * Fix ut.
    
    * Support no exits key.
    
    * Fix test result.
    
    * Fix after rebase
    
    * handle wildcart insertion into non-existing array
    
    * avoid double read of payload during update
    
    * fix missing removing data from index in case if set_payload removes indexed field
    
    ---------
    
    Co-authored-by: Shylock Hg <shylock@DESKTOP-40I855A>
    Co-authored-by: Albert Safin <xzfcpw@gmail.com>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 68cce4f51..b3adef41c 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -83,6 +83,7 @@ pub trait SegmentEntry {
         op_num: SeqNumberType,
         point_id: PointIdType,
         payload: &Payload,
+        key: &Option<String>,
     ) -> OperationResult<bool>;
 
     fn set_full_payload(

commit f80231b954478f9facc5af063d13c91f682fa329
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Tue Feb 20 12:06:20 2024 +0100

    Do not set empty payload when moving points (#3641)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index b3adef41c..9afa5010d 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -110,6 +110,8 @@ pub trait SegmentEntry {
 
     fn all_vectors(&self, point_id: PointIdType) -> OperationResult<NamedVectors>;
 
+    /// Retrieve payload for the point
+    /// If not found, return empty payload
     fn payload(&self, point_id: PointIdType) -> OperationResult<Payload>;
 
     /// Iterator over all points in segment in ascending order.

commit d39a483017d14971051e30be5023dd4e969163b6
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Tue Feb 20 14:55:57 2024 +0000

    Refactor: introduce details level enum (#3612)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 9afa5010d..f5c06a492 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -2,6 +2,8 @@ use std::collections::HashMap;
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicBool;
 
+use common::types::TelemetryDetail;
+
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderingValue};
@@ -217,5 +219,5 @@ pub trait SegmentEntry {
         -> OperationResult<PathBuf>;
 
     // Get collected telemetry data of segment
-    fn get_telemetry_data(&self) -> SegmentTelemetry;
+    fn get_telemetry_data(&self, detail: TelemetryDetail) -> SegmentTelemetry;
 }

commit 3beb4e3b4ff4b3f9585337f4e5b0826a14e247b6
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Fri Feb 23 14:38:40 2024 +0000

    Introduce JsonPathString (#3674)
    
    * Introduce JsonPathString
    
    * Fix fomatting

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index f5c06a492..254b5adca 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -9,6 +9,7 @@ use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderingValue};
 use crate::data_types::vectors::{QueryVector, Vector};
 use crate::index::field_index::CardinalityEstimation;
+use crate::json_path::JsonPath;
 use crate::telemetry::SegmentTelemetry;
 use crate::types::{
     Filter, Payload, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PointIdType,
@@ -85,7 +86,7 @@ pub trait SegmentEntry {
         op_num: SeqNumberType,
         point_id: PointIdType,
         payload: &Payload,
-        key: &Option<String>,
+        key: &Option<JsonPath>,
     ) -> OperationResult<bool>;
 
     fn set_full_payload(

commit e54ab8a636ecbfa3fe70f85fce1058ce655099fb
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Apr 11 13:16:56 2024 +0200

    Fix indexed-only behavior for proxy shard (#3998)
    
    * move check for unindexed segment size inside the segment to allow proxy shard decide where to search better
    
    * fmt
    
    * move indexed_only check inside the plain index

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 254b5adca..8c93a4e23 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -52,6 +52,7 @@ pub trait SegmentEntry {
         top: usize,
         params: Option<&SearchParams>,
         is_stopped: &AtomicBool,
+        search_optimized_threshold_kb: usize,
     ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
 
     fn upsert_point(

commit 01f5c667bc6d0669b16759dacf5e2cf815497809
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Apr 11 22:52:01 2024 +0200

    remove search method from serment trait to simplify usage in tests and prevent accidental usage in release (#3999)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 8c93a4e23..92b1f14f8 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -28,19 +28,6 @@ pub trait SegmentEntry {
     /// Get version of specified point
     fn point_version(&self, point_id: PointIdType) -> Option<SeqNumberType>;
 
-    #[allow(clippy::too_many_arguments)]
-    fn search(
-        &self,
-        vector_name: &str,
-        query_vector: &QueryVector,
-        with_payload: &WithPayload,
-        with_vector: &WithVector,
-        filter: Option<&Filter>,
-        top: usize,
-        params: Option<&SearchParams>,
-        is_stopped: &AtomicBool,
-    ) -> OperationResult<Vec<ScoredPoint>>;
-
     #[allow(clippy::too_many_arguments)]
     fn search_batch(
         &self,

commit 896cfe109d9a6dd5a9a4ab39422899d6d238a5c6
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Apr 29 14:54:14 2024 +0200

    Sparse idf dot (#4126)
    
    * introduce QueryContext, which accumulates runtime info needed for executing search
    
    * fmt
    
    * propagate query context into segment internals
    
    * [WIP] prepare idf stats for search query context
    
    * Split SparseVector and RemmapedSparseVector to guarantee we will not mix them up on the type level
    
    * implement filling of the query context with IDF statistics
    
    * implement re-weighting of the sparse query with idf
    
    * fmt
    
    * update idf param only if explicitly specified (more consistent with diff param update
    
    * replace idf bool with modifier enum, improve further extensibility
    
    * test and fixes
    
    * Update lib/collection/src/operations/types.rs
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    
    * review fixes
    
    * fmt
    
    ---------
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 92b1f14f8..99223c702 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -7,6 +7,7 @@ use common::types::TelemetryDetail;
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderingValue};
+use crate::data_types::query_context::QueryContext;
 use crate::data_types::vectors::{QueryVector, Vector};
 use crate::index::field_index::CardinalityEstimation;
 use crate::json_path::JsonPath;
@@ -39,7 +40,7 @@ pub trait SegmentEntry {
         top: usize,
         params: Option<&SearchParams>,
         is_stopped: &AtomicBool,
-        search_optimized_threshold_kb: usize,
+        query_context: &QueryContext,
     ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
 
     fn upsert_point(
@@ -209,4 +210,6 @@ pub trait SegmentEntry {
 
     // Get collected telemetry data of segment
     fn get_telemetry_data(&self, detail: TelemetryDetail) -> SegmentTelemetry;
+
+    fn fill_query_context(&self, query_context: &mut QueryContext);
 }

commit e663f8aa8710ad6e5f9c22c151617be7ac0ac6be
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon May 6 11:51:50 2024 +0200

    Faster deleted filter in proxy segments (#4148)
    
    * [WIP] introduce internal has-id check
    
    * fmt
    
    * update value of the deleted_mask in proxy
    
    * use deleted_points from the context, if present
    
    * fmt
    
    * move stopped flag into query context
    
    * fmt
    
    * segment-specific query context
    
    * enable custom deleted mask in proxy
    
    * remove unused HasIdConditionInternal
    
    * fix tests
    
    * remove debug

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 99223c702..b93ef55ca 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,13 +1,12 @@
 use std::collections::HashMap;
 use std::path::{Path, PathBuf};
-use std::sync::atomic::AtomicBool;
 
 use common::types::TelemetryDetail;
 
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderingValue};
-use crate::data_types::query_context::QueryContext;
+use crate::data_types::query_context::{QueryContext, SegmentQueryContext};
 use crate::data_types::vectors::{QueryVector, Vector};
 use crate::index::field_index::CardinalityEstimation;
 use crate::json_path::JsonPath;
@@ -39,8 +38,7 @@ pub trait SegmentEntry {
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,
-        is_stopped: &AtomicBool,
-        query_context: &QueryContext,
+        query_context: SegmentQueryContext,
     ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
 
     fn upsert_point(

commit 9d8dd0471621d704f72ffbc3fae62852641207b9
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Wed May 22 09:56:31 2024 -0400

    universal-query: Introduce `order_value` field in `ScoredPoint` (#4291)
    
    * - Fix ordering in group-by for custom scoring
    - Rename `OrderingValue` -> `OrderedValue`
    - Introduce `order_value` field in `ScoredPoint`
    
    * modify `Ord` implementation
    
    * rename to `OrderValue`
    
    * `has_custom_scoring` -> `is_distance_scored`
    
    * regen apis
    
    * flip bools in `is_distance_scored`

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index b93ef55ca..aea81f3f6 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -5,7 +5,7 @@ use common::types::TelemetryDetail;
 
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::named_vectors::NamedVectors;
-use crate::data_types::order_by::{OrderBy, OrderingValue};
+use crate::data_types::order_by::{OrderBy, OrderValue};
 use crate::data_types::query_context::{QueryContext, SegmentQueryContext};
 use crate::data_types::vectors::{QueryVector, Vector};
 use crate::index::field_index::CardinalityEstimation;
@@ -124,7 +124,7 @@ pub trait SegmentEntry {
         limit: Option<usize>,
         filter: Option<&'a Filter>,
         order_by: &'a OrderBy,
-    ) -> OperationResult<Vec<(OrderingValue, PointIdType)>>;
+    ) -> OperationResult<Vec<(OrderValue, PointIdType)>>;
 
     /// Read points in [from; to) range
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;

commit 21a3fb5f38a796f37883017adc993d0322bbca8f
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Tue May 28 16:38:56 2024 +0200

    Use correct vector storage size (#4312)
    
    * use correct vector storage size
    
    * remove dim from segment entry
    
    * are you happy fmt
    
    * codespell and proportions
    
    * remove obsolete comment
    
    * remove `try_vector_dim`
    
    * are you happy fmt
    
    * remove todo
    
    * revert code of conduct
    
    * check div 0
    
    * Simplify a bit with max iterator
    
    * Update lib/segment/src/index/hnsw_index/hnsw.rs
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * are you happy fmt
    
    * Update lib/segment/src/index/plain_payload_index.rs
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * review fix
    
    * set full scan threshold 0 for test
    
    * use u128 also for multivector storages
    
    * fix sparse vector size calculation
    
    * Move size calculation into if-branch
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>
    Co-authored-by: Tim Vise <tim+github@visee.me>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index aea81f3f6..6085821bf 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,4 +1,4 @@
-use std::collections::HashMap;
+use std::collections::{HashMap, HashSet};
 use std::path::{Path, PathBuf};
 
 use common::types::TelemetryDetail;
@@ -135,9 +135,7 @@ pub trait SegmentEntry {
     /// Estimate available point count in this segment for given filter.
     fn estimate_point_count<'a>(&'a self, filter: Option<&'a Filter>) -> CardinalityEstimation;
 
-    fn vector_dim(&self, vector_name: &str) -> OperationResult<usize>;
-
-    fn vector_dims(&self) -> HashMap<String, usize>;
+    fn vector_names(&self) -> HashSet<String>;
 
     /// Number of available points
     ///
@@ -147,6 +145,18 @@ pub trait SegmentEntry {
     /// Number of deleted points
     fn deleted_point_count(&self) -> usize;
 
+    /// Size of all available vectors in storage
+    fn available_vectors_size_in_bytes(&self, vector_name: &str) -> OperationResult<usize>;
+
+    /// Max value from all `available_vectors_size_in_bytes`
+    fn max_available_vectors_size_in_bytes(&self) -> OperationResult<usize> {
+        self.vector_names()
+            .into_iter()
+            .map(|vector_name| self.available_vectors_size_in_bytes(&vector_name))
+            .collect::<OperationResult<Vec<_>>>()
+            .map(|sizes| sizes.into_iter().max().unwrap_or_default())
+    }
+
     /// Get segment type
     fn segment_type(&self) -> SegmentType;
 

commit 40830a1729f176a8691022e47119ad5dce2d1a54
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Mon Jul 8 15:58:19 2024 +0200

    Merge pull request #4620
    
    * Add `force` flag to `SegmentEntry::flush` and `ShardHolder::flush_all

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 6085821bf..b6971b0ec 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -173,7 +173,7 @@ pub trait SegmentEntry {
     /// if sync == true, block current thread while flushing
     ///
     /// Returns maximum version number which is guaranteed to be persisted.
-    fn flush(&self, sync: bool) -> OperationResult<SeqNumberType>;
+    fn flush(&self, sync: bool, force: bool) -> OperationResult<SeqNumberType>;
 
     /// Removes all persisted data and forces to destroy segment
     fn drop_data(self) -> OperationResult<()>;

commit 38f08f77ce51082ddfbb01e5c0153dc1e0fd4c85
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Thu Jul 18 14:07:31 2024 -0400

    random-query: Implement random reads from segments up to local shard (#4619)
    
    * Implement random reads from segments up to local shard
    
    * fix some review comments
    
    - unimplemented for fixture implementation
    - map after chaining
    - kmerge instead of choose_multiple
    
    * add custom filtered_read_by_index_shuffled
    
    * cargo clippy
    
    * grab from each segment depending on availability
    
    * sample in O(limit) (#4680)
    
    * edit comment
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index b6971b0ec..ae0337884 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -126,6 +126,8 @@ pub trait SegmentEntry {
         order_by: &'a OrderBy,
     ) -> OperationResult<Vec<(OrderValue, PointIdType)>>;
 
+    fn read_random_filtered(&self, limit: usize, filter: Option<&Filter>) -> Vec<PointIdType>;
+
     /// Read points in [from; to) range
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;
 

commit eb679ff097c79aba3f11b0f0b01d307d2e163d0c
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Tue Jul 30 13:18:19 2024 -0400

    Facets in segment (#4753)
    
    * faceting in segment
    
    * Add segment integration test
    
    * nits
    
    * count from filtered stream, not value->points map directly
    
    * drop AtomicRef from fn signature
    
    * count only unique values per point
    
    * use entry in hashmap
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index ae0337884..c4179bcaf 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -4,6 +4,7 @@ use std::path::{Path, PathBuf};
 use common::types::TelemetryDetail;
 
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
+use crate::data_types::facets::{FacetHit, FacetRequest, FacetValue};
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderValue};
 use crate::data_types::query_context::{QueryContext, SegmentQueryContext};
@@ -131,6 +132,9 @@ pub trait SegmentEntry {
     /// Read points in [from; to) range
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;
 
+    /// Return the largest counts for the given facet request.
+    fn facet(&self, request: &FacetRequest) -> OperationResult<Vec<FacetHit<FacetValue>>>;
+
     /// Check if there is point with `point_id` in this segment.
     fn has_point(&self, point_id: PointIdType) -> bool;
 

commit 12c5d6b6b606cd5559a6452ef39d802039d02dd6
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Fri Aug 2 12:57:20 2024 -0400

    Support timeout in Facets (#4792)
    
    * nits in segments_searcher
    
    * implement timeout into segment faceting
    
    * Add timeout to internal service api
    
    * refactor iterator_ext, and add test

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index c4179bcaf..dfd13885b 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,5 +1,6 @@
 use std::collections::{HashMap, HashSet};
 use std::path::{Path, PathBuf};
+use std::sync::atomic::AtomicBool;
 
 use common::types::TelemetryDetail;
 
@@ -133,7 +134,11 @@ pub trait SegmentEntry {
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;
 
     /// Return the largest counts for the given facet request.
-    fn facet(&self, request: &FacetRequest) -> OperationResult<Vec<FacetHit<FacetValue>>>;
+    fn facet(
+        &self,
+        request: &FacetRequest,
+        is_stopped: &AtomicBool,
+    ) -> OperationResult<Vec<FacetHit<FacetValue>>>;
 
     /// Check if there is point with `point_id` in this segment.
     fn has_point(&self, point_id: PointIdType) -> bool;

commit 10b05c3ed84024f4aeaad5e97e24bd0b0ec421d2
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Aug 5 19:05:45 2024 +0200

    Make scroll cancellable (#4827)
    
    * Make scroll cancellable
    
    * comments and fix
    
    * better comment

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index dfd13885b..0bcbd1867 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -110,25 +110,38 @@ pub trait SegmentEntry {
     fn iter_points(&self) -> Box<dyn Iterator<Item = PointIdType> + '_>;
 
     /// Paginate over points which satisfies filtering condition starting with `offset` id including.
+    ///
+    /// Cancelled by `is_stopped` flag.
     fn read_filtered<'a>(
         &'a self,
         offset: Option<PointIdType>,
         limit: Option<usize>,
         filter: Option<&'a Filter>,
+        is_stopped: &AtomicBool,
     ) -> Vec<PointIdType>;
 
     /// Return points which satisfies filtering condition ordered by the `order_by.key` field,
     /// starting with `order_by.start_from` value including.
     ///
     /// Will fail if there is no index for the order_by key.
+    /// Cancelled by `is_stopped` flag.
     fn read_ordered_filtered<'a>(
         &'a self,
         limit: Option<usize>,
         filter: Option<&'a Filter>,
         order_by: &'a OrderBy,
+        is_stopped: &AtomicBool,
     ) -> OperationResult<Vec<(OrderValue, PointIdType)>>;
 
-    fn read_random_filtered(&self, limit: usize, filter: Option<&Filter>) -> Vec<PointIdType>;
+    /// Return random points which satisfies filtering condition.
+    ///
+    /// Cancelled by `is_stopped` flag.
+    fn read_random_filtered(
+        &self,
+        limit: usize,
+        filter: Option<&Filter>,
+        is_stopped: &AtomicBool,
+    ) -> Vec<PointIdType>;
 
     /// Read points in [from; to) range
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;

commit ace8a90259561eb483a4ffefa1ab28d65ad1e1a5
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Mon Aug 19 16:03:26 2024 -0400

    Facets in REST (#4848)
    
    * rename to FacetRequestInternal
    
    * add rest endpoint
    
    * fix correctness by fetching the whole list of values
    
    * fix mmap map index variant
    
    Also removes test for sorted output, for now
    
    * add ytt spec
    
    * fix clippy
    
    * use hashmap inside of local shard
    
    * rename operation to `facet`, add access test
    
    * whitelist endpoint
    
    * change api
    
    * make limit optional

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 0bcbd1867..ba3ea47b4 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -5,7 +5,7 @@ use std::sync::atomic::AtomicBool;
 use common::types::TelemetryDetail;
 
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
-use crate::data_types::facets::{FacetHit, FacetRequest, FacetValue};
+use crate::data_types::facets::{FacetParams, FacetValue};
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderValue};
 use crate::data_types::query_context::{QueryContext, SegmentQueryContext};
@@ -149,9 +149,9 @@ pub trait SegmentEntry {
     /// Return the largest counts for the given facet request.
     fn facet(
         &self,
-        request: &FacetRequest,
+        request: &FacetParams,
         is_stopped: &AtomicBool,
-    ) -> OperationResult<Vec<FacetHit<FacetValue>>>;
+    ) -> OperationResult<HashMap<FacetValue, usize>>;
 
     /// Check if there is point with `point_id` in this segment.
     fn has_point(&self, point_id: PointIdType) -> bool;

commit 3185dd23c50f02e8f38c10839ff622fc2bd3a072
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Mon Aug 19 23:21:17 2024 -0400

    Exact facet mode (#4878)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index ba3ea47b4..18512bfc9 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,4 +1,4 @@
-use std::collections::{HashMap, HashSet};
+use std::collections::{BTreeSet, HashMap, HashSet};
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicBool;
 
@@ -146,6 +146,14 @@ pub trait SegmentEntry {
     /// Read points in [from; to) range
     fn read_range(&self, from: Option<PointIdType>, to: Option<PointIdType>) -> Vec<PointIdType>;
 
+    /// Return all unique values for the given key.
+    fn unique_values(
+        &self,
+        key: &JsonPath,
+        filter: Option<&Filter>,
+        is_stopped: &AtomicBool,
+    ) -> OperationResult<BTreeSet<FacetValue>>;
+
     /// Return the largest counts for the given facet request.
     fn facet(
         &self,

commit 96158c6f27c8a5d4366ecb88118f1808a6dd642f
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Fri Aug 23 08:30:45 2024 -0400

    fix: Non-blocking payload index building (#4941)
    
    * separate index creation into build and apply
    
    * check version in Segment impl of `build_field_index`
    
    * add wait to issues test
    
    * fix consensus tests

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 18512bfc9..7e310271f 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -10,7 +10,7 @@ use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderValue};
 use crate::data_types::query_context::{QueryContext, SegmentQueryContext};
 use crate::data_types::vectors::{QueryVector, Vector};
-use crate::index::field_index::CardinalityEstimation;
+use crate::index::field_index::{CardinalityEstimation, FieldIndex};
 use crate::json_path::JsonPath;
 use crate::telemetry::SegmentTelemetry;
 use crate::types::{
@@ -220,13 +220,36 @@ pub trait SegmentEntry {
         key: PayloadKeyTypeRef,
     ) -> OperationResult<bool>;
 
+    /// Build the field index for the key and schema, if not built before.
+    fn build_field_index(
+        &self,
+        op_num: SeqNumberType,
+        key: PayloadKeyTypeRef,
+        field_type: Option<&PayloadFieldSchema>,
+    ) -> OperationResult<Option<(PayloadFieldSchema, Vec<FieldIndex>)>>;
+
+    /// Apply a built index. Returns whether it was actually applied or not.
+    fn apply_field_index(
+        &mut self,
+        op_num: SeqNumberType,
+        key: PayloadKeyType,
+        field_schema: PayloadFieldSchema,
+        field_index: Vec<FieldIndex>,
+    ) -> OperationResult<bool>;
+
     /// Create index for a payload field, if not exists
     fn create_field_index(
         &mut self,
         op_num: SeqNumberType,
         key: PayloadKeyTypeRef,
         field_schema: Option<&PayloadFieldSchema>,
-    ) -> OperationResult<bool>;
+    ) -> OperationResult<bool> {
+        let Some((schema, index)) = self.build_field_index(op_num, key, field_schema)? else {
+            return Ok(false);
+        };
+
+        self.apply_field_index(op_num, key.to_owned(), schema, index)
+    }
 
     /// Get indexed fields
     fn get_indexed_fields(&self) -> HashMap<PayloadKeyType, PayloadFieldSchema>;

commit 2a6ab9d4fb6d17f35d58a5ff6a4f1e92b2defd83
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Thu Sep 12 19:39:15 2024 +0000

    Direct snapshot creation (#5061)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 7e310271f..71dc81ffb 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -2,6 +2,7 @@ use std::collections::{BTreeSet, HashMap, HashSet};
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicBool;
 
+use common::tar_ext;
 use common::types::TelemetryDetail;
 
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
@@ -268,8 +269,13 @@ pub trait SegmentEntry {
     ///
     /// Creates a tar archive of the segment directory into `snapshot_dir_path`.
     /// Uses `temp_path` to prepare files to archive.
-    fn take_snapshot(&self, temp_path: &Path, snapshot_dir_path: &Path)
-        -> OperationResult<PathBuf>;
+    /// The `snapshotted_segments` set is used to avoid writing the same snapshot twice.
+    fn take_snapshot(
+        &self,
+        temp_path: &Path,
+        tar: &tar_ext::BuilderExt,
+        snapshotted_segments: &mut HashSet<String>,
+    ) -> OperationResult<()>;
 
     // Get collected telemetry data of segment
     fn get_telemetry_data(&self, detail: TelemetryDetail) -> SegmentTelemetry;

commit a50a248fd07ebeb2978ad28813bb90ca23be2bb3
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Fri Oct 4 16:09:30 2024 +0000

    Introduce SnapshotFormat (#5175)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 71dc81ffb..a2752d614 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -16,8 +16,8 @@ use crate::json_path::JsonPath;
 use crate::telemetry::SegmentTelemetry;
 use crate::types::{
     Filter, Payload, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PointIdType,
-    ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, WithPayload,
-    WithVector,
+    ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
+    SnapshotFormat, WithPayload, WithVector,
 };
 
 /// Define all operations which can be performed with Segment or Segment-like entity.
@@ -274,6 +274,7 @@ pub trait SegmentEntry {
         &self,
         temp_path: &Path,
         tar: &tar_ext::BuilderExt,
+        format: SnapshotFormat,
         snapshotted_segments: &mut HashSet<String>,
     ) -> OperationResult<()>;
 

commit 1d0ee7ea32043598f8b240e6a3a52be20663fa44
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Oct 9 10:15:46 2024 +0200

    Inference interface in REST and gRPC (#5165)
    
    * include document & image objects into grpc API
    
    * introduce image and object to rest api
    
    * minor refactoring
    
    * rename Vector -> VectorInternal
    
    * decompose vector data structures
    
    * add schema
    
    * fmt
    
    * grpc docs
    
    * fix conversion
    
    * fix clippy
    
    * fix another conversion
    
    * rename VectorInput -> VectorInputInternal
    
    * replace grpc TryFrom with async functions
    
    * fmt
    
    * replace rest TryFrom with async functions
    
    * add image and object into query rest
    
    * separate inference related conversions
    
    * move json-related conversions into a separate file
    
    * move vector-related transformations into a separate file
    
    * move more vector related-conversions into dedicated module

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index a2752d614..7c35c4dca 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -10,7 +10,7 @@ use crate::data_types::facets::{FacetParams, FacetValue};
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderValue};
 use crate::data_types::query_context::{QueryContext, SegmentQueryContext};
-use crate::data_types::vectors::{QueryVector, Vector};
+use crate::data_types::vectors::{QueryVector, VectorInternal};
 use crate::index::field_index::{CardinalityEstimation, FieldIndex};
 use crate::json_path::JsonPath;
 use crate::telemetry::SegmentTelemetry;
@@ -99,7 +99,11 @@ pub trait SegmentEntry {
         point_id: PointIdType,
     ) -> OperationResult<bool>;
 
-    fn vector(&self, vector_name: &str, point_id: PointIdType) -> OperationResult<Option<Vector>>;
+    fn vector(
+        &self,
+        vector_name: &str,
+        point_id: PointIdType,
+    ) -> OperationResult<Option<VectorInternal>>;
 
     fn all_vectors(&self, point_id: PointIdType) -> OperationResult<NamedVectors>;
 

commit dafe172c4928c7487fc31f88171d27bad42d7147
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Thu Oct 17 16:24:13 2024 +0200

    Add HardwareCounterCell + CPU measurement for sparse vector search (#5239)
    
    * Add HardwareCounterCell and counting for sparse plain search
    
    * Add measurement for indexed sparse vector
    
    * add tests for calculations
    
    * move SegmentQueryContent higher in the call stack
    
    * move hardware counters inside the query context
    
    * fix clippy
    
    * Fix applying hardware measurements and add test for this
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 7c35c4dca..3ab11c995 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -41,7 +41,7 @@ pub trait SegmentEntry {
         filter: Option<&Filter>,
         top: usize,
         params: Option<&SearchParams>,
-        query_context: SegmentQueryContext,
+        query_context: &SegmentQueryContext,
     ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
 
     fn upsert_point(

commit a11f6ae05d160b045d7a9dda567af0fc582cffb6
Author: Tim Vise <tim+github@visee.me>
Date:   Fri Nov 29 16:37:59 2024 +0100

    Keep temporary segment if not empty (#5550)
    
    * Keep temporary segment if not empty
    
    * Fix is empty condition
    
    * Swap condition because it's cheaper
    
    * Keep segment if no appendable segment or if not empty

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 3ab11c995..62c908d90 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -174,6 +174,15 @@ pub trait SegmentEntry {
 
     fn vector_names(&self) -> HashSet<String>;
 
+    /// Whether this segment is completely empty in terms of points
+    ///
+    /// The segment is considered to not be empty if it contains any points, even if deleted.
+    /// Deleted points still have a version which may be important at time of recovery. Deciding
+    /// this by just the reported point count is not reliable in case a proxy segment is used.
+    ///
+    /// Payload indices or type of storage are not considered here.
+    fn is_empty(&self) -> bool;
+
     /// Number of available points
     ///
     /// - excludes soft deleted points

commit 0702854477ae7b23f3f50d94ea9a4cac167bd612
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Thu Dec 5 17:28:09 2024 +0100

    Strict mode max collection vector size (#5501)
    
    * Strict mode config: Max collection size
    
    * api specs
    
    * Add tests + set/update payload check
    
    * Improve function names and add comments
    
    * rename config to separate vectors and payload
    
    * fix tests
    
    * Adjust configs docs
    
    * add benchmark
    
    * improve performance by caching shard info
    
    * add bench for size_info() and fix tests
    
    * Also limit the batch-size for vector updates (#5508)
    
    * Also limit the batch-size for vector updates
    
    * clippy
    
    * add lost commit
    
    * Load cache on collection initialization
    
    * add unit type to parameter name
    
    * fix renaming in test
    
    * clearer error message
    
    * fix test
    
    * review remarks
    
    * remove unused function for now
    
    ---------
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 62c908d90..53756ba54 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -209,6 +209,10 @@ pub trait SegmentEntry {
     /// Get current stats of the segment
     fn info(&self) -> SegmentInfo;
 
+    /// Get size related stats of the segment.
+    /// This returns `SegmentInfo` with some non size-related data (like `schema`) unset to improve performance.
+    fn size_info(&self) -> SegmentInfo;
+
     /// Get segment configuration
     fn config(&self) -> &SegmentConfig;
 

commit 38f478ddf7a9d03a1c783c5599f3b6ae33a05195
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Thu Jan 16 14:25:55 2025 +0100

    Measure payload read IO (#5773)
    
    * Measure read io for payload storage
    
    * Add Hardware Counter to update functions
    
    * Fix tests and benches
    
    * Rename (some) *_measured functions back to original

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 53756ba54..ab9045f85 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -2,6 +2,7 @@ use std::collections::{BTreeSet, HashMap, HashSet};
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicBool;
 
+use common::counter::hardware_counter::HardwareCounterCell;
 use common::tar_ext;
 use common::types::TelemetryDetail;
 
@@ -49,12 +50,14 @@ pub trait SegmentEntry {
         op_num: SeqNumberType,
         point_id: PointIdType,
         vectors: NamedVectors,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn delete_point(
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn update_vectors(
@@ -62,6 +65,7 @@ pub trait SegmentEntry {
         op_num: SeqNumberType,
         point_id: PointIdType,
         vectors: NamedVectors,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn delete_vector(
@@ -69,6 +73,7 @@ pub trait SegmentEntry {
         op_num: SeqNumberType,
         point_id: PointIdType,
         vector_name: &str,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn set_payload(
@@ -77,6 +82,7 @@ pub trait SegmentEntry {
         point_id: PointIdType,
         payload: &Payload,
         key: &Option<JsonPath>,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn set_full_payload(
@@ -84,6 +90,7 @@ pub trait SegmentEntry {
         op_num: SeqNumberType,
         point_id: PointIdType,
         full_payload: &Payload,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn delete_payload(
@@ -91,12 +98,14 @@ pub trait SegmentEntry {
         op_num: SeqNumberType,
         point_id: PointIdType,
         key: PayloadKeyTypeRef,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn clear_payload(
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn vector(
@@ -109,7 +118,11 @@ pub trait SegmentEntry {
 
     /// Retrieve payload for the point
     /// If not found, return empty payload
-    fn payload(&self, point_id: PointIdType) -> OperationResult<Payload>;
+    fn payload(
+        &self,
+        point_id: PointIdType,
+        hw_counter: &HardwareCounterCell,
+    ) -> OperationResult<Payload>;
 
     /// Iterator over all points in segment in ascending order.
     fn iter_points(&self) -> Box<dyn Iterator<Item = PointIdType> + '_>;
@@ -280,6 +293,7 @@ pub trait SegmentEntry {
         &'a mut self,
         op_num: SeqNumberType,
         filter: &'a Filter,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<usize>;
 
     /// Take a snapshot of the segment.

commit e85a9f18b4f5219799c3625c2d3d19c5b3be4ed5
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Fri Jan 24 01:29:01 2025 +0000

    Add `VectorName` type alias (#5763)
    
    * Add VectorName/VectorNameBuf type aliases [1/2]
    
    * Add VectorName/VectorNameBuf type aliases [2/2]

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index ab9045f85..8d1fc4d79 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -18,7 +18,7 @@ use crate::telemetry::SegmentTelemetry;
 use crate::types::{
     Filter, Payload, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PointIdType,
     ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
-    SnapshotFormat, WithPayload, WithVector,
+    SnapshotFormat, VectorName, VectorNameBuf, WithPayload, WithVector,
 };
 
 /// Define all operations which can be performed with Segment or Segment-like entity.
@@ -35,7 +35,7 @@ pub trait SegmentEntry {
     #[allow(clippy::too_many_arguments)]
     fn search_batch(
         &self,
-        vector_name: &str,
+        vector_name: &VectorName,
         query_vectors: &[&QueryVector],
         with_payload: &WithPayload,
         with_vector: &WithVector,
@@ -72,7 +72,7 @@ pub trait SegmentEntry {
         &mut self,
         op_num: SeqNumberType,
         point_id: PointIdType,
-        vector_name: &str,
+        vector_name: &VectorName,
         hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
@@ -110,7 +110,7 @@ pub trait SegmentEntry {
 
     fn vector(
         &self,
-        vector_name: &str,
+        vector_name: &VectorName,
         point_id: PointIdType,
     ) -> OperationResult<Option<VectorInternal>>;
 
@@ -185,7 +185,7 @@ pub trait SegmentEntry {
     /// Estimate available point count in this segment for given filter.
     fn estimate_point_count<'a>(&'a self, filter: Option<&'a Filter>) -> CardinalityEstimation;
 
-    fn vector_names(&self) -> HashSet<String>;
+    fn vector_names(&self) -> HashSet<VectorNameBuf>;
 
     /// Whether this segment is completely empty in terms of points
     ///
@@ -205,7 +205,7 @@ pub trait SegmentEntry {
     fn deleted_point_count(&self) -> usize;
 
     /// Size of all available vectors in storage
-    fn available_vectors_size_in_bytes(&self, vector_name: &str) -> OperationResult<usize>;
+    fn available_vectors_size_in_bytes(&self, vector_name: &VectorName) -> OperationResult<usize>;
 
     /// Max value from all `available_vectors_size_in_bytes`
     fn max_available_vectors_size_in_bytes(&self) -> OperationResult<usize> {

commit 97743b1b625d42f73955ecb32d54ca34ea3a5cb7
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Fri Jan 24 16:33:44 2025 +0100

    Propagate hardware counter for more functions (#5844)
    
    * Propagate hardware counter for more functions
    
    * Minor improvements
    
    * use vector_query_contexts hardware_counter

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 8d1fc4d79..0896738d4 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -136,6 +136,7 @@ pub trait SegmentEntry {
         limit: Option<usize>,
         filter: Option<&'a Filter>,
         is_stopped: &AtomicBool,
+        hw_counter: &HardwareCounterCell,
     ) -> Vec<PointIdType>;
 
     /// Return points which satisfies filtering condition ordered by the `order_by.key` field,
@@ -149,6 +150,7 @@ pub trait SegmentEntry {
         filter: Option<&'a Filter>,
         order_by: &'a OrderBy,
         is_stopped: &AtomicBool,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<Vec<(OrderValue, PointIdType)>>;
 
     /// Return random points which satisfies filtering condition.
@@ -159,6 +161,7 @@ pub trait SegmentEntry {
         limit: usize,
         filter: Option<&Filter>,
         is_stopped: &AtomicBool,
+        hw_counter: &HardwareCounterCell,
     ) -> Vec<PointIdType>;
 
     /// Read points in [from; to) range
@@ -170,6 +173,7 @@ pub trait SegmentEntry {
         key: &JsonPath,
         filter: Option<&Filter>,
         is_stopped: &AtomicBool,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<BTreeSet<FacetValue>>;
 
     /// Return the largest counts for the given facet request.
@@ -177,6 +181,7 @@ pub trait SegmentEntry {
         &self,
         request: &FacetParams,
         is_stopped: &AtomicBool,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<HashMap<FacetValue, usize>>;
 
     /// Check if there is point with `point_id` in this segment.

commit 9b6086389d2811d3f156847a0e690b43a10f51ae
Author: Tim Vise <tim+github@visee.me>
Date:   Mon Feb 10 19:07:55 2025 +0100

    In ID tracker fixture, exclude deleted points (#5961)
    
    * In ID tracker fixture, exclude deleted points
    
    * Update docs

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 0896738d4..f751ea925 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -185,6 +185,8 @@ pub trait SegmentEntry {
     ) -> OperationResult<HashMap<FacetValue, usize>>;
 
     /// Check if there is point with `point_id` in this segment.
+    ///
+    /// Soft deleted points are excluded.
     fn has_point(&self, point_id: PointIdType) -> bool;
 
     /// Estimate available point count in this segment for given filter.

commit 4a26134bec2cfe048c0efea004b5fddc3e086dbe
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Tue Feb 18 11:08:17 2025 +0100

    Prototype partial segment snapshots and `SegmentManifest` format (#5928)
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index f751ea925..4db62a5c9 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -12,6 +12,7 @@ use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderValue};
 use crate::data_types::query_context::{QueryContext, SegmentQueryContext};
 use crate::data_types::vectors::{QueryVector, VectorInternal};
+use crate::entry::partial_snapshot_entry::PartialSnapshotEntry;
 use crate::index::field_index::{CardinalityEstimation, FieldIndex};
 use crate::json_path::JsonPath;
 use crate::telemetry::SegmentTelemetry;
@@ -25,7 +26,7 @@ use crate::types::{
 ///
 /// Assume all operations are idempotent - which means that no matter how many times an operation
 /// is executed - the storage state will be the same.
-pub trait SegmentEntry {
+pub trait SegmentEntry: PartialSnapshotEntry {
     /// Get current update version of the segment
     fn version(&self) -> SeqNumberType;
 

commit 2cab5192f7c546986f609057d40010418686c1bd
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Wed Feb 19 13:16:02 2025 -0300

    [score boosting] handle rescoring up to local shard (#6019)
    
    * handle rescoring up to local shard
    
    * use heap to keep only best points
    
    * add stopping flag
    
    * handle wrapped segment deletions
    
    * drop ordering, assume always LargeBetter
    
    * use ahash for u32 keys
    
    * micro optimization on update_point_versions
    
    * use Option instead of Vec for error
    
    * clarify comment

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 4db62a5c9..d13f60126 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,7 +1,9 @@
 use std::collections::{BTreeSet, HashMap, HashSet};
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicBool;
+use std::sync::Arc;
 
+use bitvec::slice::BitSlice;
 use common::counter::hardware_counter::HardwareCounterCell;
 use common::tar_ext;
 use common::types::TelemetryDetail;
@@ -10,7 +12,7 @@ use crate::common::operation_error::{OperationResult, SegmentFailedState};
 use crate::data_types::facets::{FacetParams, FacetValue};
 use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderValue};
-use crate::data_types::query_context::{QueryContext, SegmentQueryContext};
+use crate::data_types::query_context::{FormulaContext, QueryContext, SegmentQueryContext};
 use crate::data_types::vectors::{QueryVector, VectorInternal};
 use crate::entry::partial_snapshot_entry::PartialSnapshotEntry;
 use crate::index::field_index::{CardinalityEstimation, FieldIndex};
@@ -46,6 +48,16 @@ pub trait SegmentEntry: PartialSnapshotEntry {
         query_context: &SegmentQueryContext,
     ) -> OperationResult<Vec<Vec<ScoredPoint>>>;
 
+    /// Rescore results with a formula that can reference payload values.
+    ///
+    /// A deleted bitslice is passed to exclude points from a wrapped segment.
+    fn rescore_with_formula(
+        &self,
+        formula_ctx: Arc<FormulaContext>,
+        wrapped_deleted: Option<&BitSlice>,
+        hw_counter: &HardwareCounterCell,
+    ) -> OperationResult<Vec<ScoredPoint>>;
+
     fn upsert_point(
         &mut self,
         op_num: SeqNumberType,

commit 8ad2b34265448ec01b89d4093de5fbb1a86dcd4d
Author: Tim Vise <tim+github@visee.me>
Date:   Tue Feb 25 11:21:25 2025 +0100

    Bump Rust edition to 2024 (#6042)
    
    * Bump Rust edition to 2024
    
    * gen is a reserved keyword now
    
    * Remove ref mut on references
    
    * Mark extern C as unsafe
    
    * Wrap unsafe function bodies in unsafe block
    
    * Geo hash implements Copy, don't reference but pass by value instead
    
    * Replace secluded self import with parent
    
    * Update execute_cluster_read_operation with new match semantics
    
    * Fix lifetime issue
    
    * Replace map_or with is_none_or
    
    * set_var is unsafe now
    
    * Reformat

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index d13f60126..f24548361 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,7 +1,7 @@
 use std::collections::{BTreeSet, HashMap, HashSet};
 use std::path::{Path, PathBuf};
-use std::sync::atomic::AtomicBool;
 use std::sync::Arc;
+use std::sync::atomic::AtomicBool;
 
 use bitvec::slice::BitSlice;
 use common::counter::hardware_counter::HardwareCounterCell;

commit 56a7cfdb205f90df28d2816d9e8ef6251fc517a2
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Fri Mar 14 11:05:38 2025 +0100

    Cardinality estimation IO measurements (#6117)
    
    * Cardinality estimation measurements
    
    * Apply hw measurements to latest changes from dev
    
    * Clippy
    
    * Also measure cardinality estimation for geo index
    
    * Make measured units 'bytes'
    
    * Use PointOffsetType instead of u32 for size calculation
    
    * fix memory cost for check_values_any in mmap index
    
    * fix double counting for value reading in mmap, remove hw_counter from mmap hashmap
    
    * fmt
    
    * fix hw measurement for text index
    
    * Remove non necessary lifetime annotations
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index f24548361..3ac2ec5a0 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -203,7 +203,11 @@ pub trait SegmentEntry: PartialSnapshotEntry {
     fn has_point(&self, point_id: PointIdType) -> bool;
 
     /// Estimate available point count in this segment for given filter.
-    fn estimate_point_count<'a>(&'a self, filter: Option<&'a Filter>) -> CardinalityEstimation;
+    fn estimate_point_count<'a>(
+        &'a self,
+        filter: Option<&'a Filter>,
+        hw_counter: &HardwareCounterCell,
+    ) -> CardinalityEstimation;
 
     fn vector_names(&self) -> HashSet<VectorNameBuf>;
 

commit d289a92a5540945e48aff2eb580b6c64adbfd28a
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Mon Mar 17 09:27:31 2025 -0300

    [score boosting] fix proxy segment leakage (#6170)
    
    * remove deleted bitslice from rescore_with_formula signature
    
    * dont allocate unnecessary ahash
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 3ac2ec5a0..9634994f7 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -3,7 +3,6 @@ use std::path::{Path, PathBuf};
 use std::sync::Arc;
 use std::sync::atomic::AtomicBool;
 
-use bitvec::slice::BitSlice;
 use common::counter::hardware_counter::HardwareCounterCell;
 use common::tar_ext;
 use common::types::TelemetryDetail;
@@ -54,7 +53,6 @@ pub trait SegmentEntry: PartialSnapshotEntry {
     fn rescore_with_formula(
         &self,
         formula_ctx: Arc<FormulaContext>,
-        wrapped_deleted: Option<&BitSlice>,
         hw_counter: &HardwareCounterCell,
     ) -> OperationResult<Vec<ScoredPoint>>;
 

commit 5cd7239b61d1a6944984132283f762850275670f
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Mon Mar 24 19:39:17 2025 +0100

    Measure Payload Index IO Writes (#6137)
    
    * Prepare measurement of index creation + Remove vector deletion
    measurement
    
    * add hw_counter to add_point functions
    
    * Adjust add_point(..) function signatures
    
    * Add new measurement type: payload index IO write
    
    * Measure payload index IO writes
    
    * Some Hw measurement performance improvements
    
    * Review remarks
    
    * Fix measurements in distributed setups
    
    * review fixes
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index 9634994f7..b89e3dd8d 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -84,7 +84,6 @@ pub trait SegmentEntry: PartialSnapshotEntry {
         op_num: SeqNumberType,
         point_id: PointIdType,
         vector_name: &VectorName,
-        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool>;
 
     fn set_payload(
@@ -279,6 +278,7 @@ pub trait SegmentEntry: PartialSnapshotEntry {
         op_num: SeqNumberType,
         key: PayloadKeyTypeRef,
         field_type: Option<&PayloadFieldSchema>,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<Option<(PayloadFieldSchema, Vec<FieldIndex>)>>;
 
     /// Apply a built index. Returns whether it was actually applied or not.
@@ -296,8 +296,11 @@ pub trait SegmentEntry: PartialSnapshotEntry {
         op_num: SeqNumberType,
         key: PayloadKeyTypeRef,
         field_schema: Option<&PayloadFieldSchema>,
+        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<bool> {
-        let Some((schema, index)) = self.build_field_index(op_num, key, field_schema)? else {
+        let Some((schema, index)) =
+            self.build_field_index(op_num, key, field_schema, hw_counter)?
+        else {
             return Ok(false);
         };
 

commit f9cc4e06f43194783a6093ec00f0d61366887e07
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Wed Mar 26 16:46:12 2025 +0100

    Merge `take_snapshot` and `take_partial_snapshot` methods (#6232)

diff --git a/lib/segment/src/entry/entry_point.rs b/lib/segment/src/entry/entry_point.rs
index b89e3dd8d..ec127b3be 100644
--- a/lib/segment/src/entry/entry_point.rs
+++ b/lib/segment/src/entry/entry_point.rs
@@ -1,10 +1,9 @@
 use std::collections::{BTreeSet, HashMap, HashSet};
-use std::path::{Path, PathBuf};
+use std::path::PathBuf;
 use std::sync::Arc;
 use std::sync::atomic::AtomicBool;
 
 use common::counter::hardware_counter::HardwareCounterCell;
-use common::tar_ext;
 use common::types::TelemetryDetail;
 
 use crate::common::operation_error::{OperationResult, SegmentFailedState};
@@ -13,21 +12,21 @@ use crate::data_types::named_vectors::NamedVectors;
 use crate::data_types::order_by::{OrderBy, OrderValue};
 use crate::data_types::query_context::{FormulaContext, QueryContext, SegmentQueryContext};
 use crate::data_types::vectors::{QueryVector, VectorInternal};
-use crate::entry::partial_snapshot_entry::PartialSnapshotEntry;
+use crate::entry::snapshot_entry::SnapshotEntry;
 use crate::index::field_index::{CardinalityEstimation, FieldIndex};
 use crate::json_path::JsonPath;
 use crate::telemetry::SegmentTelemetry;
 use crate::types::{
     Filter, Payload, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PointIdType,
-    ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType,
-    SnapshotFormat, VectorName, VectorNameBuf, WithPayload, WithVector,
+    ScoredPoint, SearchParams, SegmentConfig, SegmentInfo, SegmentType, SeqNumberType, VectorName,
+    VectorNameBuf, WithPayload, WithVector,
 };
 
 /// Define all operations which can be performed with Segment or Segment-like entity.
 ///
 /// Assume all operations are idempotent - which means that no matter how many times an operation
 /// is executed - the storage state will be the same.
-pub trait SegmentEntry: PartialSnapshotEntry {
+pub trait SegmentEntry: SnapshotEntry {
     /// Get current update version of the segment
     fn version(&self) -> SeqNumberType;
 
@@ -321,19 +320,6 @@ pub trait SegmentEntry: PartialSnapshotEntry {
         hw_counter: &HardwareCounterCell,
     ) -> OperationResult<usize>;
 
-    /// Take a snapshot of the segment.
-    ///
-    /// Creates a tar archive of the segment directory into `snapshot_dir_path`.
-    /// Uses `temp_path` to prepare files to archive.
-    /// The `snapshotted_segments` set is used to avoid writing the same snapshot twice.
-    fn take_snapshot(
-        &self,
-        temp_path: &Path,
-        tar: &tar_ext::BuilderExt,
-        format: SnapshotFormat,
-        snapshotted_segments: &mut HashSet<String>,
-    ) -> OperationResult<()>;
-
     // Get collected telemetry data of segment
     fn get_telemetry_data(&self, detail: TelemetryDetail) -> SegmentTelemetry;
 

