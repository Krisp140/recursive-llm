# Instructions

You are being benchmarked. You will see the output of a git log command, and from that must infer the current state of a file. Think carefully, as you must output the exact state of the file to earn full marks.

**Important:** Your goal is to reproduce the file's content *exactly* as it exists at the final commit, even if the code appears broken, buggy, or contains obvious errors. Do **not** try to "fix" the code. Attempting to correct issues will result in a poor score, as this benchmark evaluates your ability to reproduce the precise state of the file based on its history.

# Required Response Format

Wrap the content of the file in triple backticks (```). Any text outside the final closing backticks will be ignored. End your response after outputting the closing backticks.

# Example Response

```python
#!/usr/bin/env python
print('Hello, world!')
```

# File History

> git log -p --cc --topo-order --reverse -- lib/storage/src/content_manager/collection_meta_ops.rs

commit 2343078ea16f56108dfe85f0055f859b70db6c35
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Tue Mar 22 18:27:03 2022 +0300

    Collection meta as global state (#394)
    
    * Collection meta as global state
    
    * Improve collection wal entry error handling

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
new file mode 100644
index 000000000..4f03fb0d5
--- /dev/null
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -0,0 +1,161 @@
+use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
+#[cfg(feature = "consensus")]
+use raft::eraftpb::Entry as RaftEntry;
+use schemars::JsonSchema;
+use segment::types::Distance;
+use serde::{Deserialize, Serialize};
+
+// *Operation wrapper structure is only required for better OpenAPI generation
+
+/// Create alternative name for a collection.
+/// Collection will be available under both names for search, retrieve,
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct CreateAlias {
+    pub collection_name: String,
+    pub alias_name: String,
+}
+
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct CreateAliasOperation {
+    pub create_alias: CreateAlias,
+}
+
+/// Delete alias if exists
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct DeleteAlias {
+    pub alias_name: String,
+}
+
+/// Delete alias if exists
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct DeleteAliasOperation {
+    pub delete_alias: DeleteAlias,
+}
+
+/// Change alias to a new one
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct RenameAlias {
+    pub old_alias_name: String,
+    pub new_alias_name: String,
+}
+
+/// Change alias to a new one
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct RenameAliasOperation {
+    pub rename_alias: RenameAlias,
+}
+
+/// Group of all the possible operations related to collection aliases
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+#[serde(untagged)]
+pub enum AliasOperations {
+    CreateAlias(CreateAliasOperation),
+    DeleteAlias(DeleteAliasOperation),
+    RenameAlias(RenameAliasOperation),
+}
+
+impl From<CreateAlias> for AliasOperations {
+    fn from(create_alias: CreateAlias) -> Self {
+        AliasOperations::CreateAlias(CreateAliasOperation { create_alias })
+    }
+}
+
+impl From<DeleteAlias> for AliasOperations {
+    fn from(delete_alias: DeleteAlias) -> Self {
+        AliasOperations::DeleteAlias(DeleteAliasOperation { delete_alias })
+    }
+}
+
+impl From<RenameAlias> for AliasOperations {
+    fn from(rename_alias: RenameAlias) -> Self {
+        AliasOperations::RenameAlias(RenameAliasOperation { rename_alias })
+    }
+}
+
+/// Operation for creating new collection and (optionally) specify index params
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct CreateCollection {
+    pub vector_size: usize,
+    pub distance: Distance,
+    /// Number of shards in collection. Default is 1, minimum is 1.
+    #[serde(default = "default_shard_number")]
+    pub shard_number: u32,
+    /// Custom params for HNSW index. If none - values from service configuration file are used.
+    pub hnsw_config: Option<HnswConfigDiff>,
+    /// Custom params for WAL. If none - values from service configuration file are used.
+    pub wal_config: Option<WalConfigDiff>,
+    /// Custom params for Optimizers.  If none - values from service configuration file are used.
+    pub optimizers_config: Option<OptimizersConfigDiff>,
+}
+
+pub const fn default_shard_number() -> u32 {
+    1
+}
+
+/// Operation for creating new collection and (optionally) specify index params
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct CreateCollectionOperation {
+    pub collection_name: String,
+    #[serde(flatten)]
+    pub create_collection: CreateCollection,
+}
+
+/// Operation for updating parameters of the existing collection
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct UpdateCollection {
+    /// Custom params for Optimizers.  If none - values from service configuration file are used.
+    /// This operation is blocking, it will only proceed ones all current optimizations are complete
+    pub optimizers_config: Option<OptimizersConfigDiff>, // ToDo: Allow updates for other configuration params as well
+}
+
+/// Operation for updating parameters of the existing collection
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct UpdateCollectionOperation {
+    pub collection_name: String,
+    #[serde(flatten)]
+    pub update_collection: UpdateCollection,
+}
+
+/// Operation for performing changes of collection aliases.
+/// Alias changes are atomic, meaning that no collection modifications can happen between
+/// alias operations.
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct ChangeAliasesOperation {
+    pub actions: Vec<AliasOperations>,
+}
+
+/// Operation for deleting collection with given name
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub struct DeleteCollectionOperation(pub String);
+
+/// Enumeration of all possible collection update operations
+#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[serde(rename_all = "snake_case")]
+pub enum CollectionMetaOperations {
+    CreateCollection(CreateCollectionOperation),
+    UpdateCollection(UpdateCollectionOperation),
+    DeleteCollection(DeleteCollectionOperation),
+    ChangeAliases(ChangeAliasesOperation),
+}
+
+#[cfg(feature = "consensus")]
+impl TryFrom<&RaftEntry> for CollectionMetaOperations {
+    type Error = serde_cbor::Error;
+
+    fn try_from(entry: &RaftEntry) -> Result<Self, Self::Error> {
+        serde_cbor::from_slice(entry.get_data())
+    }
+}

commit aeea31dfa40ffe20cd05d78a855fec4e17a18043
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Wed Apr 6 18:00:44 2022 +0300

    Wait for operation commit (#436)
    
    * Wait for operation commit
    
    * Review: Option with timeout, return execution err to API
    
    * Review: Add comment about error forwarding in ???

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 4f03fb0d5..b20aa66df 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -9,35 +9,35 @@ use serde::{Deserialize, Serialize};
 
 /// Create alternative name for a collection.
 /// Collection will be available under both names for search, retrieve,
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateAlias {
     pub collection_name: String,
     pub alias_name: String,
 }
 
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateAliasOperation {
     pub create_alias: CreateAlias,
 }
 
 /// Delete alias if exists
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteAlias {
     pub alias_name: String,
 }
 
 /// Delete alias if exists
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteAliasOperation {
     pub delete_alias: DeleteAlias,
 }
 
 /// Change alias to a new one
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct RenameAlias {
     pub old_alias_name: String,
@@ -45,14 +45,14 @@ pub struct RenameAlias {
 }
 
 /// Change alias to a new one
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct RenameAliasOperation {
     pub rename_alias: RenameAlias,
 }
 
 /// Group of all the possible operations related to collection aliases
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 #[serde(untagged)]
 pub enum AliasOperations {
@@ -80,7 +80,7 @@ impl From<RenameAlias> for AliasOperations {
 }
 
 /// Operation for creating new collection and (optionally) specify index params
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollection {
     pub vector_size: usize,
@@ -101,7 +101,7 @@ pub const fn default_shard_number() -> u32 {
 }
 
 /// Operation for creating new collection and (optionally) specify index params
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollectionOperation {
     pub collection_name: String,
@@ -110,7 +110,7 @@ pub struct CreateCollectionOperation {
 }
 
 /// Operation for updating parameters of the existing collection
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollection {
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
@@ -119,7 +119,7 @@ pub struct UpdateCollection {
 }
 
 /// Operation for updating parameters of the existing collection
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollectionOperation {
     pub collection_name: String,
@@ -130,19 +130,19 @@ pub struct UpdateCollectionOperation {
 /// Operation for performing changes of collection aliases.
 /// Alias changes are atomic, meaning that no collection modifications can happen between
 /// alias operations.
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct ChangeAliasesOperation {
     pub actions: Vec<AliasOperations>,
 }
 
 /// Operation for deleting collection with given name
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteCollectionOperation(pub String);
 
 /// Enumeration of all possible collection update operations
-#[derive(Debug, Deserialize, Serialize, JsonSchema)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
 pub enum CollectionMetaOperations {
     CreateCollection(CreateCollectionOperation),

commit 40c4c1ec2ce37121ca670f095661786a3c3c8ea9
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Mon May 2 18:02:35 2022 +0300

    Allows bootstrapping peer on addition (#529)
    
    * Allows bootstrapping peer on addition
    
    * Review: warn on address replacement
    
    * Review: more detailed comments

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index b20aa66df..54694ecdf 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,6 +1,4 @@
 use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
-#[cfg(feature = "consensus")]
-use raft::eraftpb::Entry as RaftEntry;
 use schemars::JsonSchema;
 use segment::types::Distance;
 use serde::{Deserialize, Serialize};
@@ -150,12 +148,3 @@ pub enum CollectionMetaOperations {
     DeleteCollection(DeleteCollectionOperation),
     ChangeAliases(ChangeAliasesOperation),
 }
-
-#[cfg(feature = "consensus")]
-impl TryFrom<&RaftEntry> for CollectionMetaOperations {
-    type Error = serde_cbor::Error;
-
-    fn try_from(entry: &RaftEntry) -> Result<Self, Self::Error> {
-        serde_cbor::from_slice(entry.get_data())
-    }
-}

commit 63a1552cb134d882364b615391e6334963b89b58
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Tue May 24 15:42:04 2022 +0200

    [sharding] Materialize remote shards (#599)
    
    * materialize remote shards at collection creation and load
    
    * code review naming
    
    * use dedicated integration test
    
    * introduce ChannelService
    
    * introduce CreateCollectionDistributed
    
    * fix test name
    
    * create missing remote shards while applying the SnapshotData

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 54694ecdf..502446119 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,3 +1,4 @@
+use crate::content_manager::shard_distribution::ShardDistributionProposal;
 use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
 use schemars::JsonSchema;
 use segment::types::Distance;
@@ -144,6 +145,7 @@ pub struct DeleteCollectionOperation(pub String);
 #[serde(rename_all = "snake_case")]
 pub enum CollectionMetaOperations {
     CreateCollection(CreateCollectionOperation),
+    CreateCollectionDistributed(CreateCollectionOperation, ShardDistributionProposal),
     UpdateCollection(UpdateCollectionOperation),
     DeleteCollection(DeleteCollectionOperation),
     ChangeAliases(ChangeAliasesOperation),

commit 1b458780eb196ebbbd7fb1f6c5d85ce3b15adb64
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Jun 1 17:23:34 2022 +0200

    On disk payload storage (#634)
    
    * implement on-disk payload storage
    
    * fmt + clippy
    
    * config param for on-disk payload storage
    
    * upd openapi definitions
    
    * add integration test with on-disk payload
    
    * fix clippy
    
    * review fixes
    
    * fmt

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 502446119..34d80a6b0 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -87,6 +87,12 @@ pub struct CreateCollection {
     /// Number of shards in collection. Default is 1, minimum is 1.
     #[serde(default = "default_shard_number")]
     pub shard_number: u32,
+    /// If true - point's payload will not be stored in memory.
+    /// It will be read from the disk every time it is requested.
+    /// This setting saves RAM by (slightly) increasing the response time.
+    /// Note: those payload values that are involved in filtering and are indexed - remain in RAM.
+    #[serde(default = "default_on_disk_payload")]
+    pub on_disk_payload: Option<bool>,
     /// Custom params for HNSW index. If none - values from service configuration file are used.
     pub hnsw_config: Option<HnswConfigDiff>,
     /// Custom params for WAL. If none - values from service configuration file are used.
@@ -99,6 +105,10 @@ pub const fn default_shard_number() -> u32 {
     1
 }
 
+pub const fn default_on_disk_payload() -> Option<bool> {
+    None
+}
+
 /// Operation for creating new collection and (optionally) specify index params
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]

commit fc2f579ec6963e752c08ae349f42480bf0789a72
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Jun 7 16:59:10 2022 +0200

    smarter default number of shards (#668)
    
    * smarter default number of shards
    
    * upd openapi

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 34d80a6b0..8ffaf4b79 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -84,9 +84,11 @@ impl From<RenameAlias> for AliasOperations {
 pub struct CreateCollection {
     pub vector_size: usize,
     pub distance: Distance,
-    /// Number of shards in collection. Default is 1, minimum is 1.
+    /// Number of shards in collection.
+    /// Default is 1 for standalone, otherwise equal to the number of nodes
+    /// Minimum is 1
     #[serde(default = "default_shard_number")]
-    pub shard_number: u32,
+    pub shard_number: Option<u32>,
     /// If true - point's payload will not be stored in memory.
     /// It will be read from the disk every time it is requested.
     /// This setting saves RAM by (slightly) increasing the response time.
@@ -101,8 +103,8 @@ pub struct CreateCollection {
     pub optimizers_config: Option<OptimizersConfigDiff>,
 }
 
-pub const fn default_shard_number() -> u32 {
-    1
+pub const fn default_shard_number() -> Option<u32> {
+    None
 }
 
 pub const fn default_on_disk_payload() -> Option<bool> {

commit bd55b143e20f5d4a99821e87dbf499659c87f890
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Tue Jul 12 17:37:20 2022 +0300

    Consensus operations for shard transfer (#793)
    
    * Consensus operations for shard transfer
    
    * service error corrected
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    
    * Review fix: add transfer abortion reason
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 8ffaf4b79..c2d1677dc 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,5 +1,9 @@
 use crate::content_manager::shard_distribution::ShardDistributionProposal;
-use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
+use collection::{
+    operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff},
+    shard::ShardId,
+    CollectionId, PeerId,
+};
 use schemars::JsonSchema;
 use segment::types::Distance;
 use serde::{Deserialize, Serialize};
@@ -152,6 +156,13 @@ pub struct ChangeAliasesOperation {
 #[serde(rename_all = "snake_case")]
 pub struct DeleteCollectionOperation(pub String);
 
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+pub enum ShardTransferOperations {
+    Start { to: PeerId },
+    Finish,
+    Abort { reason: String },
+}
+
 /// Enumeration of all possible collection update operations
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 #[serde(rename_all = "snake_case")]
@@ -161,4 +172,5 @@ pub enum CollectionMetaOperations {
     UpdateCollection(UpdateCollectionOperation),
     DeleteCollection(DeleteCollectionOperation),
     ChangeAliases(ChangeAliasesOperation),
+    TransferShard(CollectionId, ShardId, ShardTransferOperations),
 }

commit 2f4acd91a0794eda433a22049c66ba5845080b21
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Fri Jul 15 10:12:39 2022 +0200

    Refactor collection lib rs (#819)
    
    * move collection state into separate file
    
    * move collection_shard_distribution into separate file
    
    * move collection struct into collection.rs
    
    * fmt

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index c2d1677dc..9f195b2ff 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,8 +1,8 @@
 use crate::content_manager::shard_distribution::ShardDistributionProposal;
+use collection::shard::{CollectionId, PeerId};
 use collection::{
     operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff},
     shard::ShardId,
-    CollectionId, PeerId,
 };
 use schemars::JsonSchema;
 use segment::types::Distance;

commit 026bd040b001f1c66e16fc911322f1f182d1cf0f
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Fri Jul 15 15:42:25 2022 +0300

    Add import formatting rules (#820)
    
    * Add import formatting rules
    
    * Review fix: update rusty hook

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 9f195b2ff..865e84f8d 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,13 +1,11 @@
-use crate::content_manager::shard_distribution::ShardDistributionProposal;
-use collection::shard::{CollectionId, PeerId};
-use collection::{
-    operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff},
-    shard::ShardId,
-};
+use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
+use collection::shard::{CollectionId, PeerId, ShardId};
 use schemars::JsonSchema;
 use segment::types::Distance;
 use serde::{Deserialize, Serialize};
 
+use crate::content_manager::shard_distribution::ShardDistributionProposal;
+
 // *Operation wrapper structure is only required for better OpenAPI generation
 
 /// Create alternative name for a collection.

commit 38cf82251848b7d1435cf2a51fac0febf8517f81
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Jul 27 10:12:00 2022 +0200

    Shard transmission (#830)
    
    * forward proxy shard
    
    * fmt
    
    * transmission routine
    
    * fmt
    
    * add channel service to collection
    
    * WIP: shard transfer handlelling
    
    * WIP: transfer task pool
    
    * WIP: fmt
    
    * fmt
    
    * handle commands from consensus: start, finish & abort transmission
    
    * fmt
    
    * initiate temp shard on remote
    
    * Update lib/collection/src/collection.rs
    
    Co-authored-by: Egor Ivkov <e.o.ivkov@gmail.com>
    
    * Update lib/collection/src/collection.rs
    
    Co-authored-by: Egor Ivkov <e.o.ivkov@gmail.com>
    
    * review fixes
    
    * fmt
    
    * review fixes 2
    
    Co-authored-by: Egor Ivkov <e.o.ivkov@gmail.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 865e84f8d..2c6c7626b 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -157,8 +157,8 @@ pub struct DeleteCollectionOperation(pub String);
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 pub enum ShardTransferOperations {
     Start { to: PeerId },
-    Finish,
-    Abort { reason: String },
+    Finish { to: PeerId },
+    Abort { to: PeerId, reason: String },
 }
 
 /// Enumeration of all possible collection update operations

commit 71a8bfbfdf6ab3e12666898d1c6ca8cae548d719
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Aug 1 20:40:23 2022 +0200

    Shard transfer from (#880)
    
    * explicitly specify the source of shard transfer
    
    * fmt
    
    * fix integration test

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 2c6c7626b..2107ee2dd 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,5 +1,5 @@
 use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
-use collection::shard::{CollectionId, PeerId, ShardId};
+use collection::shard::{CollectionId, ShardTransfer};
 use schemars::JsonSchema;
 use segment::types::Distance;
 use serde::{Deserialize, Serialize};
@@ -156,9 +156,12 @@ pub struct DeleteCollectionOperation(pub String);
 
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
 pub enum ShardTransferOperations {
-    Start { to: PeerId },
-    Finish { to: PeerId },
-    Abort { to: PeerId, reason: String },
+    Start(ShardTransfer),
+    Finish(ShardTransfer),
+    Abort {
+        transfer: ShardTransfer,
+        reason: String,
+    },
 }
 
 /// Enumeration of all possible collection update operations
@@ -170,5 +173,5 @@ pub enum CollectionMetaOperations {
     UpdateCollection(UpdateCollectionOperation),
     DeleteCollection(DeleteCollectionOperation),
     ChangeAliases(ChangeAliasesOperation),
-    TransferShard(CollectionId, ShardId, ShardTransferOperations),
+    TransferShard(CollectionId, ShardTransferOperations),
 }

commit 00e965fc961f87e10911c32e08869fc3baed7aa1
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Aug 4 14:47:49 2022 +0200

    Configuration change on peer removal (#914)
    
    * propose configuration change along with removal of the peer
    
    * fmt

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 2107ee2dd..2f692459a 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -10,35 +10,35 @@ use crate::content_manager::shard_distribution::ShardDistributionProposal;
 
 /// Create alternative name for a collection.
 /// Collection will be available under both names for search, retrieve,
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateAlias {
     pub collection_name: String,
     pub alias_name: String,
 }
 
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateAliasOperation {
     pub create_alias: CreateAlias,
 }
 
 /// Delete alias if exists
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteAlias {
     pub alias_name: String,
 }
 
 /// Delete alias if exists
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteAliasOperation {
     pub delete_alias: DeleteAlias,
 }
 
 /// Change alias to a new one
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct RenameAlias {
     pub old_alias_name: String,
@@ -46,14 +46,14 @@ pub struct RenameAlias {
 }
 
 /// Change alias to a new one
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct RenameAliasOperation {
     pub rename_alias: RenameAlias,
 }
 
 /// Group of all the possible operations related to collection aliases
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 #[serde(untagged)]
 pub enum AliasOperations {
@@ -81,7 +81,7 @@ impl From<RenameAlias> for AliasOperations {
 }
 
 /// Operation for creating new collection and (optionally) specify index params
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollection {
     pub vector_size: usize,
@@ -114,7 +114,7 @@ pub const fn default_on_disk_payload() -> Option<bool> {
 }
 
 /// Operation for creating new collection and (optionally) specify index params
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollectionOperation {
     pub collection_name: String,
@@ -123,7 +123,7 @@ pub struct CreateCollectionOperation {
 }
 
 /// Operation for updating parameters of the existing collection
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollection {
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
@@ -132,7 +132,7 @@ pub struct UpdateCollection {
 }
 
 /// Operation for updating parameters of the existing collection
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollectionOperation {
     pub collection_name: String,
@@ -143,18 +143,18 @@ pub struct UpdateCollectionOperation {
 /// Operation for performing changes of collection aliases.
 /// Alias changes are atomic, meaning that no collection modifications can happen between
 /// alias operations.
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct ChangeAliasesOperation {
     pub actions: Vec<AliasOperations>,
 }
 
 /// Operation for deleting collection with given name
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteCollectionOperation(pub String);
 
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 pub enum ShardTransferOperations {
     Start(ShardTransfer),
     Finish(ShardTransfer),
@@ -165,7 +165,7 @@ pub enum ShardTransferOperations {
 }
 
 /// Enumeration of all possible collection update operations
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub enum CollectionMetaOperations {
     CreateCollection(CreateCollectionOperation),

commit dc0314201edc69c04930cd8e6b752515b59ee74e
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Wed Aug 31 11:26:52 2022 +0300

    Add replication factor (#966)
    
    * Add replication_factor config and ops to change it

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 2f692459a..9d2c236ed 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -89,13 +89,13 @@ pub struct CreateCollection {
     /// Number of shards in collection.
     /// Default is 1 for standalone, otherwise equal to the number of nodes
     /// Minimum is 1
-    #[serde(default = "default_shard_number")]
+    #[serde(default)]
     pub shard_number: Option<u32>,
     /// If true - point's payload will not be stored in memory.
     /// It will be read from the disk every time it is requested.
     /// This setting saves RAM by (slightly) increasing the response time.
     /// Note: those payload values that are involved in filtering and are indexed - remain in RAM.
-    #[serde(default = "default_on_disk_payload")]
+    #[serde(default)]
     pub on_disk_payload: Option<bool>,
     /// Custom params for HNSW index. If none - values from service configuration file are used.
     pub hnsw_config: Option<HnswConfigDiff>,
@@ -105,14 +105,6 @@ pub struct CreateCollection {
     pub optimizers_config: Option<OptimizersConfigDiff>,
 }
 
-pub const fn default_shard_number() -> Option<u32> {
-    None
-}
-
-pub const fn default_on_disk_payload() -> Option<bool> {
-    None
-}
-
 /// Operation for creating new collection and (optionally) specify index params
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]

commit 167774aadec32f50b3e9feafc8ecd9491702bc30
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Tue Sep 6 15:37:34 2022 +0300

    `SetShardReplicaState` operation (#986)
    
    * `SetShardReplicaState` operation
    
    * Review fix: assume RemotePeer manages several remote peers

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 9d2c236ed..0973c9bf2 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,5 +1,5 @@
 use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
-use collection::shard::{CollectionId, ShardTransfer};
+use collection::shard::{CollectionId, PeerId, ShardId, ShardTransfer};
 use schemars::JsonSchema;
 use segment::types::Distance;
 use serde::{Deserialize, Serialize};
@@ -156,6 +156,16 @@ pub enum ShardTransferOperations {
     },
 }
 
+/// Sets the state of shard replica
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+pub struct SetShardReplicaState {
+    pub collection_name: String,
+    pub shard_id: ShardId,
+    pub peer_id: PeerId,
+    /// If `true` then the replica is up to date and can receive updates and answer requests
+    pub active: bool,
+}
+
 /// Enumeration of all possible collection update operations
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
@@ -166,4 +176,5 @@ pub enum CollectionMetaOperations {
     DeleteCollection(DeleteCollectionOperation),
     ChangeAliases(ChangeAliasesOperation),
     TransferShard(CollectionId, ShardTransferOperations),
+    SetShardReplicaState(SetShardReplicaState),
 }

commit f6b21861939744e054a861d9771608b7e6b614e7
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Sun Sep 11 22:59:23 2022 +0400

    [WIP] Many named vectors per point (#958)
    
    * many named vectors per point (segment-level)
    
    * operation result for dim function
    
    * beautifulized vector name
    
    * fix naming bug
    
    * segment version migration
    
    * fmt
    
    * add segment tests
    
    * are you happy clippy
    
    * fix build
    
    * [WIP] many named vectors per point (collection-level) (#975)
    
    * config and search
    
    * fix placeholders for proxy segment move
    
    * remove VectorType from collection
    
    * are you happy fmt
    
    * vectors in grps messages
    
    * create collections with vectors
    
    * segment holder fixes
    
    * are you happy fmt
    
    * remove default vector name placeholders
    
    * are you happy fmt
    
    * are you happy clippy
    
    * fix build
    
    * fix web api
    
    * are you happy clippy
    
    * are you happy fmt
    
    * record vector&vectors
    
    * openapi update
    
    * fix openapi integration tests
    
    * segment builder fix todo
    
    * vector names for update from segment
    
    * remove unwrap
    
    * backward compatibility
    
    * upd openapi
    
    * backward compatible PointStruct
    
    * upd openapi
    
    * fix record back-comp
    
    * fmt
    
    * vector configuration backward compatibility
    
    * fix vetor storage size estimation
    
    * fmt
    
    * multi-vec segment test + index test
    
    * fmt
    
    * api integration tests
    
    * [WIP] Named vectors struct (#1002)
    
    * move to separate file
    
    * named vectors as struct
    
    * use cow
    
    * fix build
    
    * keys iterator
    
    * avoid copy in PointStruct -> get_vectors
    
    * avoid another copy
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 0973c9bf2..f23b6c0db 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,3 +1,4 @@
+use collection::config::VectorsConfig;
 use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
 use collection::shard::{CollectionId, PeerId, ShardId, ShardTransfer};
 use schemars::JsonSchema;
@@ -84,8 +85,11 @@ impl From<RenameAlias> for AliasOperations {
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollection {
-    pub vector_size: usize,
-    pub distance: Distance,
+    pub vectors: Option<VectorsConfig>,
+    #[deprecated(since = "0.10.0", note = "Use `vectors` instead")]
+    pub vector_size: Option<usize>,
+    #[deprecated(since = "0.10.0", note = "Use `vectors` instead")]
+    pub distance: Option<Distance>,
     /// Number of shards in collection.
     /// Default is 1 for standalone, otherwise equal to the number of nodes
     /// Minimum is 1

commit 22fd3a39635045859d51cca71e61378317da3ff5
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Thu Sep 15 13:37:38 2022 +0400

    minor doc and api in tests updates (#1022)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index f23b6c0db..3e6fa1c0c 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -85,9 +85,13 @@ impl From<RenameAlias> for AliasOperations {
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollection {
+    /// Vector data config.
+    /// It is possible to provide one config for single vector mode and list of configs for multiple vectors mode.
     pub vectors: Option<VectorsConfig>,
+    /// Deprecated size setup for single-vector mode. It's required to set one vector_size or vectors field.
     #[deprecated(since = "0.10.0", note = "Use `vectors` instead")]
     pub vector_size: Option<usize>,
+    /// Deprecated distance setup for single-vector mode. It's required to set one vector_size or vectors field.
     #[deprecated(since = "0.10.0", note = "Use `vectors` instead")]
     pub distance: Option<Distance>,
     /// Number of shards in collection.

commit dc07b01e1fea5cb9be3579b555be480e30aa3041
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Sep 19 13:51:03 2022 +0200

    remove deprecated fields from API (#1030)
    
    * remove depricated fields from API
    
    * fmt
    
    * upd openapi and integration tests
    
    * fix grpc test
    
    * regenerate storage reference data
    
    * improve docs
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 3e6fa1c0c..5e37c8a14 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -2,7 +2,6 @@ use collection::config::VectorsConfig;
 use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
 use collection::shard::{CollectionId, PeerId, ShardId, ShardTransfer};
 use schemars::JsonSchema;
-use segment::types::Distance;
 use serde::{Deserialize, Serialize};
 
 use crate::content_manager::shard_distribution::ShardDistributionProposal;
@@ -87,13 +86,7 @@ impl From<RenameAlias> for AliasOperations {
 pub struct CreateCollection {
     /// Vector data config.
     /// It is possible to provide one config for single vector mode and list of configs for multiple vectors mode.
-    pub vectors: Option<VectorsConfig>,
-    /// Deprecated size setup for single-vector mode. It's required to set one vector_size or vectors field.
-    #[deprecated(since = "0.10.0", note = "Use `vectors` instead")]
-    pub vector_size: Option<usize>,
-    /// Deprecated distance setup for single-vector mode. It's required to set one vector_size or vectors field.
-    #[deprecated(since = "0.10.0", note = "Use `vectors` instead")]
-    pub distance: Option<Distance>,
+    pub vectors: VectorsConfig,
     /// Number of shards in collection.
     /// Default is 1 for standalone, otherwise equal to the number of nodes
     /// Minimum is 1

commit d690b700ffd36af2da68e8e3ed19789d6f108ffe
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Wed Sep 21 18:49:47 2022 +0300

    Replication related API changes (#1037)
    
    * Replication related API changes
    
    * minor proto file fix

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 5e37c8a14..ace949843 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,5 +1,7 @@
 use collection::config::VectorsConfig;
-use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
+use collection::operations::config_diff::{
+    CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
+};
 use collection::shard::{CollectionId, PeerId, ShardId, ShardTransfer};
 use schemars::JsonSchema;
 use serde::{Deserialize, Serialize};
@@ -92,6 +94,11 @@ pub struct CreateCollection {
     /// Minimum is 1
     #[serde(default)]
     pub shard_number: Option<u32>,
+    /// Number of shards replicas.
+    /// Default is 1
+    /// Minimum is 1
+    #[serde(default)]
+    pub replication_factor: Option<u32>,
     /// If true - point's payload will not be stored in memory.
     /// It will be read from the disk every time it is requested.
     /// This setting saves RAM by (slightly) increasing the response time.
@@ -122,6 +129,8 @@ pub struct UpdateCollection {
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
     /// This operation is blocking, it will only proceed ones all current optimizations are complete
     pub optimizers_config: Option<OptimizersConfigDiff>, // ToDo: Allow updates for other configuration params as well
+    /// Collection base params.  If none - values from service configuration file are used.
+    pub params: Option<CollectionParamsDiff>,
 }
 
 /// Operation for updating parameters of the existing collection

commit 183ea9e5e3e704a00e67aff64f4bb940043c3745
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Thu Sep 22 14:53:00 2022 +0300

    Generate API - replication follow up (#1043)
    
    Also removes `JsonSchema` from structs not exposed in API

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index ace949843..0dae3ca1b 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -114,7 +114,7 @@ pub struct CreateCollection {
 }
 
 /// Operation for creating new collection and (optionally) specify index params
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollectionOperation {
     pub collection_name: String,
@@ -134,7 +134,7 @@ pub struct UpdateCollection {
 }
 
 /// Operation for updating parameters of the existing collection
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollectionOperation {
     pub collection_name: String,
@@ -152,11 +152,11 @@ pub struct ChangeAliasesOperation {
 }
 
 /// Operation for deleting collection with given name
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteCollectionOperation(pub String);
 
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 pub enum ShardTransferOperations {
     Start(ShardTransfer),
     Finish(ShardTransfer),
@@ -167,7 +167,7 @@ pub enum ShardTransferOperations {
 }
 
 /// Sets the state of shard replica
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 pub struct SetShardReplicaState {
     pub collection_name: String,
     pub shard_id: ShardId,
@@ -177,7 +177,7 @@ pub struct SetShardReplicaState {
 }
 
 /// Enumeration of all possible collection update operations
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub enum CollectionMetaOperations {
     CreateCollection(CreateCollectionOperation),

commit a2ed0cf5db1d387606e7dbaa998cb72e60156c30
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Fri Sep 23 16:33:07 2022 +0300

    Revert replication changes (#1055)
    
    * Revert "Replication set `Change` enum"
    
    This reverts commit 28e8487542bc203486027be417f8ed6b1acbf8eb.
    
    * Revert changes (#1053)
    
    * Revert "Generate API - replication follow up (#1043)"
    
    This reverts commit 183ea9e5e3e704a00e67aff64f4bb940043c3745.
    
    * Revert "Replication related API changes (#1037)"
    
    This reverts commit d690b700ffd36af2da68e8e3ed19789d6f108ffe.
    
    * Revert "Persist replica state (#1035)"
    
    This reverts commit 31c3ae482d7adb314382842caccfba8016c833fc.
    
    * Revert "[replication] Account for replicas in shard distribution (#1009)"
    
    This reverts commit e332d482b0e0ecabeab0b2328c2e89b969be2088.
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 0dae3ca1b..5e37c8a14 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,7 +1,5 @@
 use collection::config::VectorsConfig;
-use collection::operations::config_diff::{
-    CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
-};
+use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
 use collection::shard::{CollectionId, PeerId, ShardId, ShardTransfer};
 use schemars::JsonSchema;
 use serde::{Deserialize, Serialize};
@@ -94,11 +92,6 @@ pub struct CreateCollection {
     /// Minimum is 1
     #[serde(default)]
     pub shard_number: Option<u32>,
-    /// Number of shards replicas.
-    /// Default is 1
-    /// Minimum is 1
-    #[serde(default)]
-    pub replication_factor: Option<u32>,
     /// If true - point's payload will not be stored in memory.
     /// It will be read from the disk every time it is requested.
     /// This setting saves RAM by (slightly) increasing the response time.
@@ -114,7 +107,7 @@ pub struct CreateCollection {
 }
 
 /// Operation for creating new collection and (optionally) specify index params
-#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollectionOperation {
     pub collection_name: String,
@@ -129,12 +122,10 @@ pub struct UpdateCollection {
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
     /// This operation is blocking, it will only proceed ones all current optimizations are complete
     pub optimizers_config: Option<OptimizersConfigDiff>, // ToDo: Allow updates for other configuration params as well
-    /// Collection base params.  If none - values from service configuration file are used.
-    pub params: Option<CollectionParamsDiff>,
 }
 
 /// Operation for updating parameters of the existing collection
-#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollectionOperation {
     pub collection_name: String,
@@ -152,11 +143,11 @@ pub struct ChangeAliasesOperation {
 }
 
 /// Operation for deleting collection with given name
-#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteCollectionOperation(pub String);
 
-#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 pub enum ShardTransferOperations {
     Start(ShardTransfer),
     Finish(ShardTransfer),
@@ -167,7 +158,7 @@ pub enum ShardTransferOperations {
 }
 
 /// Sets the state of shard replica
-#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 pub struct SetShardReplicaState {
     pub collection_name: String,
     pub shard_id: ShardId,
@@ -177,7 +168,7 @@ pub struct SetShardReplicaState {
 }
 
 /// Enumeration of all possible collection update operations
-#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub enum CollectionMetaOperations {
     CreateCollection(CreateCollectionOperation),

commit 9a3fad44b228273c9443f232052331872932ff18
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Fri Sep 23 16:46:06 2022 +0300

    Revert "Revert replication changes (#1055)" (#1056)
    
    This reverts commit a2ed0cf5db1d387606e7dbaa998cb72e60156c30.

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 5e37c8a14..0dae3ca1b 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,5 +1,7 @@
 use collection::config::VectorsConfig;
-use collection::operations::config_diff::{HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff};
+use collection::operations::config_diff::{
+    CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
+};
 use collection::shard::{CollectionId, PeerId, ShardId, ShardTransfer};
 use schemars::JsonSchema;
 use serde::{Deserialize, Serialize};
@@ -92,6 +94,11 @@ pub struct CreateCollection {
     /// Minimum is 1
     #[serde(default)]
     pub shard_number: Option<u32>,
+    /// Number of shards replicas.
+    /// Default is 1
+    /// Minimum is 1
+    #[serde(default)]
+    pub replication_factor: Option<u32>,
     /// If true - point's payload will not be stored in memory.
     /// It will be read from the disk every time it is requested.
     /// This setting saves RAM by (slightly) increasing the response time.
@@ -107,7 +114,7 @@ pub struct CreateCollection {
 }
 
 /// Operation for creating new collection and (optionally) specify index params
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollectionOperation {
     pub collection_name: String,
@@ -122,10 +129,12 @@ pub struct UpdateCollection {
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
     /// This operation is blocking, it will only proceed ones all current optimizations are complete
     pub optimizers_config: Option<OptimizersConfigDiff>, // ToDo: Allow updates for other configuration params as well
+    /// Collection base params.  If none - values from service configuration file are used.
+    pub params: Option<CollectionParamsDiff>,
 }
 
 /// Operation for updating parameters of the existing collection
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollectionOperation {
     pub collection_name: String,
@@ -143,11 +152,11 @@ pub struct ChangeAliasesOperation {
 }
 
 /// Operation for deleting collection with given name
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct DeleteCollectionOperation(pub String);
 
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 pub enum ShardTransferOperations {
     Start(ShardTransfer),
     Finish(ShardTransfer),
@@ -158,7 +167,7 @@ pub enum ShardTransferOperations {
 }
 
 /// Sets the state of shard replica
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 pub struct SetShardReplicaState {
     pub collection_name: String,
     pub shard_id: ShardId,
@@ -168,7 +177,7 @@ pub struct SetShardReplicaState {
 }
 
 /// Enumeration of all possible collection update operations
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub enum CollectionMetaOperations {
     CreateCollection(CreateCollectionOperation),

commit c6c0afa78177a044e5a98194951ae673f5816847
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Wed Sep 28 17:05:11 2022 +0300

    [replication] Suggest replica set changes on repl_factor change (#1059)
    
    * Suggest replica set changes on repl_factor change
    
    * Review fix: account for replication_factor being 1
    
    * Update lib/collection/src/collection.rs
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    
    * Update lib/storage/src/content_manager/toc.rs
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    
    * Review fix: accept higher repl factor than n peers
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 0dae3ca1b..4012f9cc6 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -2,7 +2,7 @@ use collection::config::VectorsConfig;
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
 };
-use collection::shard::{CollectionId, PeerId, ShardId, ShardTransfer};
+use collection::shard::{replica_set, CollectionId, PeerId, ShardId, ShardTransfer};
 use schemars::JsonSchema;
 use serde::{Deserialize, Serialize};
 
@@ -118,8 +118,26 @@ pub struct CreateCollection {
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollectionOperation {
     pub collection_name: String,
-    #[serde(flatten)]
     pub create_collection: CreateCollection,
+    distribution: Option<ShardDistributionProposal>,
+}
+
+impl CreateCollectionOperation {
+    pub fn new(collection_name: String, create_collection: CreateCollection) -> Self {
+        Self {
+            collection_name,
+            create_collection,
+            distribution: None,
+        }
+    }
+
+    pub fn take_distribution(&mut self) -> Option<ShardDistributionProposal> {
+        self.distribution.take()
+    }
+
+    pub fn set_distribution(&mut self, distribution: ShardDistributionProposal) {
+        self.distribution = Some(distribution);
+    }
 }
 
 /// Operation for updating parameters of the existing collection
@@ -138,8 +156,26 @@ pub struct UpdateCollection {
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollectionOperation {
     pub collection_name: String,
-    #[serde(flatten)]
     pub update_collection: UpdateCollection,
+    shard_replica_changes: Option<Vec<replica_set::Change>>,
+}
+
+impl UpdateCollectionOperation {
+    pub fn new(collection_name: String, update_collection: UpdateCollection) -> Self {
+        Self {
+            collection_name,
+            update_collection,
+            shard_replica_changes: None,
+        }
+    }
+
+    pub fn take_shard_replica_changes(&mut self) -> Option<Vec<replica_set::Change>> {
+        self.shard_replica_changes.take()
+    }
+
+    pub fn set_shard_replica_changes(&mut self, changes: Vec<replica_set::Change>) {
+        self.shard_replica_changes = Some(changes);
+    }
 }
 
 /// Operation for performing changes of collection aliases.
@@ -181,7 +217,6 @@ pub struct SetShardReplicaState {
 #[serde(rename_all = "snake_case")]
 pub enum CollectionMetaOperations {
     CreateCollection(CreateCollectionOperation),
-    CreateCollectionDistributed(CreateCollectionOperation, ShardDistributionProposal),
     UpdateCollection(UpdateCollectionOperation),
     DeleteCollection(DeleteCollectionOperation),
     ChangeAliases(ChangeAliasesOperation),

commit b275d452a8f2a547cb4ec80e711d5a27385c328c
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Oct 12 15:19:43 2022 +0200

    shard replica manipulation API (#1121)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 4012f9cc6..a0c1ad1d2 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -161,6 +161,17 @@ pub struct UpdateCollectionOperation {
 }
 
 impl UpdateCollectionOperation {
+    pub fn new_empty(collection_name: String) -> Self {
+        Self {
+            collection_name,
+            update_collection: UpdateCollection {
+                optimizers_config: None,
+                params: None,
+            },
+            shard_replica_changes: None,
+        }
+    }
+
     pub fn new(collection_name: String, update_collection: UpdateCollection) -> Self {
         Self {
             collection_name,

commit 9324be1d6038b4ba66ca776eb7e753e69fe5d624
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Oct 17 20:12:10 2022 +0200

    [Replication] Add replicas (#1085)
    
    * Add replicas to ReplicaSet
    
    * unproxify shard & miscs
    
    * no exlusive write locking while adding replicas
    
    * on_optimizer_config_update on Shard with async. recursion
    
    * no exlusive write locking while removing replicas
    
    * shortcut replica set propagation #1101
    
    * remove unused field
    
    * make RequestShardTransfer callback sync.
    
    * promote local & remote to replica state
    
    * fixes for replica sync api (#1123)
    
    * code review
    
    * fix replica set update - fail only if all failed
    
    * Add replica redesign (#1131)
    
    * refactor shard/mod.rs
    
    * wip
    
    * fmt
    
    * it compiles
    
    * temporary disable replica placemeant change on replication factor
    
    * fmt
    
    * finish todos
    
    * small refactoring
    
    * remove change::add
    
    * replica-set -> shard-replica-set
    
    * fmt
    
    * upd openapi
    
    * fix finish transfer logic
    
    * fix existing integration tests
    
    * shard transfer validation
    
    * fmt
    
    * review fixes
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index a0c1ad1d2..920d91116 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -2,7 +2,10 @@ use collection::config::VectorsConfig;
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
 };
-use collection::shard::{replica_set, CollectionId, PeerId, ShardId, ShardTransfer};
+use collection::shards::replica_set::ReplicaState;
+use collection::shards::shard::{PeerId, ShardId};
+use collection::shards::transfer::shard_transfer::ShardTransfer;
+use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
 use serde::{Deserialize, Serialize};
 
@@ -185,7 +188,11 @@ impl UpdateCollectionOperation {
     }
 
     pub fn set_shard_replica_changes(&mut self, changes: Vec<replica_set::Change>) {
-        self.shard_replica_changes = Some(changes);
+        if changes.is_empty() {
+            self.shard_replica_changes = None;
+        } else {
+            self.shard_replica_changes = Some(changes);
+        }
     }
 }
 
@@ -219,8 +226,8 @@ pub struct SetShardReplicaState {
     pub collection_name: String,
     pub shard_id: ShardId,
     pub peer_id: PeerId,
-    /// If `true` then the replica is up to date and can receive updates and answer requests
-    pub active: bool,
+    /// If `Active` then the replica is up to date and can receive updates and answer requests
+    pub state: ReplicaState,
 }
 
 /// Enumeration of all possible collection update operations

commit 7f8c088711462e9c3d50c3cde5ca8e8e3e43d974
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Oct 19 11:38:26 2022 +0200

    Replication transfer fixes (#1142)
    
    * fix validation and task assignment during replica transfer
    
    * fmt
    
    * upd openapi
    
    * extend integration test

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 920d91116..625a00872 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -4,7 +4,7 @@ use collection::operations::config_diff::{
 };
 use collection::shards::replica_set::ReplicaState;
 use collection::shards::shard::{PeerId, ShardId};
-use collection::shards::transfer::shard_transfer::ShardTransfer;
+use collection::shards::transfer::shard_transfer::{ShardTransfer, ShardTransferKey};
 use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
 use serde::{Deserialize, Serialize};
@@ -215,7 +215,7 @@ pub enum ShardTransferOperations {
     Start(ShardTransfer),
     Finish(ShardTransfer),
     Abort {
-        transfer: ShardTransfer,
+        transfer: ShardTransferKey,
         reason: String,
     },
 }

commit 123ae1607d9a20809c2516a66232383e18bb45d2
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Oct 19 17:59:16 2022 +0200

    Await for collection created for sure (#1144)
    
    * run plunger operation after user request to ensure that the majority of the consensus actually applied previous operation
    
    * fmt
    
    * fix test
    
    * ensure all operations are unique in consensus queue
    
    * add extra timeout for CI tests
    
    * fix timout param in delete peer + do not explicilty await on peer removal
    
    * fmt

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 625a00872..8e803a301 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -240,4 +240,5 @@ pub enum CollectionMetaOperations {
     ChangeAliases(ChangeAliasesOperation),
     TransferShard(CollectionId, ShardTransferOperations),
     SetShardReplicaState(SetShardReplicaState),
+    Nop { token: usize }, // Empty operation
 }

commit 664d9bd93be71532061ffbc2ff9c2b4c11f3d20f
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Oct 25 17:37:15 2022 +0200

    implement concern-factor, forbig disabling the last node, improve tes (#1168)
    
    * implement concern-factor, forbig disabling the last node, improve test stability
    
    * upd docs
    
    * improve test_recover_dead_node
    
    * rename to write_consistency_factor
    
    * Fix bug: applied index higher than commit on restart (#1172)
    
    * create collection with default status = dead + await for activation on create_collecton_op_submit
    
    * fmt
    
    * fix unit tests
    
    Co-authored-by: Egor Ivkov <e.o.ivkov@gmail.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 8e803a301..129821c52 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -102,6 +102,12 @@ pub struct CreateCollection {
     /// Minimum is 1
     #[serde(default)]
     pub replication_factor: Option<u32>,
+    /// Defines how many replicas should apply the operation for us to consider it successful.
+    /// Increasing this number will make the collection more resilient to inconsistencies, but will
+    /// also make it fail if not enough replicas are available.
+    /// Does not have any performance impact.
+    #[serde(default)]
+    pub write_consistency_factor: Option<u32>,
     /// If true - point's payload will not be stored in memory.
     /// It will be read from the disk every time it is requested.
     /// This setting saves RAM by (slightly) increasing the response time.

commit 8b0b28207931bb6b8ba41109eb56e5691eddc58b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Fri Nov 4 12:52:51 2022 +0100

    handle collections transition from single-node to cluster (#1189)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 129821c52..5d3aba37d 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -140,6 +140,10 @@ impl CreateCollectionOperation {
         }
     }
 
+    pub fn is_distribution_set(&self) -> bool {
+        self.distribution.is_some()
+    }
+
     pub fn take_distribution(&mut self) -> Option<ShardDistributionProposal> {
         self.distribution.take()
     }

commit 63b59c1044b2da42e493b4592cfe56e7699e8a95
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Nov 9 12:58:06 2022 +0100

    fix colletion params update (#1208)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 5d3aba37d..ef388e20d 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,7 +1,7 @@
-use collection::config::VectorsConfig;
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
 };
+use collection::operations::types::VectorsConfig;
 use collection::shards::replica_set::ReplicaState;
 use collection::shards::shard::{PeerId, ShardId};
 use collection::shards::transfer::shard_transfer::{ShardTransfer, ShardTransferKey};

commit e027db4d27255784715b727bbf67abd44dd0d5c0
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Nov 9 14:03:49 2022 +0100

    V0.11.2 (#1209)
    
    * Update: unmaintained crate memmap -> memmap2 (#559) (#1160)
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    * Consensus q n a (#1169)
    
    * Expand comments and minor refactoring for raft state
    
    * fmt
    
    * add comments to consensus.rs
    
    * fix "Consensus q n a" compatibility
    
    * Use less ram for id tracker (#1176)
    
    * use less ram for id tracker
    
    * are you happy clippy
    
    * use vec for internals
    
    * use versions for internal ids
    
    * keys test
    
    * Use less ram for id tracker fixes (#1182)
    
    * WIP: internal_to_version
    
    * fmt
    
    * fix unit tests
    
    * add comment
    
    Co-authored-by: Ivan Pleshkov <pleshkov.ivan@gmail.com>
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    * remove suggesting changes in replications on replication factor change (#1177)
    
    * Bump actix-cors from 0.6.3 to 0.6.4 (#1185)
    
    Bumps [actix-cors](https://github.com/actix/actix-extras) from 0.6.3 to 0.6.4.
    - [Release notes](https://github.com/actix/actix-extras/releases)
    - [Commits](https://github.com/actix/actix-extras/compare/cors-v0.6.3...cors-v0.6.4)
    
    ---
    updated-dependencies:
    - dependency-name: actix-cors
      dependency-type: direct:production
      update-type: version-update:semver-patch
    ...
    
    Signed-off-by: dependabot[bot] <support@github.com>
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    
    * enable HTTP compression middleware (#1184)
    
    * Use systematically assert_http_ok for better error reporting (#1183)
    
    * Use systematically assert_http_ok for better error reporting
    
    * extraction assertion to use it outside of pytest
    
    * Bump pprof from 0.10.1 to 0.11.0 (#1188)
    
    Bumps [pprof](https://github.com/tikv/pprof-rs) from 0.10.1 to 0.11.0.
    - [Release notes](https://github.com/tikv/pprof-rs/releases)
    - [Changelog](https://github.com/tikv/pprof-rs/blob/master/CHANGELOG.md)
    - [Commits](https://github.com/tikv/pprof-rs/commits)
    
    ---
    updated-dependencies:
    - dependency-name: pprof
      dependency-type: direct:production
      update-type: version-update:semver-minor
    ...
    
    Signed-off-by: dependabot[bot] <support@github.com>
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    
    * Cosine dist zero vectors (#1198)
    
    * skip pre-processing of zero-length vector for cosine distance
    
    * fmt
    
    * Bump env_logger from 0.9.1 to 0.9.3 (#1201)
    
    Bumps [env_logger](https://github.com/env-logger-rs/env_logger) from 0.9.1 to 0.9.3.
    - [Release notes](https://github.com/env-logger-rs/env_logger/releases)
    - [Changelog](https://github.com/env-logger-rs/env_logger/blob/main/CHANGELOG.md)
    - [Commits](https://github.com/env-logger-rs/env_logger/compare/v0.9.1...v0.9.3)
    
    ---
    updated-dependencies:
    - dependency-name: env_logger
      dependency-type: direct:production
      update-type: version-update:semver-patch
    ...
    
    Signed-off-by: dependabot[bot] <support@github.com>
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    
    * Bump indicatif from 0.17.1 to 0.17.2 (#1202)
    
    Bumps [indicatif](https://github.com/console-rs/indicatif) from 0.17.1 to 0.17.2.
    - [Release notes](https://github.com/console-rs/indicatif/releases)
    - [Commits](https://github.com/console-rs/indicatif/compare/0.17.1...0.17.2)
    
    ---
    updated-dependencies:
    - dependency-name: indicatif
      dependency-type: direct:production
      update-type: version-update:semver-patch
    ...
    
    Signed-off-by: dependabot[bot] <support@github.com>
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    
    * Bump ordered-float from 3.3.0 to 3.4.0 (#1204)
    
    Bumps [ordered-float](https://github.com/reem/rust-ordered-float) from 3.3.0 to 3.4.0.
    - [Release notes](https://github.com/reem/rust-ordered-float/releases)
    - [Commits](https://github.com/reem/rust-ordered-float/compare/v3.3.0...v3.4.0)
    
    ---
    updated-dependencies:
    - dependency-name: ordered-float
      dependency-type: direct:production
      update-type: version-update:semver-minor
    ...
    
    Signed-off-by: dependabot[bot] <support@github.com>
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    
    * Bump clap from 4.0.18 to 4.0.22 (#1205)
    
    Bumps [clap](https://github.com/clap-rs/clap) from 4.0.18 to 4.0.22.
    - [Release notes](https://github.com/clap-rs/clap/releases)
    - [Changelog](https://github.com/clap-rs/clap/blob/master/CHANGELOG.md)
    - [Commits](https://github.com/clap-rs/clap/compare/v4.0.18...v4.0.22)
    
    ---
    updated-dependencies:
    - dependency-name: clap
      dependency-type: direct:production
      update-type: version-update:semver-patch
    ...
    
    Signed-off-by: dependabot[bot] <support@github.com>
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    
    * Bump num_cpus from 1.13.1 to 1.14.0 (#1203)
    
    * wait for state deactivation on replica update failure (#1200)
    
    * wait for state deactivation on replica update failure
    
    * review fixes
    
    * upd version to 0.11.2
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: erare-humanum <116254494+erare-humanum@users.noreply.github.com>
    Co-authored-by: Ivan Pleshkov <pleshkov.ivan@gmail.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index ef388e20d..948a43d25 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -193,6 +193,14 @@ impl UpdateCollectionOperation {
         }
     }
 
+    // Returns `true` if there are replica changes associated with this operation
+    pub fn have_replica_changes(&self) -> bool {
+        self.shard_replica_changes
+            .as_ref()
+            .map(|changes| !changes.is_empty())
+            .unwrap_or(false)
+    }
+
     pub fn take_shard_replica_changes(&mut self) -> Option<Vec<replica_set::Change>> {
         self.shard_replica_changes.take()
     }

commit 8cd4fe15ed4fe0749edcb8e8a2f481c809a7618e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Sun Jan 22 01:16:55 2023 +0100

    Init collection from (#1364)
    
    * WIP
    
    * WIP: add shards selection
    
    * fmt
    
    * WIP: collection init from other collection
    
    * fmt
    
    * fix bugs
    
    * add collection write lock + use collection manager runtime instead of search runtime
    
    * fmt
    
    * integration test
    
    * better names ?
    
    * payload indexes transfer

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 948a43d25..14ec95521 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -85,6 +85,13 @@ impl From<RenameAlias> for AliasOperations {
     }
 }
 
+/// Operation for creating new collection and (optionally) specify index params
+#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[serde(rename_all = "snake_case")]
+pub struct InitFrom {
+    pub collection: CollectionId,
+}
+
 /// Operation for creating new collection and (optionally) specify index params
 #[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
@@ -120,6 +127,9 @@ pub struct CreateCollection {
     pub wal_config: Option<WalConfigDiff>,
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
     pub optimizers_config: Option<OptimizersConfigDiff>,
+    /// Specify other collection to copy data from.
+    #[serde(default)]
+    pub init_from: Option<InitFrom>,
 }
 
 /// Operation for creating new collection and (optionally) specify index params

commit 90c6b784f5804e13c82f2e9fb1f223bc5996e7e7
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jan 30 14:58:34 2023 +0100

    add init state to replica set (#1404)
    
    * add init state to replica set
    
    * update openapi
    
    * disallow activating shard from non-initialize state
    
    * fmt
    
    * remove useless operation confirm on collection creation
    
    * clippy fixes
    
    * fix test

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 14ec95521..3dd85516a 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -256,6 +256,13 @@ pub struct SetShardReplicaState {
     pub peer_id: PeerId,
     /// If `Active` then the replica is up to date and can receive updates and answer requests
     pub state: ReplicaState,
+    /// If `Some` then check that the replica is in this state before changing it
+    /// If `None` then the replica can be in any state
+    /// This is useful for example when we want to make sure
+    /// we only make transition from `Initializing` to `Active`, and not from `Dead` to `Active`.
+    /// If `from_state` does not match the current state of the replica, then the operation will be dismissed.
+    #[serde(default)]
+    pub from_state: Option<ReplicaState>,
 }
 
 /// Enumeration of all possible collection update operations

commit c969aa7e5b3f787ab72602582afa9cc8098a5cdb
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Feb 28 10:20:32 2023 +0100

    allow to use optimizer_config rest api, to avoid confusion with param name in collection_info api (#1507)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 3dd85516a..d41929a76 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -126,6 +126,7 @@ pub struct CreateCollection {
     /// Custom params for WAL. If none - values from service configuration file are used.
     pub wal_config: Option<WalConfigDiff>,
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
+    #[serde(alias = "optimizer_config")]
     pub optimizers_config: Option<OptimizersConfigDiff>,
     /// Specify other collection to copy data from.
     #[serde(default)]
@@ -169,6 +170,7 @@ impl CreateCollectionOperation {
 pub struct UpdateCollection {
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
     /// This operation is blocking, it will only proceed ones all current optimizations are complete
+    #[serde(alias = "optimizer_config")]
     pub optimizers_config: Option<OptimizersConfigDiff>, // ToDo: Allow updates for other configuration params as well
     /// Collection base params.  If none - values from service configuration file are used.
     pub params: Option<CollectionParamsDiff>,

commit 128e49fcc3633e361df33818de6cca0aab95da10
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Fri Mar 3 20:46:17 2023 +0400

    integrate quantized data to storages (#1311)
    
    * integrate quantized data to storages
    
    * revert gitignore
    
    * are you happy clippy
    
    * quantize in optimizer
    
    * provide flag
    
    * fix segfault
    
    * skip quantization flag, update scores
    
    * use quantization flag
    
    * are you happy fmt
    
    * use quantization flag
    
    * quantized search test
    
    * are you happy fmt
    
    * refactor test, refactor scorer choosing
    
    * are you happy fmt
    
    * run quantization on segment builder
    
    * decrease testing parameters
    
    * simplify segment
    
    * update version
    
    * remove use_quantization flag
    
    * provide quantization config
    
    * quantization version up
    
    * euclid dist
    
    * add euclid test
    
    * saveload
    
    * fix initialization bugs
    
    * quantization lib version up
    
    * fix arm build
    
    * refactor scorer selecting
    
    * quant lib version up
    
    * are you happy fmt
    
    * are you happy fmt
    
    * are you happy clippy
    
    * add save/load test for simple storage
    
    * add comments
    
    * quantiles
    
    * quantization mmap
    
    * remove f32
    
    * mmap test
    
    * fix mmap slice
    
    * fix mmap test
    
    * use chunks for quantization storage
    
    * fix build
    
    * are you happy fmt
    
    * update quantization library
    
    * update quantization lib
    
    * update quantization lib
    
    * integrate api changes
    
    * are you happy fmt
    
    * change quantization api
    
    * additional checks in tests
    
    * update quantization version
    
    * fix unit tests
    
    * add quantization to storage config
    
    * use quantization for all cardinality search cases
    
    * Integrate quantization suggestions 2 (#1520)
    
    * review api
    
    * wip: refactor quantization integrations
    
    * wip: refactor quantization integrations
    
    * wip: fmt
    
    * include quantization into snapshot
    
    * fmt
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index d41929a76..1f68ee11a 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -7,6 +7,7 @@ use collection::shards::shard::{PeerId, ShardId};
 use collection::shards::transfer::shard_transfer::{ShardTransfer, ShardTransferKey};
 use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
+use segment::types::QuantizationConfig;
 use serde::{Deserialize, Serialize};
 
 use crate::content_manager::shard_distribution::ShardDistributionProposal;
@@ -131,6 +132,10 @@ pub struct CreateCollection {
     /// Specify other collection to copy data from.
     #[serde(default)]
     pub init_from: Option<InitFrom>,
+    /// Quantization parameters. If none - quantization is disabled.
+    #[serde(default)]
+    #[serde(alias = "quantization")]
+    pub quantization_config: Option<QuantizationConfig>,
 }
 
 /// Operation for creating new collection and (optionally) specify index params

commit d7379f07067b928eed7c5b6c878c2d075517abb1
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Mar 7 17:03:01 2023 +0100

    Fix recover snapshot peer (#1534)
    
    * allow to recover distributed snapshot on local intance + allow recover non-existing collections
    
    * async snapshot recovery
    
    * fix tests
    
    * be polite earlier

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 1f68ee11a..55ad88366 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,3 +1,4 @@
+use collection::config::CollectionConfig;
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
 };
@@ -284,3 +285,22 @@ pub enum CollectionMetaOperations {
     SetShardReplicaState(SetShardReplicaState),
     Nop { token: usize }, // Empty operation
 }
+
+/// Use config of the existing collection to generate a create collection operation
+/// for the new collection
+impl From<CollectionConfig> for CreateCollection {
+    fn from(value: CollectionConfig) -> Self {
+        Self {
+            vectors: value.params.vectors,
+            shard_number: Some(value.params.shard_number.get()),
+            replication_factor: Some(value.params.replication_factor.get()),
+            write_consistency_factor: Some(value.params.write_consistency_factor.get()),
+            on_disk_payload: Some(value.params.on_disk_payload),
+            hnsw_config: Some(value.hnsw_config.into()),
+            wal_config: Some(value.wal_config.into()),
+            optimizers_config: Some(value.optimizer_config.into()),
+            init_from: None,
+            quantization_config: value.quantization_config,
+        }
+    }
+}

commit f0f92292e022e3ddfde82f96d393efc8b6addcf9
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Mon Apr 3 11:43:55 2023 +0400

    Add Actix and config validation (#1463)
    
    * actix validation
    
    * add check for memmap/indexing_threshold
    
    * fix actix json settings
    
    * Validate settings configuration on start, print pretty warnings on fail
    
    * Add more validation rules for settings and nested types
    
    * Move shared validation logic into collection/operations
    
    * Show validation warning in log when loading some internal configs
    
    * Show prettier actix JSON validation errors
    
    * Stubs for pretty handling of query errors, reformat validation errors
    
    * Use crate flatten function, the hard work was already done for us
    
    We don't have to flatten validation errors into their qualified field
    names ourselves because there is a utility function for this.
    
    * Configure actix path validator
    
    * Actix endpoints don't require public
    
    * Extend validation to more actix types
    
    * Validate all remaining actix path and query properties
    
    * Rephrase range validation messages to clearly describe they're inclusive
    
    * Validate all query params to respond with pretty deserialize errors
    
    * Nicely format JSON payload deserialize error responses
    
    * Improve error reporting for upsert point batches
    
    * Add basic validation test that checks a path, query and payload value
    
    * Add some validation constraints
    
    * Add simple validation error render test
    
    * Update Cargo.lock
    
    ---------
    
    Co-authored-by: timvisee <tim+github@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 55ad88366..53ca41b7a 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -10,6 +10,7 @@ use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
 use segment::types::QuantizationConfig;
 use serde::{Deserialize, Serialize};
+use validator::Validate;
 
 use crate::content_manager::shard_distribution::ShardDistributionProposal;
 
@@ -95,7 +96,7 @@ pub struct InitFrom {
 }
 
 /// Operation for creating new collection and (optionally) specify index params
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, Validate, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct CreateCollection {
     /// Vector data config.
@@ -124,11 +125,14 @@ pub struct CreateCollection {
     #[serde(default)]
     pub on_disk_payload: Option<bool>,
     /// Custom params for HNSW index. If none - values from service configuration file are used.
+    #[validate]
     pub hnsw_config: Option<HnswConfigDiff>,
     /// Custom params for WAL. If none - values from service configuration file are used.
+    #[validate]
     pub wal_config: Option<WalConfigDiff>,
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
     #[serde(alias = "optimizer_config")]
+    #[validate]
     pub optimizers_config: Option<OptimizersConfigDiff>,
     /// Specify other collection to copy data from.
     #[serde(default)]
@@ -171,7 +175,7 @@ impl CreateCollectionOperation {
 }
 
 /// Operation for updating parameters of the existing collection
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, Validate, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollection {
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
@@ -235,7 +239,7 @@ impl UpdateCollectionOperation {
 /// Operation for performing changes of collection aliases.
 /// Alias changes are atomic, meaning that no collection modifications can happen between
 /// alias operations.
-#[derive(Debug, Deserialize, Serialize, JsonSchema, PartialEq, Eq, Hash, Clone)]
+#[derive(Debug, Deserialize, Serialize, JsonSchema, Validate, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct ChangeAliasesOperation {
     pub actions: Vec<AliasOperations>,

commit e8002b27813b472176ef18b887898eab02f3d974
Author: Tim Vise <tim+github@visee.me>
Date:   Mon Apr 10 16:02:11 2023 +0200

    Verify quantization configuration on collection creation (#1681)
    
    * Verify quantization configuration on collection creation
    
    * Update OpenAPI specification
    
    * Update range in doc to match validation definition
    
    * Update OpenAPI specification

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 53ca41b7a..96de1a20d 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -140,6 +140,7 @@ pub struct CreateCollection {
     /// Quantization parameters. If none - quantization is disabled.
     #[serde(default)]
     #[serde(alias = "quantization")]
+    #[validate]
     pub quantization_config: Option<QuantizationConfig>,
 }
 

commit 66ba8f17af136554e5a5a707c31d8d1fd801b70c
Author: Tim Vise <tim+github@visee.me>
Date:   Mon Apr 10 17:16:56 2023 +0200

    Add vector specific HNSW configuration (#1675)
    
    * Validate VectorConfig/VectorParams, remove obsolete validation
    
    * Add HNSW config diff to vector parameters
    
    * Validate params in collection config
    
    * Add HNSW config to segment vector data config
    
    * Add VectorsConfig params iterator for more elegant conversions
    
    * Prefer vector HNSW config over collection config for building HNSW index
    
    * Base segment vector param HNSW config on collection config
    
    * General improvements
    
    * Rewrite HNSW ef_construct extract function to also consider vector configs
    
    * Update OpenAPI specification
    
    * Add test to check if vector specific HNSW config is persisted
    
    * review changes
    
    * review changes
    
    * Regenerate gRPC docs
    
    * Fix test on Windows
    
    * Regenerate OpenAPI specification
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 96de1a20d..626c69f2d 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -101,6 +101,7 @@ pub struct InitFrom {
 pub struct CreateCollection {
     /// Vector data config.
     /// It is possible to provide one config for single vector mode and list of configs for multiple vectors mode.
+    #[validate]
     pub vectors: VectorsConfig,
     /// Number of shards in collection.
     /// Default is 1 for standalone, otherwise equal to the number of nodes

commit 868626f409a7bcc4e2537dcf69b9b4bbe2c10208
Author: Tim Vise <tim+github@visee.me>
Date:   Mon Apr 10 21:39:43 2023 +0200

    Add vector specific quantization configuration (#1680)
    
    * Add QuantizationConfigDiff type
    
    * Add quantization config diff to vector parameters
    
    * Prefer vector config over collection config for quantization
    
    * Update OpenAPI specification
    
    * Validate quantization configuration quantile in 0.5-1.0 range
    
    As per https://github.com/qdrant/qdrant/pull/1681
    
    * Add test if check if vector specific quantization config is persisted
    
    * Alias quantization to quantization_config in vector parameters
    
    * Remove quantization config diff, use full vector specific config instead
    
    * Regenerate OpenAPI specification and gRPC docs
    
    * Fix compilation error
    
    * Add error handling to quantization config conversions
    
    * Fix quantization integration test, make HNSW test stricter

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 626c69f2d..acf507e2a 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -139,8 +139,7 @@ pub struct CreateCollection {
     #[serde(default)]
     pub init_from: Option<InitFrom>,
     /// Quantization parameters. If none - quantization is disabled.
-    #[serde(default)]
-    #[serde(alias = "quantization")]
+    #[serde(default, alias = "quantization")]
     #[validate]
     pub quantization_config: Option<QuantizationConfig>,
 }

commit 7baa296d8ba5e3bf7d3cdcbdc127c60d0e3894a5
Author: Tim Vise <tim+github@visee.me>
Date:   Tue Jul 18 14:32:13 2023 +0200

    Update collection: HNSW config (#2083)
    
    * Add field to REST collection update to change HNSW config
    
    * Add field to gRPC collection update to change HNSW config
    
    * Update OpenAPI specification
    
    * Update gRPC docs
    
    * Improve optimizer filtering for excluded segment IDs
    
    * Add config mismatch optimizer detecting basic HNSW mismatches
    
    * Trigger optimizers when changing collection HNSW config
    
    * Make config mismatch optimizer aware of vector specific HNSW configs
    
    * Extract triggering optimizers after collection update into function
    
    * Add config mismatch optimizer test for changing HNSW config
    
    * Simplify config mismatch optimizer test
    
    * Add config mismatch optimizer test for vector specific HNSW change
    
    * Reformat
    
    * Update collection HNSW params in integration test
    
    * Validate HNSW config in collection update gRPC endpoint
    
    * Improve description of update collection request
    
    * Do not require to rebuild HNSW when on_disk flag changes
    
    Ref: https://github.com/qdrant/qdrant/pull/2083#discussion_r1231002072
    
    * Do rebuild segment with on_disk change
    
    * Trigger optimizers in parallel
    
    * Recreate optimizers only once on collection update
    
    * Reformat
    
    * Fix incorrect usage of self
    
    * Fix deadlock in collection state config update
    
    * Also rebuild index on full scan threshold change
    
    * decompose worst_segment condition check
    
    * review refactor
    
    * Update lib/storage/src/content_manager/collection_meta_ops.rs
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    
    * Update lib/api/src/grpc/proto/collections.proto
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    
    * upd grpc docs
    
    * upd grpc docs
    
    * update openapi
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index acf507e2a..cca8a6343 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -179,12 +179,15 @@ impl CreateCollectionOperation {
 #[derive(Debug, Deserialize, Serialize, JsonSchema, Validate, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollection {
-    /// Custom params for Optimizers.  If none - values from service configuration file are used.
-    /// This operation is blocking, it will only proceed ones all current optimizations are complete
+    /// Custom params for Optimizers.  If none - it is left unchanged.
+    /// This operation is blocking, it will only proceed once all current optimizations are complete
     #[serde(alias = "optimizer_config")]
-    pub optimizers_config: Option<OptimizersConfigDiff>, // ToDo: Allow updates for other configuration params as well
-    /// Collection base params.  If none - values from service configuration file are used.
+    pub optimizers_config: Option<OptimizersConfigDiff>, // TODO: Allow updates for other configuration params as well
+    /// Collection base params. If none - it is left unchanged.
     pub params: Option<CollectionParamsDiff>,
+    /// HNSW parameters to update for the collection index. If none - it is left unchanged.
+    #[validate]
+    pub hnsw_config: Option<HnswConfigDiff>,
 }
 
 /// Operation for updating parameters of the existing collection
@@ -203,6 +206,7 @@ impl UpdateCollectionOperation {
             update_collection: UpdateCollection {
                 optimizers_config: None,
                 params: None,
+                hnsw_config: None,
             },
             shard_replica_changes: None,
         }

commit 482301cd005fe3f6809fc3503cc4023e106328e8
Author: Tim Vise <tim+github@visee.me>
Date:   Tue Jul 25 12:19:59 2023 +0200

    Update collection: vector HNSW config (#2087)
    
    * Add update vector config type
    
    * Add mutable getter to update vector config
    
    * Add update vector config to update collection REST operation, reorder
    
    * Add logic to update vector HNSW in collection
    
    * Update OpenAPI specification
    
    * If HNSW diff is empty, consider it as unset
    
    * Update descriptions to clarify an empty HNSW diff unsets
    
    * Make new vector HNSW diff update existing diff
    
    This means that the existing vector HNSW diff is kept intact. Specified
    fields are updated in the existing diff. An empty HNSW diff object may
    be provided to unset the diff.
    
    * Add update vector config to update collection gRPC operation
    
    * Update gRPC docs
    
    * Use vector specific HNSW config in integration test
    
    * Extract & improve gRPC type conversions, fix collection update with None
    
    * Validate vector specific HNSW config in collection update gRPC endpoint
    
    * Explicitly test we do not rebuild on on_disk change
    
    * Use new method to recreate optimizers
    
    * Don't test on_disk change anymore
    
    * Reuse collection write lock to save, do not relock
    
    * Fix invalid update collection request body in OpenAPI test
    
    * Simplify update collection test
    
    * Add update collection test for HNSW parameters
    
    * Extract vector param update logic into local functions
    
    * Reformat
    
    * Transform UpdateVectorParams into VectorParamsDiff
    
    * Transform UpdateVectorsConfig into VectorsConfigDiff
    
    * Combine serde attributes
    
    * Make HNSW diff empty check generic over DiffConfig types
    
    * Move DiffConfig implementation
    
    * Fix typo

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index cca8a6343..a6f18878e 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -2,7 +2,7 @@ use collection::config::CollectionConfig;
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
 };
-use collection::operations::types::VectorsConfig;
+use collection::operations::types::{VectorsConfig, VectorsConfigDiff};
 use collection::shards::replica_set::ReplicaState;
 use collection::shards::shard::{PeerId, ShardId};
 use collection::shards::transfer::shard_transfer::{ShardTransfer, ShardTransferKey};
@@ -179,6 +179,10 @@ impl CreateCollectionOperation {
 #[derive(Debug, Deserialize, Serialize, JsonSchema, Validate, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollection {
+    /// Vector data parameters to update.
+    /// It is possible to provide one config for single vector mode and list of configs for multiple vectors mode.
+    #[validate]
+    pub vectors: Option<VectorsConfigDiff>,
     /// Custom params for Optimizers.  If none - it is left unchanged.
     /// This operation is blocking, it will only proceed once all current optimizations are complete
     #[serde(alias = "optimizer_config")]
@@ -204,9 +208,10 @@ impl UpdateCollectionOperation {
         Self {
             collection_name,
             update_collection: UpdateCollection {
-                optimizers_config: None,
-                params: None,
+                vectors: None,
                 hnsw_config: None,
+                params: None,
+                optimizers_config: None,
             },
             shard_replica_changes: None,
         }

commit 029c21e3f7c91faeb5e713f195fbc1d135504494
Author: Tim Vise <tim+github@visee.me>
Date:   Fri Jul 28 19:48:08 2023 +0200

    Update collection: quantization config (#2090)
    
    * Reoptimize segments on quantization mismatch
    
    * Add collection quantization params to collection update REST endpoint
    
    * Do not require rebuild of quantization for on_disk change
    
    * Add collection quantization params to collection update gRPC endpoint
    
    * Add option to update vector specific quantization config to REST API
    
    * Add option to update vector specific quantization config to gRPC API
    
    * Update OpenAPI and gRPC specification
    
    * Fix quantization mismatch detecting not working as expected
    
    * Fix config mismatch optimizer not using vector specific quantization
    
    * Add unit test for quantization in config mismatch optimizer
    
    * Add some quantization params to collection update integration test
    
    * Reformat
    
    * Apply suggestions from code review
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    
    * Remove if-statement, simply return
    
    * Move quantization params in named vector in integration test
    
    * Test updating quantization params in multivec integration test
    
    * Fix gRPC docs
    
    * Fix quantization rebuild on changing enabled state on indexed segment
    
    * allow disabling quantization config
    
    * fmt
    
    * clippy
    
    * compare all params of the quantization for rebuild
    
    * explicitly use params on update
    
    * test for disabling quantization
    
    ---------
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index a6f18878e..fb78d7da3 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,6 +1,7 @@
 use collection::config::CollectionConfig;
 use collection::operations::config_diff::{
-    CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, WalConfigDiff,
+    CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, QuantizationConfigDiff,
+    WalConfigDiff,
 };
 use collection::operations::types::{VectorsConfig, VectorsConfigDiff};
 use collection::shards::replica_set::ReplicaState;
@@ -192,6 +193,10 @@ pub struct UpdateCollection {
     /// HNSW parameters to update for the collection index. If none - it is left unchanged.
     #[validate]
     pub hnsw_config: Option<HnswConfigDiff>,
+    /// Quantization parameters to update. If none - it is left unchanged.
+    #[serde(default, alias = "quantization")]
+    #[validate]
+    pub quantization_config: Option<QuantizationConfigDiff>,
 }
 
 /// Operation for updating parameters of the existing collection
@@ -212,6 +217,7 @@ impl UpdateCollectionOperation {
                 hnsw_config: None,
                 params: None,
                 optimizers_config: None,
+                quantization_config: None,
             },
             shard_replica_changes: None,
         }

commit 6bdd1e5c11763df9c896dde0386a114b28d13d70
Author: Tim Vise <tim+github@visee.me>
Date:   Thu Oct 5 17:39:12 2023 +0200

    Improve description of vector parameters in update collection REST call (#2765)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index fb78d7da3..f4d79bf31 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -180,8 +180,8 @@ impl CreateCollectionOperation {
 #[derive(Debug, Deserialize, Serialize, JsonSchema, Validate, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
 pub struct UpdateCollection {
-    /// Vector data parameters to update.
-    /// It is possible to provide one config for single vector mode and list of configs for multiple vectors mode.
+    /// Map of vector data parameters to update for each named vector.
+    /// To update parameters in a collection having a single unnamed vector, use an empty string as name.
     #[validate]
     pub vectors: Option<VectorsConfigDiff>,
     /// Custom params for Optimizers.  If none - it is left unchanged.

commit 849cd8e8ec12c77e4d0875a96339945a07ae4618
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Oct 16 14:23:37 2023 +0200

    Shard key - create collection (#2810)
    
    * introduce sharding strategy configuration into collection config
    
    * enable custom sharding method config on collection creation
    
    * review fixes
    
    * Use `debug_assert_eq` for equality check
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index f4d79bf31..c6c94c8ac 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,4 +1,4 @@
-use collection::config::CollectionConfig;
+use collection::config::{CollectionConfig, ShardingMethod};
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, QuantizationConfigDiff,
     WalConfigDiff,
@@ -104,21 +104,34 @@ pub struct CreateCollection {
     /// It is possible to provide one config for single vector mode and list of configs for multiple vectors mode.
     #[validate]
     pub vectors: VectorsConfig,
+    /// For auto sharding:
     /// Number of shards in collection.
-    /// Default is 1 for standalone, otherwise equal to the number of nodes
-    /// Minimum is 1
+    ///  - Default is 1 for standalone, otherwise equal to the number of nodes
+    ///  - Minimum is 1
+    /// For custom sharding:
+    /// Number of shards in collection per shard group.
+    ///  - Default is 1, meaning that each shard key will be mapped to a single shard
+    ///  - Minimum is 1
     #[serde(default)]
+    #[validate(range(min = 1))]
     pub shard_number: Option<u32>,
+    /// Sharding method
+    /// Default is Auto - points are distributed across all available shards
+    /// Custom - points are distributed across shards according to shard key
+    #[serde(default)]
+    pub sharding_method: Option<ShardingMethod>,
     /// Number of shards replicas.
     /// Default is 1
     /// Minimum is 1
     #[serde(default)]
+    #[validate(range(min = 1))]
     pub replication_factor: Option<u32>,
     /// Defines how many replicas should apply the operation for us to consider it successful.
     /// Increasing this number will make the collection more resilient to inconsistencies, but will
     /// also make it fail if not enough replicas are available.
     /// Does not have any performance impact.
     #[serde(default)]
+    #[validate(range(min = 1))]
     pub write_consistency_factor: Option<u32>,
     /// If true - point's payload will not be stored in memory.
     /// It will be read from the disk every time it is requested.
@@ -313,6 +326,7 @@ impl From<CollectionConfig> for CreateCollection {
         Self {
             vectors: value.params.vectors,
             shard_number: Some(value.params.shard_number.get()),
+            sharding_method: value.params.sharding_method,
             replication_factor: Some(value.params.replication_factor.get()),
             write_consistency_factor: Some(value.params.write_consistency_factor.get()),
             on_disk_payload: Some(value.params.on_disk_payload),

commit 5bdf5e4bfe5ca2de32aff603a755ad263d5eca56
Author: Tim Vise <tim+github@visee.me>
Date:   Mon Oct 30 12:44:39 2023 +0100

    Shard snapshot transfer integration (#2467)
    
    * Clone inside blocks
    
    * Add shard transfer method to distinguish between batching and snapshots
    
    * Add stub method to drive snapshot transfer
    
    * Store remote shard in forward proxy, merge unproxy methods
    
    * On snapshot shard transfer, create a shard snapshot
    
    * Unify logic for unproxifying forward and queue proxy
    
    * Error snapshot transfer if shard is not a queue proxy
    
    * Add remote shard function to request remote HTTP port
    
    * Handle all specific shard types when proxifying
    
    * Allow queue proxy for some shard holder snapshot methods
    
    * Bring local and remote shard snapshot transfer URLs into transfer logic
    
    * Expose optional shard transfer method parameter in REST and gRPC API
    
    * Expose shard transfer method in list of active transfers
    
    * Fix off-by-one error in queue proxy shard batch transfer logic
    
    * Do not set max ack version for WAL twice, already set when finalizing
    
    * Merge comment for two similar calls
    
    * Use reqwest client to transfer and recover shard snapshot on remote
    
    Using the reqwest client should be temporary. We better switch to a gRPC
    call here eventually to use our existing channels. That way we don't
    require an extra HTTP client (and dependency) just for this.
    
    * Send queue proxy updates to remote when shard is transferred
    
    * On shard queue transfer, set max WAL ack to last transferred
    
    * Add safe queue proxy destructor, skip destructing in error
    
    This adds a finalize method to safely destruct a queue proxy shard. It
    ensures that all remaining updates are transferred to the remote, and
    that the max acknowledged version for our WAL is released. Only then is
    the queue proxy shard destructed unwrapping the inner local shard.
    
    Our unproxify logic now ensures that the queue proxy shard remains if
    transferring the updates fails.
    
    * Clean up method driving shard snapshot transfer a bit
    
    * Change default shard transfer method to stream records
    
    This changes the default transfer method to stream records rather than
    using a snaphsot transfer. We can switch this once snapshot transfer is
    fully integrated.
    
    * Improve error handling, don't panic but return proper error
    
    * Do not unwrap in type conversions
    
    * Update OpenAPI and gRPC specification
    
    * Resolve and remove some TODOs
    
    * During shard snapshot transfer, use REST port from config
    
    * Always release max acknowledged WAL version on queue proxy finalize
    
    * Rework queue unproxying, transform into forward proxy to handle errors
    
    When a queue or forward proxy shard needs to be unproxified into a local
    shard again we typically don't have room to handle errors. A queue proxy
    shard may error if it fails to send updates to the remote shard, while a
    forward proxy does not fail at all when transforming.
    
    We now transfer queued updates before a shard is unproxified. This
    allows for proper error handling. After everything is transferred the
    shard is transformed into a forward proxy which can eventually be safely
    unproxified later.
    
    * Add trace logging for transferring queue proxy updates in batch
    
    * Simplify snapshot method conversion from gRPC
    
    * Remove remote shard parameter
    
    * Add safe guard to queue proxy handler, panic in debug if not finalized
    
    * Improve safety and architecture of queue proxy shard
    
    Switch from an explicit finalized flag to an outer-inner architecture.
    This improves the interface and robustness of the type.
    
    * Do not panic on drop if already unwinding
    
    * Make REST port interface in channel service for local node explicitly
    
    * Recover shard on remote over gRPC, remove reqwest client
    
    * Use shard transfer priority for shard snapshot recovery
    
    * Remove obsolete comment
    
    * Simplify qualified path with use
    
    * Don't construct URLs ourselves as a string, use `parse` and `set_port`
    
    * Use `set_path` when building shard download URL
    
    * Fix error handling in queue to forward proxy transformation
    
    Before, we didn't handle finalization errors properly. If this failed,
    tie shard would be lost.  With this change the queue proxy shard is put
    back.
    
    * Set default shard transfer method to stream records, eliminate panics
    
    * Fix shard snapshot transfer not correctly aborting due to queue proxy
    
    When a shard transfer fails (for any reason), the transfer is aborted.
    If we still have a queue proxy shard it should also be reverted, and
    collected updates should be forgotten. Before this change it would try
    to send all collected updates to the remote, even if the transfer
    failed.
    
    * Review fixes
    
    Co-authored-by: Roman Titov <ffuugoo@users.noreply.github.com>
    
    * Review fixes
    
    Co-authored-by: Roman Titov <ffuugoo@users.noreply.github.com>
    
    * Initiate forward and queue proxy shard in specialized transfer methods
    
    Co-authored-by: Roman Titov <ffuugoo@users.noreply.github.com>
    
    * Add consensus interface to shard transfer, repurpose dispatcher (#2873)
    
    * Add shard transfer consensus interface
    
    * Integrate shard transfer consensus interface into toc and transfer logic
    
    * Repurpose dispatcher for getting consensus into shard transfer
    
    * Derive clone
    
    * Mark consensus as unused for now
    
    * Use custom dispatcher with weak ref to prevent Arc cycle for ToC
    
    * Add comment on why a weak reference is used
    
    * Do exhaustive match in shard unproxy logic
    
    * Restructure match statement, use match if
    
    * When queue proxifying shard, allow forward proxy state if same remote
    
    * Before retrying a shard transfer after error, destruct queue proxy
    
    * Synchronize consensus across all nodes for shard snapshot transfer (#2874)
    
    * Move await consensus commit functions into channel service
    
    * Add shard consensus method to synchronize consensus across all nodes
    
    * Move transfer config, channels and local address into snapshot transfer
    
    * Await other nodes to reach consensus before finalizing shard transfer
    
    * Do not fail right away awaiting consensus if still on older term
    
    Instead, give the node time to reach the same term.
    
    * Fix `await_commit_on_all_peers` not catching peer errors properly
    
    * Change return type of `wait_for_consensus_commit` to `Result`
    
    This is of course more conventional, and automatically sets `must_use`.
    
    * Explicitly note number of peers when awaiting consensus
    
    * Before consensus sync, wait for local shard to reach partial state
    
    * Fix timeout error handling when waiting for replica set state
    
    * Wait for replica set to have remote in partial state instead
    
    * Set `(Partial)Snapshot` states for shard snapshot transfer through consensus (#2881)
    
    * When doing a shard snapshot transfer, set shard to `PartialSnapshot`
    
    * Add shard transfer method to set shard state to partial
    
    It currently uses a naive implementation. Using a custom consensus
    operation to also confirm a transfer is still active will be implemented
    later.
    
    * Add consensus snapshot transfer operation to change shard to partial
    
    The operation `ShardTransferOperations::SnapshotRecovered` is called
    after the shard snapshot is recovered on the remote and it progresses
    the transfer further.
    
    The operation sets the shard state from `PartialSnapshot` to `Partial`
    and ensures the transfer is still active.
    
    * Confirm consensus put shard into partial state, retry 3 times
    
    * Get replica set once
    
    * Add extensive shard snapshot transfer process docs, clean up function
    
    * Fix typo
    
    * Review suggestion
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    
    * Add delay between consensus confirmation retries
    
    * Rename retry timeout to retry delay
    
    ---------
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    
    * On replicate shard, remember specified method
    
    ---------
    
    Co-authored-by: Roman Titov <ffuugoo@users.noreply.github.com>
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index c6c94c8ac..9605ea16f 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -283,6 +283,11 @@ pub struct DeleteCollectionOperation(pub String);
 pub enum ShardTransferOperations {
     Start(ShardTransfer),
     Finish(ShardTransfer),
+    /// Used in `ShardTransferMethod::Snapshot`
+    ///
+    /// Called when the snapshot has successfully been recovered on the remote, brings the transfer
+    /// to the next stage.
+    SnapshotRecovered(ShardTransferKey),
     Abort {
         transfer: ShardTransferKey,
         reason: String,

commit 7f304340a0b067661c12aa73964c1fbb2e7d5f1b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Nov 2 12:27:28 2023 +0100

    Shard key - consensus (#2811)
    
    * wip: implement consensus operations to create and delete shard keys
    
    * Fix typo in variable name
    
    * wip: methods to add shard keys
    
    * fmt
    
    * api for submitting creating and deleting shard keys operations into consensus
    
    * fmt
    
    * apply shard mapping in with the collection state transfer
    
    * handle single-to-cluster transition
    
    * fix api structure and bugs
    
    * fmt
    
    * rename param
    
    * review fixes
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 9605ea16f..37195f90a 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -5,7 +5,7 @@ use collection::operations::config_diff::{
 };
 use collection::operations::types::{VectorsConfig, VectorsConfigDiff};
 use collection::shards::replica_set::ReplicaState;
-use collection::shards::shard::{PeerId, ShardId};
+use collection::shards::shard::{PeerId, ShardId, ShardKey, ShardsPlacement};
 use collection::shards::transfer::shard_transfer::{ShardTransfer, ShardTransferKey};
 use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
@@ -311,6 +311,19 @@ pub struct SetShardReplicaState {
     pub from_state: Option<ReplicaState>,
 }
 
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+pub struct CreateShardKey {
+    pub collection_name: String,
+    pub shard_key: ShardKey,
+    pub placement: ShardsPlacement,
+}
+
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+pub struct DropShardKey {
+    pub collection_name: String,
+    pub shard_key: ShardKey,
+}
+
 /// Enumeration of all possible collection update operations
 #[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
@@ -321,6 +334,8 @@ pub enum CollectionMetaOperations {
     ChangeAliases(ChangeAliasesOperation),
     TransferShard(CollectionId, ShardTransferOperations),
     SetShardReplicaState(SetShardReplicaState),
+    CreateShardKey(CreateShardKey),
+    DropShardKey(DropShardKey),
     Nop { token: usize }, // Empty operation
 }
 

commit 816b5a7448c7f1e0d81c99e5a31219d00ece6fe5
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Nov 9 15:06:02 2023 +0100

    Shard key routing for update requests (#2909)
    
    * add shard_key into output data structures for points
    
    * fmt
    
    * add shard selector for point update operations
    
    * fix creating index without sharding
    
    * Merge serde attributes
    
    * Code review changes
    
    * review fixes
    
    * upd openapi
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 37195f90a..711da3de4 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -5,11 +5,11 @@ use collection::operations::config_diff::{
 };
 use collection::operations::types::{VectorsConfig, VectorsConfigDiff};
 use collection::shards::replica_set::ReplicaState;
-use collection::shards::shard::{PeerId, ShardId, ShardKey, ShardsPlacement};
+use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
 use collection::shards::transfer::shard_transfer::{ShardTransfer, ShardTransferKey};
 use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
-use segment::types::QuantizationConfig;
+use segment::types::{QuantizationConfig, ShardKey};
 use serde::{Deserialize, Serialize};
 use validator::Validate;
 

commit d3aada0e9644975b94409fd79c94e990643614a0
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Fri Nov 10 17:23:30 2023 +0100

    Shard key index consistency (#2938)
    
    * WIP: collection-level storage for payload indexe scheme
    
    * introduce consensus-level operation for creating payload index
    
    * make operation_id optional in the UpdateResult
    
    * set payload index in newly created shards
    
    * upd api definitions
    
    * include payload index schema into collection consensus state
    
    * include payload index schema into shard snapshot
    
    * review fixes

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 711da3de4..aeea006e2 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -9,7 +9,7 @@ use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
 use collection::shards::transfer::shard_transfer::{ShardTransfer, ShardTransferKey};
 use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
-use segment::types::{QuantizationConfig, ShardKey};
+use segment::types::{PayloadFieldSchema, PayloadKeyType, QuantizationConfig, ShardKey};
 use serde::{Deserialize, Serialize};
 use validator::Validate;
 
@@ -324,6 +324,19 @@ pub struct DropShardKey {
     pub shard_key: ShardKey,
 }
 
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+pub struct CreatePayloadIndex {
+    pub collection_name: String,
+    pub field_name: PayloadKeyType,
+    pub field_schema: PayloadFieldSchema,
+}
+
+#[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
+pub struct DropPayloadIndex {
+    pub collection_name: String,
+    pub field_name: PayloadKeyType,
+}
+
 /// Enumeration of all possible collection update operations
 #[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 #[serde(rename_all = "snake_case")]
@@ -336,6 +349,8 @@ pub enum CollectionMetaOperations {
     SetShardReplicaState(SetShardReplicaState),
     CreateShardKey(CreateShardKey),
     DropShardKey(DropShardKey),
+    CreatePayloadIndex(CreatePayloadIndex),
+    DropPayloadIndex(DropPayloadIndex),
     Nop { token: usize }, // Empty operation
 }
 

commit 9b177d56320c9b65884c3e1af81d05cc3c2f34cb
Author: Tim Vise <tim+github@visee.me>
Date:   Fri Nov 17 14:23:35 2023 +0100

    Refactor shard transfer logic (#2991)
    
    * Extract shard transfer implementations into modules
    
    * Extract shard transfer helpers into module
    
    * Extract functions driving shard transfer into module
    
    * Move implementation below struct definition

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index aeea006e2..ea436f1b7 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -6,7 +6,7 @@ use collection::operations::config_diff::{
 use collection::operations::types::{VectorsConfig, VectorsConfigDiff};
 use collection::shards::replica_set::ReplicaState;
 use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
-use collection::shards::transfer::shard_transfer::{ShardTransfer, ShardTransferKey};
+use collection::shards::transfer::{ShardTransfer, ShardTransferKey};
 use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
 use segment::types::{PayloadFieldSchema, PayloadKeyType, QuantizationConfig, ShardKey};

commit 3fc1f9656418995d21d156bd83f6f3611a99ee96
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Fri Dec 1 13:10:58 2023 +0100

    Sparse index segment and collection config (#2802)
    
    * quantization storage as separate entity
    
    sparse index try to extend segment types
    
    fix build
    
    fix async scorer
    
    codespell
    
    update openapi
    
    update vector index
    
    remove code duplications
    
    more fixes
    
    more fixes
    
    fix build
    
    fix deserialization test
    
    remove transform_into
    
    are you happy clippy
    
    update openapi
    
    update openapi
    
    are you happy clippy
    
    fix build
    
    optional serialize
    
    more defaults
    
    update openapi
    
    fix comments
    
    generic transpose_map_into_named_vector
    
    rename fields in tests
    
    remove obsolete parts
    
    only named sparse config
    
    VectorStruct without unnamed sparse
    
    NamedVectorStruct without unnamed sparse
    
    remove obsolete test
    
    update openapi
    
    mmap index
    
    revert preprocess function
    
    are you happy fmt
    
    update openapi
    
    fix build
    
    fix tests
    
    are you happy fmt
    
    fix for client generation
    
    fix sparse segment creation
    
    fix basic sparse test
    
    fix conflicts
    
    remove obsolete convertion
    
    fix build
    
    config diffs
    
    update openapi
    
    review remarks
    
    update openapi
    
    fix batch upsert
    
    add failing test showing bad ids matching
    
    fix sparse vector insertion
    
    remove on_disk flag
    
    update openapi
    
    revert debug assert
    
    simplify conversions
    
    update openapi
    
    remove on disk storage flag
    
    update openapi
    
    default for vector config
    
    update openapi comment
    
    remove diffs
    
    update openapi
    
    * enable consensus test
    
    * add comment
    
    * update openapi

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index ea436f1b7..3fe15a57a 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,9 +1,13 @@
+use std::collections::BTreeMap;
+
 use collection::config::{CollectionConfig, ShardingMethod};
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, QuantizationConfigDiff,
     WalConfigDiff,
 };
-use collection::operations::types::{VectorsConfig, VectorsConfigDiff};
+use collection::operations::types::{
+    SparseVectorParams, SparseVectorsConfig, VectorsConfig, VectorsConfigDiff,
+};
 use collection::shards::replica_set::ReplicaState;
 use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
 use collection::shards::transfer::{ShardTransfer, ShardTransferKey};
@@ -102,6 +106,7 @@ pub struct InitFrom {
 pub struct CreateCollection {
     /// Vector data config.
     /// It is possible to provide one config for single vector mode and list of configs for multiple vectors mode.
+    #[serde(default)]
     #[validate]
     pub vectors: VectorsConfig,
     /// For auto sharding:
@@ -156,6 +161,9 @@ pub struct CreateCollection {
     #[serde(default, alias = "quantization")]
     #[validate]
     pub quantization_config: Option<QuantizationConfig>,
+    /// Sparse vector data config.
+    #[validate]
+    pub sparse_vectors: Option<BTreeMap<String, SparseVectorParams>>,
 }
 
 /// Operation for creating new collection and (optionally) specify index params
@@ -210,6 +218,9 @@ pub struct UpdateCollection {
     #[serde(default, alias = "quantization")]
     #[validate]
     pub quantization_config: Option<QuantizationConfigDiff>,
+    /// Map of sparse vector data parameters to update for each sparse vector.
+    #[validate]
+    pub sparse_vectors: Option<SparseVectorsConfig>,
 }
 
 /// Operation for updating parameters of the existing collection
@@ -231,6 +242,7 @@ impl UpdateCollectionOperation {
                 params: None,
                 optimizers_config: None,
                 quantization_config: None,
+                sparse_vectors: None,
             },
             shard_replica_changes: None,
         }
@@ -370,6 +382,7 @@ impl From<CollectionConfig> for CreateCollection {
             optimizers_config: Some(value.optimizer_config.into()),
             init_from: None,
             quantization_config: value.quantization_config,
+            sparse_vectors: value.params.sparse_vectors,
         }
     }
 }

commit 78c3797fbfa85db02642b134c78b7feccf107c20
Author: Tim Vise <tim+github@visee.me>
Date:   Thu Feb 29 17:03:21 2024 +0100

    Add consensus operation to restart shard transfer (#3703)
    
    * Add consensus operation to restart shard transfer with different config
    
    * Require shard transfer restart to have a changed configuration
    
    * implement api
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 3fe15a57a..b36a55aae 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -294,6 +294,10 @@ pub struct DeleteCollectionOperation(pub String);
 #[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 pub enum ShardTransferOperations {
     Start(ShardTransfer),
+    /// Restart an existing transfer with a new configuration
+    ///
+    /// If the given transfer is ongoing, it is aborted and restarted with the new configuration.
+    Restart(ShardTransfer),
     Finish(ShardTransfer),
     /// Used in `ShardTransferMethod::Snapshot`
     ///

commit b9f211af465d903a5ff24ba8168e5f69cba80d68
Author: Tim Vise <tim+github@visee.me>
Date:   Thu Feb 29 19:15:35 2024 +0100

    When restarting shard transfer, keep sync if old transfer was sync (#3728)
    
    * When restarting shard transfer, use sync if old or new one had sync set
    
    * refactor restart transfer models
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index b36a55aae..b600377b7 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -10,7 +10,7 @@ use collection::operations::types::{
 };
 use collection::shards::replica_set::ReplicaState;
 use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
-use collection::shards::transfer::{ShardTransfer, ShardTransferKey};
+use collection::shards::transfer::{ShardTransfer, ShardTransferKey, ShardTransferRestart};
 use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
 use segment::types::{PayloadFieldSchema, PayloadKeyType, QuantizationConfig, ShardKey};
@@ -297,7 +297,7 @@ pub enum ShardTransferOperations {
     /// Restart an existing transfer with a new configuration
     ///
     /// If the given transfer is ongoing, it is aborted and restarted with the new configuration.
-    Restart(ShardTransfer),
+    Restart(ShardTransferRestart),
     Finish(ShardTransfer),
     /// Used in `ShardTransferMethod::Snapshot`
     ///

commit 76eed8b000911d66f93a900b589adca5e64cf341
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Mon Mar 4 22:35:03 2024 +0100

    Add `ShardTransferOperations::RecoveryToPartial` (#3757)
    
    * Add `ShardTransferOperations::RecoveryToPartial`
    
    * Add `set_shard_replica_state_impl`...
    
    ...that allows more flexible `from_state` checks when switching replica states
    
    * Switch from either `PartialSnapshot` or `Recovery` into `Partial`...
    
    ...when handling `SnapshotRecovered` and `RecoveryToPartial` operations
    
    * Revert last two commits
    
    * Switch from either `PartialSnapshot` or `Recovery` into `Partial`...
    
    ...when handling `SnapshotRecovered` and `RecoveryToPartial` operations

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index b600377b7..7f832aff4 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -304,6 +304,11 @@ pub enum ShardTransferOperations {
     /// Called when the snapshot has successfully been recovered on the remote, brings the transfer
     /// to the next stage.
     SnapshotRecovered(ShardTransferKey),
+    /// Used in `ShardTransferMethod::Snapshot` and `ShardTransferMethod::WalDelta`
+    ///
+    /// Called when the first stage of the transfer has been successfully finished, brings the
+    /// transfer to the next stage.
+    RecoveryToPartial(ShardTransferKey),
     Abort {
         transfer: ShardTransferKey,
         reason: String,

commit b1e2a298bff4641041b126ff56a85e9beba8bd22
Author: Tim Vise <tim+github@visee.me>
Date:   Tue Mar 19 14:50:27 2024 +0100

    Deprecate SnapshotRecovered consensus call, switch to  RecoveryToPartial (#3848)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 7f832aff4..aa5ee1f06 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -299,6 +299,8 @@ pub enum ShardTransferOperations {
     /// If the given transfer is ongoing, it is aborted and restarted with the new configuration.
     Restart(ShardTransferRestart),
     Finish(ShardTransfer),
+    /// Deprecated since Qdrant 1.9.0, used in Qdrant 1.7.0 and 1.8.0
+    ///
     /// Used in `ShardTransferMethod::Snapshot`
     ///
     /// Called when the snapshot has successfully been recovered on the remote, brings the transfer

commit 572bc7d51e20dd0eb40d5cb0563e1087073a566a
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Fri May 17 16:58:32 2024 +0200

    Add `ReshardingOperation::Start` consensus message (#4238)
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index aa5ee1f06..53bd83bea 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -291,6 +291,15 @@ pub struct ChangeAliasesOperation {
 #[serde(rename_all = "snake_case")]
 pub struct DeleteCollectionOperation(pub String);
 
+#[derive(Clone, Debug, Eq, PartialEq, Hash, Deserialize, Serialize)]
+pub enum ReshardingOperation {
+    Start {
+        peer_id: PeerId,
+        shard_id: ShardId,
+        shard_key: Option<ShardKey>,
+    },
+}
+
 #[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]
 pub enum ShardTransferOperations {
     Start(ShardTransfer),
@@ -368,6 +377,7 @@ pub enum CollectionMetaOperations {
     UpdateCollection(UpdateCollectionOperation),
     DeleteCollection(DeleteCollectionOperation),
     ChangeAliases(ChangeAliasesOperation),
+    Resharding(CollectionId, ReshardingOperation),
     TransferShard(CollectionId, ShardTransferOperations),
     SetShardReplicaState(SetShardReplicaState),
     CreateShardKey(CreateShardKey),

commit 95c7c877711b6342d7f9044a96422908c3378412
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Tue May 28 10:36:41 2024 +0200

    Add `ReshardingOperation::Abort` consensus message (#4290)
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 53bd83bea..b6ccfab8b 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -298,6 +298,12 @@ pub enum ReshardingOperation {
         shard_id: ShardId,
         shard_key: Option<ShardKey>,
     },
+
+    Abort {
+        peer_id: PeerId,
+        shard_id: ShardId,
+        shard_key: Option<ShardKey>,
+    },
 }
 
 #[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]

commit cd6fa6948474010bdb81f82c402a33d80ecf00ee
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Wed May 29 16:58:08 2024 +0200

    Refactor and cleanup resharding consensus operations (#4351)
    
    * Refactor and cleanup resharding consensus operations
    
    * Minor tweaks and cleanup
    
    * Remove `collection/resharding.rs`

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index b6ccfab8b..a8e487938 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -9,6 +9,7 @@ use collection::operations::types::{
     SparseVectorParams, SparseVectorsConfig, VectorsConfig, VectorsConfigDiff,
 };
 use collection::shards::replica_set::ReplicaState;
+use collection::shards::resharding::ReshardingKey;
 use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
 use collection::shards::transfer::{ShardTransfer, ShardTransferKey, ShardTransferRestart};
 use collection::shards::{replica_set, CollectionId};
@@ -293,17 +294,8 @@ pub struct DeleteCollectionOperation(pub String);
 
 #[derive(Clone, Debug, Eq, PartialEq, Hash, Deserialize, Serialize)]
 pub enum ReshardingOperation {
-    Start {
-        peer_id: PeerId,
-        shard_id: ShardId,
-        shard_key: Option<ShardKey>,
-    },
-
-    Abort {
-        peer_id: PeerId,
-        shard_id: ShardId,
-        shard_key: Option<ShardKey>,
-    },
+    Start(ReshardingKey),
+    Abort(ReshardingKey),
 }
 
 #[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]

commit c9b1e50d7215f99b9f15a0936e0305cc4b17a38c
Author: Tim Vise <tim+github@visee.me>
Date:   Thu May 30 16:37:10 2024 +0200

    Initial stubs for resharding driver (#4355)
    
    * Initial stubs for resharding driver
    
    * Add basic steps in resharding driver
    
    * Link Notion document
    
    * Clean up start function
    
    * Describe difference between reshard key and task
    
    * Report resharding abort/finish to consensus
    
    * Add driver methods for remaining stages
    
    * Fix typo
    
    * Only start driver on the peer that is responsible for driving it
    
    * Remove ReshardTask, repurpose ReshardKey for that

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index a8e487938..ee92c042c 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -9,7 +9,7 @@ use collection::operations::types::{
     SparseVectorParams, SparseVectorsConfig, VectorsConfig, VectorsConfigDiff,
 };
 use collection::shards::replica_set::ReplicaState;
-use collection::shards::resharding::ReshardingKey;
+use collection::shards::resharding::ReshardKey;
 use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
 use collection::shards::transfer::{ShardTransfer, ShardTransferKey, ShardTransferRestart};
 use collection::shards::{replica_set, CollectionId};
@@ -294,8 +294,8 @@ pub struct DeleteCollectionOperation(pub String);
 
 #[derive(Clone, Debug, Eq, PartialEq, Hash, Deserialize, Serialize)]
 pub enum ReshardingOperation {
-    Start(ReshardingKey),
-    Abort(ReshardingKey),
+    Start(ReshardKey),
+    Abort(ReshardKey),
 }
 
 #[derive(Debug, Deserialize, Serialize, PartialEq, Eq, Hash, Clone)]

commit 88378298eb4234b271b324b627b22a5735f24213
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Fri May 31 17:05:07 2024 +0200

    Add `ReshardingOperation::CommitHashRing` consensus operation (#4344)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index ee92c042c..a061cdb97 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -295,6 +295,7 @@ pub struct DeleteCollectionOperation(pub String);
 #[derive(Clone, Debug, Eq, PartialEq, Hash, Deserialize, Serialize)]
 pub enum ReshardingOperation {
     Start(ReshardKey),
+    CommitHashRing(ReshardKey),
     Abort(ReshardKey),
 }
 

commit ed4e2fd10679953e9424688d5eb135eb0ab263bd
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Wed Jun 19 12:14:26 2024 +0200

    Rework `CommitHashRing` consensus message into `CommitRead`/`CommitWrite`/`Finish` (#4417)
    
    * Refactor `CommitHashRing` into `CommitRead`/`CommitWrite`/`Finish`
    
    * Add `Resharding` filter condition
    
    * Filter "resharded" points from search, scroll by, count and retrieve request results
    
    * fixup! Refactor `CommitHashRing` into `CommitRead`/`CommitWrite`/`Finish`
    
    `cargo clippy --fix`
    
    * Apply suggestions from code review
    
    * fixup! Filter "resharded" points from search, scroll by, count and retrieve request results
    
    Add `Condition::is_local_only` method
    
    * fixup! Add `Resharding` filter condition
    
    * fixup! Filter "resharded" points from search, scroll by, count and retrieve request results
    
    Clarified a few `TODO`s
    
    * Fix clippy suggestions
    
    ---------
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index a061cdb97..a7b1bbb69 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -295,7 +295,9 @@ pub struct DeleteCollectionOperation(pub String);
 #[derive(Clone, Debug, Eq, PartialEq, Hash, Deserialize, Serialize)]
 pub enum ReshardingOperation {
     Start(ReshardKey),
-    CommitHashRing(ReshardKey),
+    CommitRead(ReshardKey),
+    CommitWrite(ReshardKey),
+    Finish(ReshardKey),
     Abort(ReshardKey),
 }
 

commit a06d20fb58a70f369c3a3b40178b726a291e6423
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Mon Jul 8 07:51:59 2024 +0000

    Remove dead code (#4623)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index a7b1bbb69..965be8d75 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -257,14 +257,6 @@ impl UpdateCollectionOperation {
         }
     }
 
-    // Returns `true` if there are replica changes associated with this operation
-    pub fn have_replica_changes(&self) -> bool {
-        self.shard_replica_changes
-            .as_ref()
-            .map(|changes| !changes.is_empty())
-            .unwrap_or(false)
-    }
-
     pub fn take_shard_replica_changes(&mut self) -> Option<Vec<replica_set::Change>> {
         self.shard_replica_changes.take()
     }

commit 1db1e7e52e3c5f6703b8b9dbd0967509e1688b4f
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Fri Jul 26 04:42:17 2024 +0200

    Fix Clippy 1.80 (#4752)
    
    * Fix Clippy 1.80
    
    * sync openapi spec
    
    * add `check-cfg` setting to `workspace.lints.rust`
    
    ---------
    
    Co-authored-by: Luis Cosso <luis.cossio@outlook.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 965be8d75..c5f58ec34 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -114,6 +114,7 @@ pub struct CreateCollection {
     /// Number of shards in collection.
     ///  - Default is 1 for standalone, otherwise equal to the number of nodes
     ///  - Minimum is 1
+    ///
     /// For custom sharding:
     /// Number of shards in collection per shard group.
     ///  - Default is 1, meaning that each shard key will be mapped to a single shard

commit 29126883bc8865a0a936496ac61bc5019789c387
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Aug 15 15:22:51 2024 +0200

    Update Validator 0.18 (#4894)
    
    * Update Validator 0.18
    
    * fix new test error message
    
    * clearer geo error message
    
    * fix error message
    
    * fix unit tests
    
    * Put spaces back
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index c5f58ec34..8f8dca6cc 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -108,7 +108,7 @@ pub struct CreateCollection {
     /// Vector data config.
     /// It is possible to provide one config for single vector mode and list of configs for multiple vectors mode.
     #[serde(default)]
-    #[validate]
+    #[validate(nested)]
     pub vectors: VectorsConfig,
     /// For auto sharding:
     /// Number of shards in collection.
@@ -147,24 +147,24 @@ pub struct CreateCollection {
     #[serde(default)]
     pub on_disk_payload: Option<bool>,
     /// Custom params for HNSW index. If none - values from service configuration file are used.
-    #[validate]
+    #[validate(nested)]
     pub hnsw_config: Option<HnswConfigDiff>,
     /// Custom params for WAL. If none - values from service configuration file are used.
-    #[validate]
+    #[validate(nested)]
     pub wal_config: Option<WalConfigDiff>,
     /// Custom params for Optimizers.  If none - values from service configuration file are used.
     #[serde(alias = "optimizer_config")]
-    #[validate]
+    #[validate(nested)]
     pub optimizers_config: Option<OptimizersConfigDiff>,
     /// Specify other collection to copy data from.
     #[serde(default)]
     pub init_from: Option<InitFrom>,
     /// Quantization parameters. If none - quantization is disabled.
     #[serde(default, alias = "quantization")]
-    #[validate]
+    #[validate(nested)]
     pub quantization_config: Option<QuantizationConfig>,
     /// Sparse vector data config.
-    #[validate]
+    #[validate(nested)]
     pub sparse_vectors: Option<BTreeMap<String, SparseVectorParams>>,
 }
 
@@ -205,7 +205,7 @@ impl CreateCollectionOperation {
 pub struct UpdateCollection {
     /// Map of vector data parameters to update for each named vector.
     /// To update parameters in a collection having a single unnamed vector, use an empty string as name.
-    #[validate]
+    #[validate(nested)]
     pub vectors: Option<VectorsConfigDiff>,
     /// Custom params for Optimizers.  If none - it is left unchanged.
     /// This operation is blocking, it will only proceed once all current optimizations are complete
@@ -214,14 +214,14 @@ pub struct UpdateCollection {
     /// Collection base params. If none - it is left unchanged.
     pub params: Option<CollectionParamsDiff>,
     /// HNSW parameters to update for the collection index. If none - it is left unchanged.
-    #[validate]
+    #[validate(nested)]
     pub hnsw_config: Option<HnswConfigDiff>,
     /// Quantization parameters to update. If none - it is left unchanged.
     #[serde(default, alias = "quantization")]
-    #[validate]
+    #[validate(nested)]
     pub quantization_config: Option<QuantizationConfigDiff>,
     /// Map of sparse vector data parameters to update for each sparse vector.
-    #[validate]
+    #[validate(nested)]
     pub sparse_vectors: Option<SparseVectorsConfig>,
 }
 

commit 3377530c6263ec3c723b16c0fefec712406ddfdd
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Thu Aug 29 10:49:23 2024 +0200

    [Strict-Mode] Basic implementation (#4887)
    
    * add CollectionRequestVerification
    
    * add to api
    
    * rebase
    
    * improve implementation
    
    * implement strict mode for SearchRequest+Batch
    
    * improve code + fix Clippy
    
    * improve error handling
    
    * restructure StrictModeVerification trait
    
    * generate docs
    
    * check `enabled` option
    
    * review remarks
    
    * rename StrictModeConfigDiff in grpc
    
    * use missing payload detection from issue api
    
    * performance improvement
    
    * decouple extractor from issues (#4945)
    
    * some review remarks
    
    * don't default to empty functions in StrictModeVerification trait
    
    * update openapi
    
    * filter_limit => query_limit
    
    * replace discovery_max_context_size and recommend_max_examples with max_input_examples
    
    * review remarks
    
    * review fix: include possible index types into error message
    
    * review remarks
    
    ---------
    
    Co-authored-by: Luis Cosso <luis.cossio@qdrant.com>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 8f8dca6cc..e01a7a784 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -3,7 +3,7 @@ use std::collections::BTreeMap;
 use collection::config::{CollectionConfig, ShardingMethod};
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, QuantizationConfigDiff,
-    WalConfigDiff,
+    StrictModeConfig, WalConfigDiff,
 };
 use collection::operations::types::{
     SparseVectorParams, SparseVectorsConfig, VectorsConfig, VectorsConfigDiff,
@@ -166,6 +166,10 @@ pub struct CreateCollection {
     /// Sparse vector data config.
     #[validate(nested)]
     pub sparse_vectors: Option<BTreeMap<String, SparseVectorParams>>,
+    /// Strict-mode config.
+    #[validate(nested)]
+    #[schemars(skip)]
+    pub strict_mode_config: Option<StrictModeConfig>,
 }
 
 /// Operation for creating new collection and (optionally) specify index params
@@ -398,6 +402,7 @@ impl From<CollectionConfig> for CreateCollection {
             init_from: None,
             quantization_config: value.quantization_config,
             sparse_vectors: value.params.sparse_vectors,
+            strict_mode_config: value.strict_mode_config,
         }
     }
 }

commit 0b236d8107156a0da37afc4fd0f22888af18c792
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Wed Sep 25 14:22:36 2024 +0200

    [Strict mode] default config (#5037)
    
    * add default config for strict mode
    
    * add default values as example to config/config.yaml
    
    * improve implementation
    
    * update grpc docs

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index e01a7a784..d44f0c946 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -3,7 +3,7 @@ use std::collections::BTreeMap;
 use collection::config::{CollectionConfig, ShardingMethod};
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, QuantizationConfigDiff,
-    StrictModeConfig, WalConfigDiff,
+    StrictModeConfigDiff, WalConfigDiff,
 };
 use collection::operations::types::{
     SparseVectorParams, SparseVectorsConfig, VectorsConfig, VectorsConfigDiff,
@@ -169,7 +169,7 @@ pub struct CreateCollection {
     /// Strict-mode config.
     #[validate(nested)]
     #[schemars(skip)]
-    pub strict_mode_config: Option<StrictModeConfig>,
+    pub strict_mode_config: Option<StrictModeConfigDiff>,
 }
 
 /// Operation for creating new collection and (optionally) specify index params
@@ -402,7 +402,7 @@ impl From<CollectionConfig> for CreateCollection {
             init_from: None,
             quantization_config: value.quantization_config,
             sparse_vectors: value.params.sparse_vectors,
-            strict_mode_config: value.strict_mode_config,
+            strict_mode_config: value.strict_mode_config.map(StrictModeConfigDiff::from),
         }
     }
 }

commit 05b8dca540be9a5ddc4a5ef864c9c49a02326a48
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Thu Sep 26 12:36:39 2024 +0200

    [Strict mode] Merge StrictMode config types (#5137)
    
    * merge StrictModeConfig and StrictModeConfigDiff into one type
    
    * review remarks

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index d44f0c946..58a73b86b 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -3,7 +3,7 @@ use std::collections::BTreeMap;
 use collection::config::{CollectionConfig, ShardingMethod};
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, QuantizationConfigDiff,
-    StrictModeConfigDiff, WalConfigDiff,
+    WalConfigDiff,
 };
 use collection::operations::types::{
     SparseVectorParams, SparseVectorsConfig, VectorsConfig, VectorsConfigDiff,
@@ -14,7 +14,9 @@ use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
 use collection::shards::transfer::{ShardTransfer, ShardTransferKey, ShardTransferRestart};
 use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
-use segment::types::{PayloadFieldSchema, PayloadKeyType, QuantizationConfig, ShardKey};
+use segment::types::{
+    PayloadFieldSchema, PayloadKeyType, QuantizationConfig, ShardKey, StrictModeConfig,
+};
 use serde::{Deserialize, Serialize};
 use validator::Validate;
 
@@ -169,7 +171,7 @@ pub struct CreateCollection {
     /// Strict-mode config.
     #[validate(nested)]
     #[schemars(skip)]
-    pub strict_mode_config: Option<StrictModeConfigDiff>,
+    pub strict_mode_config: Option<StrictModeConfig>,
 }
 
 /// Operation for creating new collection and (optionally) specify index params
@@ -402,7 +404,7 @@ impl From<CollectionConfig> for CreateCollection {
             init_from: None,
             quantization_config: value.quantization_config,
             sparse_vectors: value.params.sparse_vectors,
-            strict_mode_config: value.strict_mode_config.map(StrictModeConfigDiff::from),
+            strict_mode_config: value.strict_mode_config,
         }
     }
 }

commit a0de9509d735c3edc84133fcb367808b4a4c91be
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Mon Oct 14 10:27:00 2024 +0200

    Add strict mode config to update collection API + Populate strict mode in API (#5187)
    
    * add strict mode to update collection API
    
    * update API specs
    
    * clippy
    
    * Update lib/storage/src/content_manager/toc/collection_meta_ops.rs
    
    * Strict mode integration tests (#5189)
    
    * Add integration tests for strict mode
    
    * add full update test
    
    * Apply suggestions from code review
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * Adjust error messages
    
    * improve checking of error response
    
    ---------
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    * prefer explicit structu conversion
    
    ---------
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 58a73b86b..fa4e8db06 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -170,7 +170,6 @@ pub struct CreateCollection {
     pub sparse_vectors: Option<BTreeMap<String, SparseVectorParams>>,
     /// Strict-mode config.
     #[validate(nested)]
-    #[schemars(skip)]
     pub strict_mode_config: Option<StrictModeConfig>,
 }
 
@@ -229,6 +228,8 @@ pub struct UpdateCollection {
     /// Map of sparse vector data parameters to update for each sparse vector.
     #[validate(nested)]
     pub sparse_vectors: Option<SparseVectorsConfig>,
+    #[validate(nested)]
+    pub strict_mode_config: Option<StrictModeConfig>,
 }
 
 /// Operation for updating parameters of the existing collection
@@ -251,6 +252,7 @@ impl UpdateCollectionOperation {
                 optimizers_config: None,
                 quantization_config: None,
                 sparse_vectors: None,
+                strict_mode_config: None,
             },
             shard_replica_changes: None,
         }

commit 719f4f40942a33d7bdef25e789eb06e2f7f9f9a3
Author: Luis Cosso <luis.cossio@qdrant.com>
Date:   Mon Nov 11 10:38:43 2024 -0600

    Make `default_on_disk_payload` consistent with config file (#5396)
    
    * make the default `on_disk_payload` match the default config value
    
    * remove duplicate impl, update docstrings
    
    * change default `PayloadStorageType` too
    
    * gen openapi

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index fa4e8db06..83f8af31d 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -146,6 +146,8 @@ pub struct CreateCollection {
     /// It will be read from the disk every time it is requested.
     /// This setting saves RAM by (slightly) increasing the response time.
     /// Note: those payload values that are involved in filtering and are indexed - remain in RAM.
+    ///
+    /// Default: true
     #[serde(default)]
     pub on_disk_payload: Option<bool>,
     /// Custom params for HNSW index. If none - values from service configuration file are used.

commit 9e06d68661402bb2df271134bab5d9aeda995048
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Sat Nov 16 01:03:50 2024 +0700

    Add UUID to collection config (#5378)
    
    * Add UUID to collection...
    
    ...and recreate collection, when applying Raft snapshot, if UUID of collection is different
    
    * fixup! Add UUID to collection...
    
    Remove UUID field from gRPC and exclude it from OpenAPI spec 
    
    * fixup! fixup! Add UUID to collection...
    
    Always generate collection UUID 
    
    * Raft snapshot recreate collection no expose UUID (#5452)
    
    * separate colleciton config structure from API
    
    * fmt
    
    * Update lib/collection/src/operations/types.rs
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    ---------
    
    Co-authored-by: Tim Vise <tim+github@visee.me>
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    Co-authored-by: Tim Vise <tim+github@visee.me>

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 83f8af31d..24979da07 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,6 +1,6 @@
 use std::collections::BTreeMap;
 
-use collection::config::{CollectionConfig, ShardingMethod};
+use collection::config::{CollectionConfigInternal, ShardingMethod};
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, QuantizationConfigDiff,
     WalConfigDiff,
@@ -18,6 +18,7 @@ use segment::types::{
     PayloadFieldSchema, PayloadKeyType, QuantizationConfig, ShardKey, StrictModeConfig,
 };
 use serde::{Deserialize, Serialize};
+use uuid::Uuid;
 use validator::Validate;
 
 use crate::content_manager::shard_distribution::ShardDistributionProposal;
@@ -173,6 +174,9 @@ pub struct CreateCollection {
     /// Strict-mode config.
     #[validate(nested)]
     pub strict_mode_config: Option<StrictModeConfig>,
+    #[serde(default)]
+    #[schemars(skip)]
+    pub uuid: Option<Uuid>,
 }
 
 /// Operation for creating new collection and (optionally) specify index params
@@ -393,8 +397,8 @@ pub enum CollectionMetaOperations {
 
 /// Use config of the existing collection to generate a create collection operation
 /// for the new collection
-impl From<CollectionConfig> for CreateCollection {
-    fn from(value: CollectionConfig) -> Self {
+impl From<CollectionConfigInternal> for CreateCollection {
+    fn from(value: CollectionConfigInternal) -> Self {
         Self {
             vectors: value.params.vectors,
             shard_number: Some(value.params.shard_number.get()),
@@ -409,6 +413,7 @@ impl From<CollectionConfig> for CreateCollection {
             quantization_config: value.quantization_config,
             sparse_vectors: value.params.sparse_vectors,
             strict_mode_config: value.strict_mode_config,
+            uuid: value.uuid,
         }
     }
 }

commit 66780503325258e53a2284b04cbbc68161c4bfc0
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Jan 15 16:51:05 2025 +0100

    API validation for unique dense and sparse vector names (#5808)
    
    * API validation for unique dense and sparse vector names
    
    * less alloc
    
    * test empty name as well
    
    * quotes instead of ticks

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 24979da07..c6047951b 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -21,6 +21,7 @@ use serde::{Deserialize, Serialize};
 use uuid::Uuid;
 use validator::Validate;
 
+use crate::content_manager::errors::{StorageError, StorageResult};
 use crate::content_manager::shard_distribution::ShardDistributionProposal;
 
 // *Operation wrapper structure is only required for better OpenAPI generation
@@ -189,12 +190,26 @@ pub struct CreateCollectionOperation {
 }
 
 impl CreateCollectionOperation {
-    pub fn new(collection_name: String, create_collection: CreateCollection) -> Self {
-        Self {
+    pub fn new(
+        collection_name: String,
+        create_collection: CreateCollection,
+    ) -> StorageResult<Self> {
+        // validate vector names are unique between dense and sparse vectors
+        if let Some(sparse_config) = &create_collection.sparse_vectors {
+            let mut dense_names = create_collection.vectors.params_iter().map(|p| p.0);
+            if let Some(duplicate_name) = dense_names.find(|name| sparse_config.contains_key(*name))
+            {
+                return Err(StorageError::bad_input(
+                    format!("Dense and sparse vector names must be unique - duplicate found with '{duplicate_name}'"),
+                ));
+            }
+        }
+
+        Ok(Self {
             collection_name,
             create_collection,
             distribution: None,
-        }
+        })
     }
 
     pub fn is_distribution_set(&self) -> bool {

commit e85a9f18b4f5219799c3625c2d3d19c5b3be4ed5
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Fri Jan 24 01:29:01 2025 +0000

    Add `VectorName` type alias (#5763)
    
    * Add VectorName/VectorNameBuf type aliases [1/2]
    
    * Add VectorName/VectorNameBuf type aliases [2/2]

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index c6047951b..9784880fa 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -16,6 +16,7 @@ use collection::shards::{replica_set, CollectionId};
 use schemars::JsonSchema;
 use segment::types::{
     PayloadFieldSchema, PayloadKeyType, QuantizationConfig, ShardKey, StrictModeConfig,
+    VectorNameBuf,
 };
 use serde::{Deserialize, Serialize};
 use uuid::Uuid;
@@ -171,7 +172,7 @@ pub struct CreateCollection {
     pub quantization_config: Option<QuantizationConfig>,
     /// Sparse vector data config.
     #[validate(nested)]
-    pub sparse_vectors: Option<BTreeMap<String, SparseVectorParams>>,
+    pub sparse_vectors: Option<BTreeMap<VectorNameBuf, SparseVectorParams>>,
     /// Strict-mode config.
     #[validate(nested)]
     pub strict_mode_config: Option<StrictModeConfig>,

commit 8ad2b34265448ec01b89d4093de5fbb1a86dcd4d
Author: Tim Vise <tim+github@visee.me>
Date:   Tue Feb 25 11:21:25 2025 +0100

    Bump Rust edition to 2024 (#6042)
    
    * Bump Rust edition to 2024
    
    * gen is a reserved keyword now
    
    * Remove ref mut on references
    
    * Mark extern C as unsafe
    
    * Wrap unsafe function bodies in unsafe block
    
    * Geo hash implements Copy, don't reference but pass by value instead
    
    * Replace secluded self import with parent
    
    * Update execute_cluster_read_operation with new match semantics
    
    * Fix lifetime issue
    
    * Replace map_or with is_none_or
    
    * set_var is unsafe now
    
    * Reformat

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 9784880fa..13e3f03fa 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -12,7 +12,7 @@ use collection::shards::replica_set::ReplicaState;
 use collection::shards::resharding::ReshardKey;
 use collection::shards::shard::{PeerId, ShardId, ShardsPlacement};
 use collection::shards::transfer::{ShardTransfer, ShardTransferKey, ShardTransferRestart};
-use collection::shards::{replica_set, CollectionId};
+use collection::shards::{CollectionId, replica_set};
 use schemars::JsonSchema;
 use segment::types::{
     PayloadFieldSchema, PayloadKeyType, QuantizationConfig, ShardKey, StrictModeConfig,
@@ -200,9 +200,9 @@ impl CreateCollectionOperation {
             let mut dense_names = create_collection.vectors.params_iter().map(|p| p.0);
             if let Some(duplicate_name) = dense_names.find(|name| sparse_config.contains_key(*name))
             {
-                return Err(StorageError::bad_input(
-                    format!("Dense and sparse vector names must be unique - duplicate found with '{duplicate_name}'"),
-                ));
+                return Err(StorageError::bad_input(format!(
+                    "Dense and sparse vector names must be unique - duplicate found with '{duplicate_name}'",
+                )));
             }
         }
 

commit b5de28db80a9ca6734cd2e544853e2d49a3e7561
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Feb 26 15:57:06 2025 +0100

    Struct deconstruction leftovers (#6071)

diff --git a/lib/storage/src/content_manager/collection_meta_ops.rs b/lib/storage/src/content_manager/collection_meta_ops.rs
index 13e3f03fa..6a5001632 100644
--- a/lib/storage/src/content_manager/collection_meta_ops.rs
+++ b/lib/storage/src/content_manager/collection_meta_ops.rs
@@ -1,6 +1,6 @@
 use std::collections::BTreeMap;
 
-use collection::config::{CollectionConfigInternal, ShardingMethod};
+use collection::config::{CollectionConfigInternal, CollectionParams, ShardingMethod};
 use collection::operations::config_diff::{
     CollectionParamsDiff, HnswConfigDiff, OptimizersConfigDiff, QuantizationConfigDiff,
     WalConfigDiff,
@@ -415,21 +415,42 @@ pub enum CollectionMetaOperations {
 /// for the new collection
 impl From<CollectionConfigInternal> for CreateCollection {
     fn from(value: CollectionConfigInternal) -> Self {
+        let CollectionConfigInternal {
+            params,
+            hnsw_config,
+            optimizer_config,
+            wal_config,
+            quantization_config,
+            strict_mode_config,
+            uuid,
+        } = value;
+
+        let CollectionParams {
+            vectors,
+            shard_number,
+            sharding_method,
+            replication_factor,
+            write_consistency_factor,
+            read_fan_out_factor: _,
+            on_disk_payload,
+            sparse_vectors,
+        } = params;
+
         Self {
-            vectors: value.params.vectors,
-            shard_number: Some(value.params.shard_number.get()),
-            sharding_method: value.params.sharding_method,
-            replication_factor: Some(value.params.replication_factor.get()),
-            write_consistency_factor: Some(value.params.write_consistency_factor.get()),
-            on_disk_payload: Some(value.params.on_disk_payload),
-            hnsw_config: Some(value.hnsw_config.into()),
-            wal_config: Some(value.wal_config.into()),
-            optimizers_config: Some(value.optimizer_config.into()),
+            vectors,
+            shard_number: Some(shard_number.get()),
+            sharding_method,
+            replication_factor: Some(replication_factor.get()),
+            write_consistency_factor: Some(write_consistency_factor.get()),
+            on_disk_payload: Some(on_disk_payload),
+            hnsw_config: Some(hnsw_config.into()),
+            wal_config: Some(wal_config.into()),
+            optimizers_config: Some(optimizer_config.into()),
             init_from: None,
-            quantization_config: value.quantization_config,
-            sparse_vectors: value.params.sparse_vectors,
-            strict_mode_config: value.strict_mode_config,
-            uuid: value.uuid,
+            quantization_config,
+            sparse_vectors,
+            strict_mode_config,
+            uuid,
         }
     }
 }

